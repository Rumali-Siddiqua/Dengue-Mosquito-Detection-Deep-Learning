{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dengue Mosquito Detection .ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhzxsJb3dpWq"
      },
      "source": [
        "## Configs and Hyperparameters\n",
        "\n",
        "Support a variety of models, you can find more pretrained model from [Tensorflow detection model zoo: COCO-trained models](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models), as well as their pipline config files in [object_detection/samples/configs/](https://github.com/tensorflow/models/tree/master/research/object_detection/samples/configs)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnNXNQCjdniL"
      },
      "source": [
        "# If you forked the repository, you can replace the link.\n",
        "repo_url = 'https://github.com/Rumali-Siddiqua/Dengue-Mosquito-Detection-Deep-Learning'\n",
        "\n",
        "# Number of training steps.\n",
        "num_steps = 800  # 200000\n",
        "\n",
        "# Number of evaluation steps.\n",
        "num_eval_steps = 50\n",
        "\n",
        "MODELS_CONFIG = {\n",
        "    'ssd_mobilenet_v2': {\n",
        "        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n",
        "        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'faster_rcnn_inception_v2': {\n",
        "        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n",
        "        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'rfcn_resnet101': {\n",
        "        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n",
        "        'pipeline_file': 'rfcn_resnet101_pets.config',\n",
        "        'batch_size': 8\n",
        "    }\n",
        "}\n",
        "\n",
        "# Pick the model you want to use\n",
        "# Select a model in `MODELS_CONFIG`.\n",
        "selected_model = 'faster_rcnn_inception_v2'\n",
        "\n",
        "# Name of the object detection model to use.\n",
        "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
        "\n",
        "# Name of the pipline file in tensorflow object detection API.\n",
        "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
        "\n",
        "# Training batch size fits in Colabe's Tesla K80 GPU memory for selected model.\n",
        "batch_size = MODELS_CONFIG[selected_model]['batch_size']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lav0F2Iki9Zv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21816156-078f-4155-d4cc-c6f986fcf561"
      },
      "source": [
        "# use TF 1.x for Object Detection APIs as they are not ported to TF 2.0 yet\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxmTFRTLiMYr"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4V-XE6kbkc1"
      },
      "source": [
        "## Clone the `object_detection_demo` repository or your fork."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxc3DmvLQF3z",
        "outputId": "7ef60cbd-21f8-44cd-8a1f-7781048b5b23"
      },
      "source": [
        "import os\n",
        "\n",
        "%cd /content\n",
        "\n",
        "repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n",
        "\n",
        "!git clone {repo_url}\n",
        "%cd {repo_dir_path}\n",
        "!git pull"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'detection_demo'...\n",
            "remote: Enumerating objects: 84, done.\u001b[K\n",
            "remote: Counting objects: 100% (84/84), done.\u001b[K\n",
            "remote: Compressing objects: 100% (83/83), done.\u001b[K\n",
            "remote: Total 324 (delta 34), reused 0 (delta 0), pack-reused 240\u001b[K\n",
            "Receiving objects: 100% (324/324), 11.16 MiB | 6.81 MiB/s, done.\n",
            "Resolving deltas: 100% (142/142), done.\n",
            "/content/detection_demo\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKX_sDk7iGls"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI8__uNS8-ns"
      },
      "source": [
        "## Install required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLnC4AR9hgas",
        "outputId": "75b4ad6b-12af-447c-8c2c-5c03c66b6994"
      },
      "source": [
        "%cd /content\n",
        "!git clone --quiet https://github.com/tensorflow/models.git\n",
        "\n",
        "!pip install tf_slim\n",
        "\n",
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
        "\n",
        "!pip install -q pycocotools\n",
        "\n",
        "!pip install lvis\n",
        "\n",
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n",
        "\n",
        "!python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Collecting tf_slim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n",
            "\u001b[K     |████████████████████████████████| 358kB 12.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf_slim) (0.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n",
            "Installing collected packages: tf-slim\n",
            "Successfully installed tf-slim-1.1.0\n",
            "E: Failed to fetch http://security.ubuntu.com/ubuntu/pool/main/l/lxml/python-lxml_4.2.1-1ubuntu0.1_amd64.deb  404  Not Found [IP: 91.189.88.142 80]\n",
            "E: Unable to fetch some archives, maybe run apt-get update or try with --fix-missing?\n",
            "Collecting lvis\n",
            "  Downloading https://files.pythonhosted.org/packages/72/b6/1992240ab48310b5360bfdd1d53163f43bb97d90dc5dc723c67d41c38e78/lvis-0.5.3-py3-none-any.whl\n",
            "Requirement already satisfied: pyparsing>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from lvis) (2.4.7)\n",
            "Requirement already satisfied: Cython>=0.29.12 in /usr/local/lib/python3.6/dist-packages (from lvis) (0.29.21)\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.6/dist-packages (from lvis) (1.18.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.6/dist-packages (from lvis) (4.1.2.30)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from lvis) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.6/dist-packages (from lvis) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from lvis) (1.3.1)\n",
            "Requirement already satisfied: matplotlib>=3.1.1 in /usr/local/lib/python3.6/dist-packages (from lvis) (3.2.2)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.6/dist-packages (from lvis) (0.10.0)\n",
            "Installing collected packages: lvis\n",
            "Successfully installed lvis-0.5.3\n",
            "/content/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-k7uGThXlny"
      },
      "source": [
        "## Prepare `tfrecord` files\n",
        "\n",
        "Use the following scripts to generate the `tfrecord` files.\n",
        "```bash\n",
        "# Convert train folder annotation xml files to a single csv file,\n",
        "# generate the `label_map.pbtxt` file to `data/` directory as well.\n",
        "python xml_to_csv.py -i data/images/train -o data/annotations/train_labels.csv -l data/annotations\n",
        "\n",
        "# Convert test folder annotation xml files to a single csv.\n",
        "python xml_to_csv.py -i data/images/test -o data/annotations/test_labels.csv\n",
        "\n",
        "# Generate `train.record`\n",
        "python generate_tfrecord.py --csv_input=data/annotations/train_labels.csv --output_path=data/annotations/train.record --img_path=data/images/train --label_map data/annotations/label_map.pbtxt\n",
        "\n",
        "# Generate `test.record`\n",
        "python generate_tfrecord.py --csv_input=data/annotations/test_labels.csv --output_path=data/annotations/test.record --img_path=data/images/test --label_map data/annotations/label_map.pbtxt\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezGDABRXXhPP",
        "outputId": "164e3bac-0a1e-44d7-bc43-3f035a0f6686"
      },
      "source": [
        "%cd {repo_dir_path}\n",
        "\n",
        "# Convert train folder annotation xml files to a single csv file,\n",
        "# generate the `label_map.pbtxt` file to `data/` directory as well.\n",
        "!python xml_to_csv.py -i data/images/train -o data/annotations/train_labels.csv -l data/annotations\n",
        "\n",
        "# Convert test folder annotation xml files to a single csv.\n",
        "!python xml_to_csv.py -i data/images/test -o data/annotations/test_labels.csv\n",
        "\n",
        "# Generate `train.record`\n",
        "!python generate_tfrecord.py --csv_input=data/annotations/train_labels.csv --output_path=data/annotations/train.record --img_path=data/images/train --label_map data/annotations/label_map.pbtxt\n",
        "\n",
        "# Generate `test.record`\n",
        "!python generate_tfrecord.py --csv_input=data/annotations/test_labels.csv --output_path=data/annotations/test.record --img_path=data/images/test --label_map data/annotations/label_map.pbtxt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/detection_demo\n",
            "Successfully converted xml to csv.\n",
            "Generate `data/annotations/label_map.pbtxt`\n",
            "Successfully converted xml to csv.\n",
            "WARNING:tensorflow:From generate_tfrecord.py:134: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W1213 05:03:12.854070 139791539500928 module_wrapper.py:139] From generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From generate_tfrecord.py:53: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W1213 05:03:12.886468 139791539500928 module_wrapper.py:139] From generate_tfrecord.py:53: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "Successfully created the TFRecords: /content/detection_demo/data/annotations/train.record\n",
            "WARNING:tensorflow:From generate_tfrecord.py:134: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W1213 05:03:15.406341 140214498772864 module_wrapper.py:139] From generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From generate_tfrecord.py:53: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W1213 05:03:15.421133 140214498772864 module_wrapper.py:139] From generate_tfrecord.py:53: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"generate_tfrecord.py\", line 134, in <module>\n",
            "    tf.app.run()\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/platform/app.py\", line 40, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 300, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 251, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"generate_tfrecord.py\", line 125, in main\n",
            "    tf_example = create_tf_example(group, path, label_map)\n",
            "  File \"generate_tfrecord.py\", line 54, in create_tf_example\n",
            "    encoded_jpg = fid.read()\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/lib/io/file_io.py\", line 122, in read\n",
            "    self._preread_check()\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/lib/io/file_io.py\", line 84, in _preread_check\n",
            "    compat.as_bytes(self.__name), 1024 * 512)\n",
            "tensorflow.python.framework.errors_impl.NotFoundError: /content/detection_demo/data/images/test/28.jpg; No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgd-fzAIkZlV"
      },
      "source": [
        "test_record_fname = '/content/detection_demo/data/annotations/test.record'\n",
        "train_record_fname = '/content/detection_demo/data/annotations/train.record'\n",
        "label_map_pbtxt_fname = '/content/detection_demo/data/annotations/label_map.pbtxt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCNYAaC7w6N8"
      },
      "source": [
        "## Download base model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orDCj6ihgUMR",
        "outputId": "713c617c-9cb0-4827-f135-c5b1d6169764"
      },
      "source": [
        "%cd /content/models/research\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import urllib.request\n",
        "import tarfile\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "DEST_DIR = '/content/models/research/pretrained_model'\n",
        "\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(DEST_DIR)):\n",
        "    shutil.rmtree(DEST_DIR)\n",
        "os.rename(MODEL, DEST_DIR)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGhvAObeiIix",
        "outputId": "b73f00e6-96ba-4b9b-8f73-9e4648ca84df"
      },
      "source": [
        "!echo {DEST_DIR}\n",
        "!ls -alh {DEST_DIR}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/pretrained_model\n",
            "total 111M\n",
            "drwxr-xr-x  3 345018 5000 4.0K Feb  1  2018 .\n",
            "drwxr-xr-x 24 root   root 4.0K Dec 13 05:03 ..\n",
            "-rw-r--r--  1 345018 5000   77 Feb  1  2018 checkpoint\n",
            "-rw-r--r--  1 345018 5000  55M Feb  1  2018 frozen_inference_graph.pb\n",
            "-rw-r--r--  1 345018 5000  51M Feb  1  2018 model.ckpt.data-00000-of-00001\n",
            "-rw-r--r--  1 345018 5000  16K Feb  1  2018 model.ckpt.index\n",
            "-rw-r--r--  1 345018 5000 5.5M Feb  1  2018 model.ckpt.meta\n",
            "-rw-r--r--  1 345018 5000 3.2K Feb  1  2018 pipeline.config\n",
            "drwxr-xr-x  3 345018 5000 4.0K Feb  1  2018 saved_model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UHnxlfRznPP3",
        "outputId": "6e7ead0d-4d59-426c-c584-48759a556404"
      },
      "source": [
        "fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n",
        "fine_tune_checkpoint"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/models/research/pretrained_model/model.ckpt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvwtHlLOeRJD"
      },
      "source": [
        "## Configuring a Training Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIhw7IdpLuiU"
      },
      "source": [
        "import os\n",
        "pipeline_fname = os.path.join('/content/models/research/object_detection/samples/configs/', pipeline_file)\n",
        "\n",
        "assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG1nCNpUXcRU"
      },
      "source": [
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjtCbLF2i0wI"
      },
      "source": [
        "import re\n",
        "\n",
        "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
        "with open(pipeline_fname) as f:\n",
        "    s = f.read()\n",
        "with open(pipeline_fname, 'w') as f:\n",
        "    \n",
        "    # fine_tune_checkpoint\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "    \n",
        "    # tfrecord files train and test.\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
        "\n",
        "    # label_map_path\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
        "\n",
        "    # Set training batch_size.\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    # Set training steps, num_steps\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "    \n",
        "    # Set number of classes num_classes.\n",
        "    s = re.sub('num_classes: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "    f.write(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GH0MEEanocn6",
        "outputId": "7fe14acd-ab96-4684-b6b4-dfc900333fbd"
      },
      "source": [
        "!cat {pipeline_fname}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Faster R-CNN with Inception v2, configured for Oxford-IIIT Pets Dataset.\n",
            "# Users should configure the fine_tune_checkpoint field in the train config as\n",
            "# well as the label_map_path and input_path fields in the train_input_reader and\n",
            "# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n",
            "# should be configured.\n",
            "\n",
            "model {\n",
            "  faster_rcnn {\n",
            "    num_classes: 1\n",
            "    image_resizer {\n",
            "      keep_aspect_ratio_resizer {\n",
            "        min_dimension: 600\n",
            "        max_dimension: 1024\n",
            "      }\n",
            "    }\n",
            "    feature_extractor {\n",
            "      type: 'faster_rcnn_inception_v2'\n",
            "      first_stage_features_stride: 16\n",
            "    }\n",
            "    first_stage_anchor_generator {\n",
            "      grid_anchor_generator {\n",
            "        scales: [0.25, 0.5, 1.0, 2.0]\n",
            "        aspect_ratios: [0.5, 1.0, 2.0]\n",
            "        height_stride: 16\n",
            "        width_stride: 16\n",
            "      }\n",
            "    }\n",
            "    first_stage_box_predictor_conv_hyperparams {\n",
            "      op: CONV\n",
            "      regularizer {\n",
            "        l2_regularizer {\n",
            "          weight: 0.0\n",
            "        }\n",
            "      }\n",
            "      initializer {\n",
            "        truncated_normal_initializer {\n",
            "          stddev: 0.01\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    first_stage_nms_score_threshold: 0.0\n",
            "    first_stage_nms_iou_threshold: 0.7\n",
            "    first_stage_max_proposals: 300\n",
            "    first_stage_localization_loss_weight: 2.0\n",
            "    first_stage_objectness_loss_weight: 1.0\n",
            "    initial_crop_size: 14\n",
            "    maxpool_kernel_size: 2\n",
            "    maxpool_stride: 2\n",
            "    second_stage_box_predictor {\n",
            "      mask_rcnn_box_predictor {\n",
            "        use_dropout: false\n",
            "        dropout_keep_probability: 1.0\n",
            "        fc_hyperparams {\n",
            "          op: FC\n",
            "          regularizer {\n",
            "            l2_regularizer {\n",
            "              weight: 0.0\n",
            "            }\n",
            "          }\n",
            "          initializer {\n",
            "            variance_scaling_initializer {\n",
            "              factor: 1.0\n",
            "              uniform: true\n",
            "              mode: FAN_AVG\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    second_stage_post_processing {\n",
            "      batch_non_max_suppression {\n",
            "        score_threshold: 0.0\n",
            "        iou_threshold: 0.6\n",
            "        max_detections_per_class: 100\n",
            "        max_total_detections: 300\n",
            "      }\n",
            "      score_converter: SOFTMAX\n",
            "    }\n",
            "    second_stage_localization_loss_weight: 2.0\n",
            "    second_stage_classification_loss_weight: 1.0\n",
            "  }\n",
            "}\n",
            "\n",
            "train_config: {\n",
            "  batch_size: 12\n",
            "  optimizer {\n",
            "    momentum_optimizer: {\n",
            "      learning_rate: {\n",
            "        manual_step_learning_rate {\n",
            "          initial_learning_rate: 0.0002\n",
            "          schedule {\n",
            "            step: 900000\n",
            "            learning_rate: .00002\n",
            "          }\n",
            "          schedule {\n",
            "            step: 1200000\n",
            "            learning_rate: .000002\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      momentum_optimizer_value: 0.9\n",
            "    }\n",
            "    use_moving_average: false\n",
            "  }\n",
            "  gradient_clipping_by_norm: 10.0\n",
            "  fine_tune_checkpoint: \"/content/models/research/pretrained_model/model.ckpt\"\n",
            "  from_detection_checkpoint: true\n",
            "  load_all_detection_checkpoint_vars: true\n",
            "  # Note: The below line limits the training process to 200K steps, which we\n",
            "  # empirically found to be sufficient enough to train the pets dataset. This\n",
            "  # effectively bypasses the learning rate schedule (the learning rate will\n",
            "  # never decay). Remove the below line to train indefinitely.\n",
            "  num_steps: 800\n",
            "  data_augmentation_options {\n",
            "    random_horizontal_flip {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "train_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/detection_demo/data/annotations/train.record\"\n",
            "  }\n",
            "  label_map_path: \"/content/detection_demo/data/annotations/label_map.pbtxt\"\n",
            "}\n",
            "\n",
            "eval_config: {\n",
            "  metrics_set: \"coco_detection_metrics\"\n",
            "  num_examples: 1101\n",
            "}\n",
            "\n",
            "eval_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/detection_demo/data/annotations/test.record\"\n",
            "  }\n",
            "  label_map_path: \"/content/detection_demo/data/annotations/label_map.pbtxt\"\n",
            "  shuffle: false\n",
            "  num_readers: 1\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f11w0uO3jFCB"
      },
      "source": [
        "model_dir = 'training/'\n",
        "# Optionally remove content in output model directory to fresh start.\n",
        "!rm -rf {model_dir}\n",
        "os.makedirs(model_dir, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23TECXvNezIF"
      },
      "source": [
        "## Run Tensorboard(Optional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0H2PZs-mSCmO",
        "outputId": "9469182c-d581-4bfa-8793-49bc6a095ff8"
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -o ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-13 05:04:48--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 107.21.11.91, 52.200.34.95, 54.225.42.45, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|107.21.11.91|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13773305 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.13M  12.8MB/s    in 1.0s    \n",
            "\n",
            "2020-12-13 05:04:49 (12.8 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13773305/13773305]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8o6r1o5SC5M"
      },
      "source": [
        "LOG_DIR = model_dir\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ge1OX7gcSC7S"
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5GSGxZNh8rp"
      },
      "source": [
        "### Get Tensorboard link"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjhPT9iPSJ6T",
        "outputId": "8e6a96eb-9197-4410-b4aa-088fc4186368"
      },
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://a67cb3b5d992.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDddx2rPfex9"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nC7_syR1SJ9F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjDHjhKQofT5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e3b1bd1-74bf-4dc4-b54c-8de157d73a44"
      },
      "source": [
        "!python /content/models/research/object_detection/model_main.py \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --num_eval_steps={num_eval_steps}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W1213 05:05:11.936888 139941885183872 model_lib.py:793] Forced number of epochs for all eval validations to be 1.\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 800\n",
            "I1213 05:05:11.937122 139941885183872 config_util.py:552] Maybe overwriting train_steps: 800\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I1213 05:05:11.937247 139941885183872 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "I1213 05:05:11.937357 139941885183872 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I1213 05:05:11.937474 139941885183872 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W1213 05:05:11.937615 139941885183872 model_lib.py:809] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
            "I1213 05:05:11.937750 139941885183872 model_lib.py:846] create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f464da1e128>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "I1213 05:05:11.938237 139941885183872 estimator.py:212] Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f464da1e128>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f464df20b70>) includes params argument, but params are not passed to Estimator.\n",
            "W1213 05:05:11.938483 139941885183872 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f464df20b70>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "I1213 05:05:11.939409 139941885183872 estimator_training.py:186] Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "I1213 05:05:11.939626 139941885183872 training.py:612] Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "I1213 05:05:11.939937 139941885183872 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W1213 05:05:11.952707 139941885183872 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/train.record']\n",
            "I1213 05:05:11.993632 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/train.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/train.record']\n",
            "I1213 05:05:11.994685 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/train.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 05:05:11.994821 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W1213 05:05:11.994936 139941885183872 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:103: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W1213 05:05:12.000405 139941885183872 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:103: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:222: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W1213 05:05:12.021370 139941885183872 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:222: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f464dfd82e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 05:05:12.063553 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f464dfd82e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function train_input.<locals>.transform_and_pad_input_data_fn at 0x7f464df20ea0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 05:05:12.283524 139941885183872 ag_logging.py:146] Entity <function train_input.<locals>.transform_and_pad_input_data_fn at 0x7f464df20ea0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:110: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W1213 05:05:12.285362 139941885183872 deprecation.py:323] From /content/models/research/object_detection/inputs.py:110: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:96: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W1213 05:05:12.296651 139941885183872 deprecation.py:323] From /content/models/research/object_detection/inputs.py:96: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:283: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W1213 05:05:12.437799 139941885183872 deprecation.py:323] From /content/models/research/object_detection/inputs.py:283: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 05:05:12.909813 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:2802: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W1213 05:05:13.223679 139941885183872 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:2802: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 05:05:14.641850 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 05:05:14.794682 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 05:05:14.795127 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/spatial_transform_ops.py:478: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "W1213 05:05:21.701232 139941885183872 deprecation.py:506] From /content/models/research/object_detection/utils/spatial_transform_ops.py:478: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1666: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "W1213 05:05:22.281417 139941885183872 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1666: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 05:05:22.284149 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 05:05:22.302240 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/losses.py:380: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "W1213 05:05:24.969585 139941885183872 deprecation.py:323] From /content/models/research/object_detection/core/losses.py:380: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 05:05:32.615508 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "I1213 05:05:32.617008 139941885183872 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 05:05:37.018871 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "2020-12-13 05:05:37.032976: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2250000000 Hz\n",
            "2020-12-13 05:05:37.033279: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1bea28c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-12-13 05:05:37.033308: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-12-13 05:05:37.072706: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-12-13 05:05:37.158573: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2020-12-13 05:05:37.158639: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (0b6d36a6b087): /proc/driver/nvidia/version does not exist\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 05:05:39.903223 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 05:05:40.341924 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into training/model.ckpt.\n",
            "I1213 05:05:53.870054 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 0 into training/model.ckpt.\n",
            "INFO:tensorflow:loss = 4.478245, step = 1\n",
            "I1213 05:06:56.368722 139941885183872 basic_session_run_hooks.py:262] loss = 4.478245, step = 1\n",
            "INFO:tensorflow:Saving checkpoints for 13 into training/model.ckpt.\n",
            "I1213 05:16:42.068484 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 13 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 05:16:44.347992 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 05:16:44.349015 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 05:16:44.349166 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f46408d1240>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 05:16:44.395314 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f46408d1240>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f46457c6840> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 05:16:44.589246 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f46457c6840> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 05:16:45.180756 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 05:16:46.624987 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 05:16:46.980667 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 05:16:46.981077 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 05:16:48.020021 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 05:16:48.036594 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/eval_util.py:927: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W1213 05:16:48.967746 139941885183872 deprecation.py:323] From /content/models/research/object_detection/eval_util.py:927: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "W1213 05:16:49.165383 139941885183872 deprecation.py:323] From /content/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 05:16:49.743895 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T05:16:49Z\n",
            "I1213 05:16:49.762701 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T05:16:49Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 05:16:50.206735 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-13\n",
            "I1213 05:16:50.208359 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-13\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 05:16:51.125375 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 05:16:51.291840 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 05:17:09.255544 139939724338944 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 05:17:09.256145 139939724338944 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 05:17:09.256881 139939724338944 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.087\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.087\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-05:17:10\n",
            "I1213 05:17:10.854092 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-05:17:10\n",
            "INFO:tensorflow:Saving dict for global step 13: DetectionBoxes_Precision/mAP = 0.00019163916, DetectionBoxes_Precision/mAP (large) = 0.00034916287, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0007150715, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.0875, DetectionBoxes_Recall/AR@100 (large) = 0.0875, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.19625211, Loss/BoxClassifierLoss/localization_loss = 0.17236869, Loss/RPNLoss/localization_loss = 0.19606501, Loss/RPNLoss/objectness_loss = 0.6803857, Loss/total_loss = 1.2450714, global_step = 13, learning_rate = 0.0002, loss = 1.2450714\n",
            "I1213 05:17:10.854527 139941885183872 estimator.py:2049] Saving dict for global step 13: DetectionBoxes_Precision/mAP = 0.00019163916, DetectionBoxes_Precision/mAP (large) = 0.00034916287, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0007150715, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.0875, DetectionBoxes_Recall/AR@100 (large) = 0.0875, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.19625211, Loss/BoxClassifierLoss/localization_loss = 0.17236869, Loss/RPNLoss/localization_loss = 0.19606501, Loss/RPNLoss/objectness_loss = 0.6803857, Loss/total_loss = 1.2450714, global_step = 13, learning_rate = 0.0002, loss = 1.2450714\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 13: training/model.ckpt-13\n",
            "I1213 05:17:11.995003 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 13: training/model.ckpt-13\n",
            "INFO:tensorflow:Saving checkpoints for 25 into training/model.ckpt.\n",
            "I1213 05:26:50.884705 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 25 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 05:26:53.181046 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 05:26:53.182025 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 05:26:53.182200 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463a358860>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 05:26:53.229234 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463a358860>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463a60e598> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 05:26:53.420214 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463a60e598> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 05:26:54.004177 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 05:26:55.442540 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 05:26:55.586349 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 05:26:55.586791 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 05:26:56.638019 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 05:26:56.655302 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 05:26:58.656003 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T05:26:58Z\n",
            "I1213 05:26:58.672671 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T05:26:58Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 05:26:59.130555 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-25\n",
            "I1213 05:26:59.132088 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-25\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 05:27:00.129547 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 05:27:00.309149 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 05:27:18.138214 139939724338944 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 05:27:18.138520 139939724338944 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 05:27:18.139365 139939724338944 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.050\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.050\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-05:27:19\n",
            "I1213 05:27:19.668045 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-05:27:19\n",
            "INFO:tensorflow:Saving dict for global step 25: DetectionBoxes_Precision/mAP = 0.00012903546, DetectionBoxes_Precision/mAP (large) = 0.0002209663, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0006451773, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.05, DetectionBoxes_Recall/AR@100 (large) = 0.05, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.19916193, Loss/BoxClassifierLoss/localization_loss = 0.17447068, Loss/RPNLoss/localization_loss = 0.19203272, Loss/RPNLoss/objectness_loss = 0.6513463, Loss/total_loss = 1.2170117, global_step = 25, learning_rate = 0.0002, loss = 1.2170117\n",
            "I1213 05:27:19.668419 139941885183872 estimator.py:2049] Saving dict for global step 25: DetectionBoxes_Precision/mAP = 0.00012903546, DetectionBoxes_Precision/mAP (large) = 0.0002209663, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0006451773, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.05, DetectionBoxes_Recall/AR@100 (large) = 0.05, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.19916193, Loss/BoxClassifierLoss/localization_loss = 0.17447068, Loss/RPNLoss/localization_loss = 0.19203272, Loss/RPNLoss/objectness_loss = 0.6513463, Loss/total_loss = 1.2170117, global_step = 25, learning_rate = 0.0002, loss = 1.2170117\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 25: training/model.ckpt-25\n",
            "I1213 05:27:19.674200 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 25: training/model.ckpt-25\n",
            "INFO:tensorflow:Saving checkpoints for 37 into training/model.ckpt.\n",
            "I1213 05:36:58.058145 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 37 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 05:37:00.351999 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 05:37:00.353295 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 05:37:00.353435 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463ba76940>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 05:37:00.400021 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463ba76940>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f4638aa82f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 05:37:00.590933 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f4638aa82f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 05:37:01.189167 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 05:37:02.622574 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 05:37:02.771586 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 05:37:02.772023 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 05:37:03.871867 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 05:37:03.888757 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 05:37:05.587346 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T05:37:05Z\n",
            "I1213 05:37:05.603939 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T05:37:05Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 05:37:06.046805 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-37\n",
            "I1213 05:37:06.048293 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-37\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 05:37:06.989882 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 05:37:07.169152 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 05:37:24.931220 139939732731648 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 05:37:24.931658 139939732731648 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 05:37:24.932289 139939732731648 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.003\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.200\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.200\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-05:37:26\n",
            "I1213 05:37:26.472366 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-05:37:26\n",
            "INFO:tensorflow:Saving dict for global step 37: DetectionBoxes_Precision/mAP = 0.0009076964, DetectionBoxes_Precision/mAP (large) = 0.0013250671, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.002586174, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.2, DetectionBoxes_Recall/AR@100 (large) = 0.2, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.15757112, Loss/BoxClassifierLoss/localization_loss = 0.14584315, Loss/RPNLoss/localization_loss = 0.19340388, Loss/RPNLoss/objectness_loss = 0.6079463, Loss/total_loss = 1.1047645, global_step = 37, learning_rate = 0.0002, loss = 1.1047645\n",
            "I1213 05:37:26.472726 139941885183872 estimator.py:2049] Saving dict for global step 37: DetectionBoxes_Precision/mAP = 0.0009076964, DetectionBoxes_Precision/mAP (large) = 0.0013250671, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.002586174, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.2, DetectionBoxes_Recall/AR@100 (large) = 0.2, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.15757112, Loss/BoxClassifierLoss/localization_loss = 0.14584315, Loss/RPNLoss/localization_loss = 0.19340388, Loss/RPNLoss/objectness_loss = 0.6079463, Loss/total_loss = 1.1047645, global_step = 37, learning_rate = 0.0002, loss = 1.1047645\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 37: training/model.ckpt-37\n",
            "I1213 05:37:26.478249 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 37: training/model.ckpt-37\n",
            "INFO:tensorflow:Saving checkpoints for 49 into training/model.ckpt.\n",
            "I1213 05:47:05.115477 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 49 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 05:47:07.413921 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 05:47:07.414980 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 05:47:07.415131 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463a5dc940>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 05:47:07.465390 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463a5dc940>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463a4168c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 05:47:07.652925 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463a4168c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 05:47:08.225774 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 05:47:09.664701 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 05:47:09.807574 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 05:47:09.808012 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 05:47:10.902549 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 05:47:10.921909 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 05:47:13.065173 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T05:47:13Z\n",
            "I1213 05:47:13.081797 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T05:47:13Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 05:47:13.542167 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-49\n",
            "I1213 05:47:13.543691 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-49\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 05:47:14.518349 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 05:47:14.690513 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 05:47:32.567467 139939724338944 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 05:47:32.567859 139939724338944 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 05:47:32.568444 139939724338944 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.005\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.002\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.237\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.237\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-05:47:34\n",
            "I1213 05:47:34.164314 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-05:47:34\n",
            "INFO:tensorflow:Saving dict for global step 49: DetectionBoxes_Precision/mAP = 0.0016331096, DetectionBoxes_Precision/mAP (large) = 0.0022494663, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.005408723, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.2375, DetectionBoxes_Recall/AR@100 (large) = 0.2375, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.14022335, Loss/BoxClassifierLoss/localization_loss = 0.12234184, Loss/RPNLoss/localization_loss = 0.20109221, Loss/RPNLoss/objectness_loss = 0.5507944, Loss/total_loss = 1.0144519, global_step = 49, learning_rate = 0.0002, loss = 1.0144519\n",
            "I1213 05:47:34.164668 139941885183872 estimator.py:2049] Saving dict for global step 49: DetectionBoxes_Precision/mAP = 0.0016331096, DetectionBoxes_Precision/mAP (large) = 0.0022494663, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.005408723, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.2375, DetectionBoxes_Recall/AR@100 (large) = 0.2375, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.14022335, Loss/BoxClassifierLoss/localization_loss = 0.12234184, Loss/RPNLoss/localization_loss = 0.20109221, Loss/RPNLoss/objectness_loss = 0.5507944, Loss/total_loss = 1.0144519, global_step = 49, learning_rate = 0.0002, loss = 1.0144519\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 49: training/model.ckpt-49\n",
            "I1213 05:47:34.169877 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 49: training/model.ckpt-49\n",
            "INFO:tensorflow:Saving checkpoints for 61 into training/model.ckpt.\n",
            "I1213 05:57:13.144836 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 61 into training/model.ckpt.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "W1213 05:57:13.300401 139941885183872 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 05:57:15.507726 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 05:57:15.508924 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 05:57:15.509068 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463ac28c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 05:57:15.558366 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463ac28c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463ac3c2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 05:57:15.757868 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463ac3c2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 05:57:16.344602 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 05:57:17.758205 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 05:57:17.909209 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 05:57:17.909650 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 05:57:18.987030 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 05:57:19.004090 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 05:57:20.706550 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T05:57:20Z\n",
            "I1213 05:57:20.723479 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T05:57:20Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 05:57:21.179704 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-61\n",
            "I1213 05:57:21.181230 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-61\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 05:57:22.172471 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 05:57:22.351295 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 05:57:40.232621 139939732731648 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 05:57:40.232979 139939732731648 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 05:57:40.233707 139939732731648 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.006\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.003\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.287\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.287\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-05:57:41\n",
            "I1213 05:57:41.764792 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-05:57:41\n",
            "INFO:tensorflow:Saving dict for global step 61: DetectionBoxes_Precision/mAP = 0.0023523762, DetectionBoxes_Precision/mAP (large) = 0.0032619466, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0058667497, DetectionBoxes_Precision/mAP@.75IOU = 0.0002785993, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.2875, DetectionBoxes_Recall/AR@100 (large) = 0.2875, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.13657619, Loss/BoxClassifierLoss/localization_loss = 0.14254451, Loss/RPNLoss/localization_loss = 0.20207812, Loss/RPNLoss/objectness_loss = 0.45323393, Loss/total_loss = 0.9344328, global_step = 61, learning_rate = 0.0002, loss = 0.9344328\n",
            "I1213 05:57:41.765098 139941885183872 estimator.py:2049] Saving dict for global step 61: DetectionBoxes_Precision/mAP = 0.0023523762, DetectionBoxes_Precision/mAP (large) = 0.0032619466, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0058667497, DetectionBoxes_Precision/mAP@.75IOU = 0.0002785993, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.2875, DetectionBoxes_Recall/AR@100 (large) = 0.2875, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.13657619, Loss/BoxClassifierLoss/localization_loss = 0.14254451, Loss/RPNLoss/localization_loss = 0.20207812, Loss/RPNLoss/objectness_loss = 0.45323393, Loss/total_loss = 0.9344328, global_step = 61, learning_rate = 0.0002, loss = 0.9344328\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 61: training/model.ckpt-61\n",
            "I1213 05:57:41.770428 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 61: training/model.ckpt-61\n",
            "INFO:tensorflow:Saving checkpoints for 73 into training/model.ckpt.\n",
            "I1213 06:07:20.494767 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 73 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 06:07:22.793769 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 06:07:22.794707 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 06:07:22.794838 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463b2329e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 06:07:22.840872 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463b2329e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463b2a7b70> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 06:07:23.032477 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463b2a7b70> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 06:07:23.633227 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 06:07:25.056897 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 06:07:25.207981 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 06:07:25.208430 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 06:07:26.773232 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 06:07:26.791289 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 06:07:28.504383 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T06:07:28Z\n",
            "I1213 06:07:28.521000 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T06:07:28Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 06:07:28.965166 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-73\n",
            "I1213 06:07:28.966900 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-73\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 06:07:29.959843 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 06:07:30.147090 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 06:07:48.071357 139939732731648 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 06:07:48.071760 139939732731648 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 06:07:48.072464 139939732731648 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.023\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.008\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.087\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.212\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.212\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.212\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-06:07:49\n",
            "I1213 06:07:49.686266 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-06:07:49\n",
            "INFO:tensorflow:Saving dict for global step 73: DetectionBoxes_Precision/mAP = 0.0070821834, DetectionBoxes_Precision/mAP (large) = 0.00838825, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.023435814, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0875, DetectionBoxes_Recall/AR@10 = 0.2125, DetectionBoxes_Recall/AR@100 = 0.2125, DetectionBoxes_Recall/AR@100 (large) = 0.2125, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.14363089, Loss/BoxClassifierLoss/localization_loss = 0.17264178, Loss/RPNLoss/localization_loss = 0.21784675, Loss/RPNLoss/objectness_loss = 0.37601778, Loss/total_loss = 0.9101371, global_step = 73, learning_rate = 0.0002, loss = 0.9101371\n",
            "I1213 06:07:49.686572 139941885183872 estimator.py:2049] Saving dict for global step 73: DetectionBoxes_Precision/mAP = 0.0070821834, DetectionBoxes_Precision/mAP (large) = 0.00838825, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.023435814, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0875, DetectionBoxes_Recall/AR@10 = 0.2125, DetectionBoxes_Recall/AR@100 = 0.2125, DetectionBoxes_Recall/AR@100 (large) = 0.2125, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.14363089, Loss/BoxClassifierLoss/localization_loss = 0.17264178, Loss/RPNLoss/localization_loss = 0.21784675, Loss/RPNLoss/objectness_loss = 0.37601778, Loss/total_loss = 0.9101371, global_step = 73, learning_rate = 0.0002, loss = 0.9101371\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 73: training/model.ckpt-73\n",
            "I1213 06:07:49.692494 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 73: training/model.ckpt-73\n",
            "INFO:tensorflow:Saving checkpoints for 85 into training/model.ckpt.\n",
            "I1213 06:17:28.888516 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 85 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 06:17:31.194124 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 06:17:31.195138 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 06:17:31.195279 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463b27fe10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 06:17:31.244134 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463b27fe10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463b2492f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 06:17:31.434717 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463b2492f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 06:17:32.034975 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 06:17:33.444208 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 06:17:33.583791 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 06:17:33.584239 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 06:17:34.651999 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 06:17:34.668715 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 06:17:36.390763 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T06:17:36Z\n",
            "I1213 06:17:36.408146 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T06:17:36Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 06:17:36.869551 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-85\n",
            "I1213 06:17:36.871052 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-85\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 06:17:37.846518 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 06:17:38.013398 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 06:17:55.964034 139939724338944 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 06:17:55.964462 139939724338944 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 06:17:55.965224 139939724338944 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.012\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.048\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.014\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.075\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.237\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.250\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.250\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-06:17:57\n",
            "I1213 06:17:57.508445 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-06:17:57\n",
            "INFO:tensorflow:Saving dict for global step 85: DetectionBoxes_Precision/mAP = 0.0116252685, DetectionBoxes_Precision/mAP (large) = 0.013596649, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.047762338, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.075, DetectionBoxes_Recall/AR@10 = 0.2375, DetectionBoxes_Recall/AR@100 = 0.25, DetectionBoxes_Recall/AR@100 (large) = 0.25, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.12816235, Loss/BoxClassifierLoss/localization_loss = 0.17534152, Loss/RPNLoss/localization_loss = 0.24029188, Loss/RPNLoss/objectness_loss = 0.32765988, Loss/total_loss = 0.87145567, global_step = 85, learning_rate = 0.0002, loss = 0.87145567\n",
            "I1213 06:17:57.508765 139941885183872 estimator.py:2049] Saving dict for global step 85: DetectionBoxes_Precision/mAP = 0.0116252685, DetectionBoxes_Precision/mAP (large) = 0.013596649, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.047762338, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.075, DetectionBoxes_Recall/AR@10 = 0.2375, DetectionBoxes_Recall/AR@100 = 0.25, DetectionBoxes_Recall/AR@100 (large) = 0.25, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.12816235, Loss/BoxClassifierLoss/localization_loss = 0.17534152, Loss/RPNLoss/localization_loss = 0.24029188, Loss/RPNLoss/objectness_loss = 0.32765988, Loss/total_loss = 0.87145567, global_step = 85, learning_rate = 0.0002, loss = 0.87145567\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 85: training/model.ckpt-85\n",
            "I1213 06:17:57.514132 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 85: training/model.ckpt-85\n",
            "INFO:tensorflow:Saving checkpoints for 97 into training/model.ckpt.\n",
            "I1213 06:27:37.485658 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 97 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 06:27:39.767498 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 06:27:39.768782 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 06:27:39.768935 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f46368c19e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 06:27:39.816838 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f46368c19e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f4637ca2b70> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 06:27:40.010385 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f4637ca2b70> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 06:27:40.606463 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 06:27:42.496486 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 06:27:42.641449 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 06:27:42.641973 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 06:27:43.755635 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 06:27:43.774077 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 06:27:45.487884 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T06:27:45Z\n",
            "I1213 06:27:45.504967 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T06:27:45Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 06:27:45.955234 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-97\n",
            "I1213 06:27:45.956869 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-97\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 06:27:46.960993 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 06:27:47.146066 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 06:28:05.113381 139939732731648 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 06:28:05.113755 139939732731648 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 06:28:05.114414 139939732731648 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.020\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.056\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.005\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.021\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.150\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.312\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.312\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.312\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-06:28:06\n",
            "I1213 06:28:06.634161 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-06:28:06\n",
            "INFO:tensorflow:Saving dict for global step 97: DetectionBoxes_Precision/mAP = 0.019637454, DetectionBoxes_Precision/mAP (large) = 0.020685052, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.05633519, DetectionBoxes_Precision/mAP@.75IOU = 0.004767143, DetectionBoxes_Recall/AR@1 = 0.15, DetectionBoxes_Recall/AR@10 = 0.3125, DetectionBoxes_Recall/AR@100 = 0.3125, DetectionBoxes_Recall/AR@100 (large) = 0.3125, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.11386523, Loss/BoxClassifierLoss/localization_loss = 0.1475913, Loss/RPNLoss/localization_loss = 0.26839504, Loss/RPNLoss/objectness_loss = 0.30209118, Loss/total_loss = 0.83194274, global_step = 97, learning_rate = 0.0002, loss = 0.83194274\n",
            "I1213 06:28:06.634491 139941885183872 estimator.py:2049] Saving dict for global step 97: DetectionBoxes_Precision/mAP = 0.019637454, DetectionBoxes_Precision/mAP (large) = 0.020685052, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.05633519, DetectionBoxes_Precision/mAP@.75IOU = 0.004767143, DetectionBoxes_Recall/AR@1 = 0.15, DetectionBoxes_Recall/AR@10 = 0.3125, DetectionBoxes_Recall/AR@100 = 0.3125, DetectionBoxes_Recall/AR@100 (large) = 0.3125, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.11386523, Loss/BoxClassifierLoss/localization_loss = 0.1475913, Loss/RPNLoss/localization_loss = 0.26839504, Loss/RPNLoss/objectness_loss = 0.30209118, Loss/total_loss = 0.83194274, global_step = 97, learning_rate = 0.0002, loss = 0.83194274\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 97: training/model.ckpt-97\n",
            "I1213 06:28:06.639507 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 97: training/model.ckpt-97\n",
            "INFO:tensorflow:global_step/sec: 0.0197494\n",
            "I1213 06:31:19.803042 139941885183872 basic_session_run_hooks.py:692] global_step/sec: 0.0197494\n",
            "INFO:tensorflow:loss = 0.48825997, step = 101 (5063.435 sec)\n",
            "I1213 06:31:19.804032 139941885183872 basic_session_run_hooks.py:260] loss = 0.48825997, step = 101 (5063.435 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 109 into training/model.ckpt.\n",
            "I1213 06:37:46.335892 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 109 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 06:37:48.630717 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 06:37:48.631639 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 06:37:48.631772 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463b873e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 06:37:48.676962 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463b873e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463b8826a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 06:37:48.866700 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463b8826a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 06:37:49.455472 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 06:37:50.873588 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 06:37:51.017231 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 06:37:51.017645 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 06:37:52.119938 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 06:37:52.138437 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 06:37:53.850326 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T06:37:53Z\n",
            "I1213 06:37:53.867657 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T06:37:53Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 06:37:54.653176 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-109\n",
            "I1213 06:37:54.654831 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-109\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 06:37:55.736805 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 06:37:55.924323 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 06:38:13.894490 139939732731648 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 06:38:13.895048 139939732731648 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 06:38:13.895851 139939732731648 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.028\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.068\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.003\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.028\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.225\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.287\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.287\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.287\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-06:38:15\n",
            "I1213 06:38:15.451076 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-06:38:15\n",
            "INFO:tensorflow:Saving dict for global step 109: DetectionBoxes_Precision/mAP = 0.027823523, DetectionBoxes_Precision/mAP (large) = 0.027823523, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.06812802, DetectionBoxes_Precision/mAP@.75IOU = 0.0034787261, DetectionBoxes_Recall/AR@1 = 0.225, DetectionBoxes_Recall/AR@10 = 0.2875, DetectionBoxes_Recall/AR@100 = 0.2875, DetectionBoxes_Recall/AR@100 (large) = 0.2875, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.122849554, Loss/BoxClassifierLoss/localization_loss = 0.14242247, Loss/RPNLoss/localization_loss = 0.28946868, Loss/RPNLoss/objectness_loss = 0.28955096, Loss/total_loss = 0.84429157, global_step = 109, learning_rate = 0.0002, loss = 0.84429157\n",
            "I1213 06:38:15.451452 139941885183872 estimator.py:2049] Saving dict for global step 109: DetectionBoxes_Precision/mAP = 0.027823523, DetectionBoxes_Precision/mAP (large) = 0.027823523, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.06812802, DetectionBoxes_Precision/mAP@.75IOU = 0.0034787261, DetectionBoxes_Recall/AR@1 = 0.225, DetectionBoxes_Recall/AR@10 = 0.2875, DetectionBoxes_Recall/AR@100 = 0.2875, DetectionBoxes_Recall/AR@100 (large) = 0.2875, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.122849554, Loss/BoxClassifierLoss/localization_loss = 0.14242247, Loss/RPNLoss/localization_loss = 0.28946868, Loss/RPNLoss/objectness_loss = 0.28955096, Loss/total_loss = 0.84429157, global_step = 109, learning_rate = 0.0002, loss = 0.84429157\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 109: training/model.ckpt-109\n",
            "I1213 06:38:15.456875 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 109: training/model.ckpt-109\n",
            "INFO:tensorflow:Saving checkpoints for 121 into training/model.ckpt.\n",
            "I1213 06:47:56.974982 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 121 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 06:47:59.305676 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 06:47:59.307895 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 06:47:59.308054 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463aa38390>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 06:47:59.358826 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463aa38390>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463adc9ae8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 06:47:59.554846 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463adc9ae8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 06:48:00.148415 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 06:48:01.590245 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 06:48:01.731364 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 06:48:01.731786 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 06:48:02.855523 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 06:48:02.874044 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 06:48:04.594509 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T06:48:04Z\n",
            "I1213 06:48:04.611362 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T06:48:04Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 06:48:05.062870 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-121\n",
            "I1213 06:48:05.064379 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-121\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 06:48:06.079388 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 06:48:06.253789 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 06:48:24.205382 139939732731648 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 06:48:24.205804 139939732731648 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 06:48:24.206562 139939732731648 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.048\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.129\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.048\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.200\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.300\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.300\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.300\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-06:48:25\n",
            "I1213 06:48:25.780455 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-06:48:25\n",
            "INFO:tensorflow:Saving dict for global step 121: DetectionBoxes_Precision/mAP = 0.047806237, DetectionBoxes_Precision/mAP (large) = 0.047806237, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.12942009, DetectionBoxes_Precision/mAP@.75IOU = 0.0018928363, DetectionBoxes_Recall/AR@1 = 0.2, DetectionBoxes_Recall/AR@10 = 0.3, DetectionBoxes_Recall/AR@100 = 0.3, DetectionBoxes_Recall/AR@100 (large) = 0.3, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.10514381, Loss/BoxClassifierLoss/localization_loss = 0.14619836, Loss/RPNLoss/localization_loss = 0.3031319, Loss/RPNLoss/objectness_loss = 0.27293685, Loss/total_loss = 0.82741094, global_step = 121, learning_rate = 0.0002, loss = 0.82741094\n",
            "I1213 06:48:25.780778 139941885183872 estimator.py:2049] Saving dict for global step 121: DetectionBoxes_Precision/mAP = 0.047806237, DetectionBoxes_Precision/mAP (large) = 0.047806237, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.12942009, DetectionBoxes_Precision/mAP@.75IOU = 0.0018928363, DetectionBoxes_Recall/AR@1 = 0.2, DetectionBoxes_Recall/AR@10 = 0.3, DetectionBoxes_Recall/AR@100 = 0.3, DetectionBoxes_Recall/AR@100 (large) = 0.3, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.10514381, Loss/BoxClassifierLoss/localization_loss = 0.14619836, Loss/RPNLoss/localization_loss = 0.3031319, Loss/RPNLoss/objectness_loss = 0.27293685, Loss/total_loss = 0.82741094, global_step = 121, learning_rate = 0.0002, loss = 0.82741094\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 121: training/model.ckpt-121\n",
            "I1213 06:48:25.785857 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 121: training/model.ckpt-121\n",
            "INFO:tensorflow:Saving checkpoints for 133 into training/model.ckpt.\n",
            "I1213 06:58:06.427614 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 133 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 06:58:08.679555 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 06:58:08.680848 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 06:58:08.681009 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f4637eed9b0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 06:58:08.728197 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f4637eed9b0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f4637ece6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 06:58:08.924642 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f4637ece6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 06:58:09.551923 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 06:58:11.066966 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 06:58:11.225268 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 06:58:11.225744 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 06:58:12.334442 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 06:58:12.352941 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 06:58:14.554424 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T06:58:14Z\n",
            "I1213 06:58:14.571979 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T06:58:14Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 06:58:15.028448 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-133\n",
            "I1213 06:58:15.030195 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-133\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 06:58:16.069098 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 06:58:16.250730 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 06:58:34.330329 139939724338944 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 06:58:34.330728 139939724338944 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 06:58:34.331409 139939724338944 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.054\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.113\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.055\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.054\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.225\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.350\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.350\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.350\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-06:58:35\n",
            "I1213 06:58:35.942600 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-06:58:35\n",
            "INFO:tensorflow:Saving dict for global step 133: DetectionBoxes_Precision/mAP = 0.05427602, DetectionBoxes_Precision/mAP (large) = 0.05436179, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.11307646, DetectionBoxes_Precision/mAP@.75IOU = 0.054925058, DetectionBoxes_Recall/AR@1 = 0.225, DetectionBoxes_Recall/AR@10 = 0.35, DetectionBoxes_Recall/AR@100 = 0.35, DetectionBoxes_Recall/AR@100 (large) = 0.35, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.09742362, Loss/BoxClassifierLoss/localization_loss = 0.14507145, Loss/RPNLoss/localization_loss = 0.313038, Loss/RPNLoss/objectness_loss = 0.27702546, Loss/total_loss = 0.8325585, global_step = 133, learning_rate = 0.0002, loss = 0.8325585\n",
            "I1213 06:58:35.942975 139941885183872 estimator.py:2049] Saving dict for global step 133: DetectionBoxes_Precision/mAP = 0.05427602, DetectionBoxes_Precision/mAP (large) = 0.05436179, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.11307646, DetectionBoxes_Precision/mAP@.75IOU = 0.054925058, DetectionBoxes_Recall/AR@1 = 0.225, DetectionBoxes_Recall/AR@10 = 0.35, DetectionBoxes_Recall/AR@100 = 0.35, DetectionBoxes_Recall/AR@100 (large) = 0.35, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.09742362, Loss/BoxClassifierLoss/localization_loss = 0.14507145, Loss/RPNLoss/localization_loss = 0.313038, Loss/RPNLoss/objectness_loss = 0.27702546, Loss/total_loss = 0.8325585, global_step = 133, learning_rate = 0.0002, loss = 0.8325585\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 133: training/model.ckpt-133\n",
            "I1213 06:58:35.948335 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 133: training/model.ckpt-133\n",
            "INFO:tensorflow:Saving checkpoints for 145 into training/model.ckpt.\n",
            "I1213 07:08:16.381327 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 145 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 07:08:18.682283 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 07:08:18.683550 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 07:08:18.683720 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f4637c3ac18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 07:08:18.744256 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f4637c3ac18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f4637c2a2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 07:08:18.932581 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f4637c2a2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 07:08:19.536257 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 07:08:20.975490 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 07:08:21.117124 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 07:08:21.117548 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 07:08:22.231082 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 07:08:22.249330 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 07:08:23.944341 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T07:08:23Z\n",
            "I1213 07:08:23.961632 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T07:08:23Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 07:08:24.408540 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-145\n",
            "I1213 07:08:24.410062 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-145\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 07:08:25.392051 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 07:08:25.561036 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 07:08:43.639542 139939724338944 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 07:08:43.639997 139939724338944 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 07:08:43.640882 139939724338944 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.069\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.186\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.069\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.212\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.287\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.287\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.287\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-07:08:45\n",
            "I1213 07:08:45.169259 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-07:08:45\n",
            "INFO:tensorflow:Saving dict for global step 145: DetectionBoxes_Precision/mAP = 0.069398336, DetectionBoxes_Precision/mAP (large) = 0.069398336, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.18567269, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.2125, DetectionBoxes_Recall/AR@10 = 0.2875, DetectionBoxes_Recall/AR@100 = 0.2875, DetectionBoxes_Recall/AR@100 (large) = 0.2875, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.10306438, Loss/BoxClassifierLoss/localization_loss = 0.11999397, Loss/RPNLoss/localization_loss = 0.31844848, Loss/RPNLoss/objectness_loss = 0.27786613, Loss/total_loss = 0.81937295, global_step = 145, learning_rate = 0.0002, loss = 0.81937295\n",
            "I1213 07:08:45.169633 139941885183872 estimator.py:2049] Saving dict for global step 145: DetectionBoxes_Precision/mAP = 0.069398336, DetectionBoxes_Precision/mAP (large) = 0.069398336, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.18567269, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.2125, DetectionBoxes_Recall/AR@10 = 0.2875, DetectionBoxes_Recall/AR@100 = 0.2875, DetectionBoxes_Recall/AR@100 (large) = 0.2875, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.10306438, Loss/BoxClassifierLoss/localization_loss = 0.11999397, Loss/RPNLoss/localization_loss = 0.31844848, Loss/RPNLoss/objectness_loss = 0.27786613, Loss/total_loss = 0.81937295, global_step = 145, learning_rate = 0.0002, loss = 0.81937295\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 145: training/model.ckpt-145\n",
            "I1213 07:08:45.175198 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 145: training/model.ckpt-145\n",
            "INFO:tensorflow:Saving checkpoints for 157 into training/model.ckpt.\n",
            "I1213 07:18:26.199208 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 157 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 07:18:28.470771 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 07:18:28.471969 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 07:18:28.472135 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f4637d38940>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 07:18:28.518554 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f4637d38940>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f46388d98c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 07:18:28.709455 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f46388d98c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 07:18:29.299121 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 07:18:30.755999 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 07:18:30.901602 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 07:18:30.902039 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 07:18:31.998354 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 07:18:32.016616 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 07:18:34.153714 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T07:18:34Z\n",
            "I1213 07:18:34.170524 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T07:18:34Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 07:18:34.623574 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-157\n",
            "I1213 07:18:34.625090 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-157\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 07:18:35.657469 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 07:18:35.847026 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 07:18:53.862969 139939724338944 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 07:18:53.863523 139939724338944 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 07:18:53.864236 139939724338944 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.064\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.193\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.064\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.188\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.275\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.275\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.275\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-07:18:55\n",
            "I1213 07:18:55.459545 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-07:18:55\n",
            "INFO:tensorflow:Saving dict for global step 157: DetectionBoxes_Precision/mAP = 0.064004764, DetectionBoxes_Precision/mAP (large) = 0.064004764, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.19265677, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.1875, DetectionBoxes_Recall/AR@10 = 0.275, DetectionBoxes_Recall/AR@100 = 0.275, DetectionBoxes_Recall/AR@100 (large) = 0.275, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.0885434, Loss/BoxClassifierLoss/localization_loss = 0.11659171, Loss/RPNLoss/localization_loss = 0.3271718, Loss/RPNLoss/objectness_loss = 0.27466887, Loss/total_loss = 0.8069757, global_step = 157, learning_rate = 0.0002, loss = 0.8069757\n",
            "I1213 07:18:55.459874 139941885183872 estimator.py:2049] Saving dict for global step 157: DetectionBoxes_Precision/mAP = 0.064004764, DetectionBoxes_Precision/mAP (large) = 0.064004764, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.19265677, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.1875, DetectionBoxes_Recall/AR@10 = 0.275, DetectionBoxes_Recall/AR@100 = 0.275, DetectionBoxes_Recall/AR@100 (large) = 0.275, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.0885434, Loss/BoxClassifierLoss/localization_loss = 0.11659171, Loss/RPNLoss/localization_loss = 0.3271718, Loss/RPNLoss/objectness_loss = 0.27466887, Loss/total_loss = 0.8069757, global_step = 157, learning_rate = 0.0002, loss = 0.8069757\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 157: training/model.ckpt-157\n",
            "I1213 07:18:55.465273 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 157: training/model.ckpt-157\n",
            "INFO:tensorflow:Saving checkpoints for 169 into training/model.ckpt.\n",
            "I1213 07:28:36.709877 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 169 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 07:28:39.027215 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 07:28:39.028085 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 07:28:39.028254 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f46380a0c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 07:28:39.074509 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f46380a0c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463808b2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 07:28:39.273293 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463808b2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 07:28:39.863940 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 07:28:41.304993 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 07:28:41.447644 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 07:28:41.448073 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 07:28:42.589349 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 07:28:42.607134 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 07:28:44.298887 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T07:28:44Z\n",
            "I1213 07:28:44.316199 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T07:28:44Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 07:28:44.765195 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-169\n",
            "I1213 07:28:44.766882 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-169\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 07:28:45.789398 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 07:28:45.963121 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 07:29:03.894144 139939732731648 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 07:29:03.895688 139939732731648 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 07:29:03.896513 139939732731648 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.046\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.126\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.025\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.046\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.163\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.350\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.350\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.350\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-07:29:05\n",
            "I1213 07:29:05.458614 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-07:29:05\n",
            "INFO:tensorflow:Saving dict for global step 169: DetectionBoxes_Precision/mAP = 0.04578965, DetectionBoxes_Precision/mAP (large) = 0.04578965, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.12587388, DetectionBoxes_Precision/mAP@.75IOU = 0.02459846, DetectionBoxes_Recall/AR@1 = 0.1625, DetectionBoxes_Recall/AR@10 = 0.35, DetectionBoxes_Recall/AR@100 = 0.35, DetectionBoxes_Recall/AR@100 (large) = 0.35, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.098238215, Loss/BoxClassifierLoss/localization_loss = 0.12958759, Loss/RPNLoss/localization_loss = 0.32370463, Loss/RPNLoss/objectness_loss = 0.28036484, Loss/total_loss = 0.8318954, global_step = 169, learning_rate = 0.0002, loss = 0.8318954\n",
            "I1213 07:29:05.458930 139941885183872 estimator.py:2049] Saving dict for global step 169: DetectionBoxes_Precision/mAP = 0.04578965, DetectionBoxes_Precision/mAP (large) = 0.04578965, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.12587388, DetectionBoxes_Precision/mAP@.75IOU = 0.02459846, DetectionBoxes_Recall/AR@1 = 0.1625, DetectionBoxes_Recall/AR@10 = 0.35, DetectionBoxes_Recall/AR@100 = 0.35, DetectionBoxes_Recall/AR@100 (large) = 0.35, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.098238215, Loss/BoxClassifierLoss/localization_loss = 0.12958759, Loss/RPNLoss/localization_loss = 0.32370463, Loss/RPNLoss/objectness_loss = 0.28036484, Loss/total_loss = 0.8318954, global_step = 169, learning_rate = 0.0002, loss = 0.8318954\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 169: training/model.ckpt-169\n",
            "I1213 07:29:05.464137 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 169: training/model.ckpt-169\n",
            "INFO:tensorflow:Saving checkpoints for 181 into training/model.ckpt.\n",
            "I1213 07:38:46.554660 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 181 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 07:38:48.853653 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 07:38:48.854918 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 07:38:48.855065 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f46381b19e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 07:38:48.909560 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f46381b19e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f4638225c80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 07:38:49.105036 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f4638225c80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 07:38:49.710650 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 07:38:51.611047 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 07:38:51.774684 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 07:38:51.775156 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 07:38:52.831539 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 07:38:52.849984 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 07:38:54.567845 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T07:38:54Z\n",
            "I1213 07:38:54.585435 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T07:38:54Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 07:38:55.050412 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-181\n",
            "I1213 07:38:55.052080 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-181\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 07:38:56.060513 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 07:38:56.237915 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 07:39:14.376347 139939732731648 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 07:39:14.376727 139939732731648 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 07:39:14.377484 139939732731648 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.054\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.144\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.051\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.054\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.200\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.338\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.338\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.338\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-07:39:15\n",
            "I1213 07:39:15.925149 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-07:39:15\n",
            "INFO:tensorflow:Saving dict for global step 181: DetectionBoxes_Precision/mAP = 0.054154832, DetectionBoxes_Precision/mAP (large) = 0.054154832, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.14370996, DetectionBoxes_Precision/mAP@.75IOU = 0.05130513, DetectionBoxes_Recall/AR@1 = 0.2, DetectionBoxes_Recall/AR@10 = 0.3375, DetectionBoxes_Recall/AR@100 = 0.3375, DetectionBoxes_Recall/AR@100 (large) = 0.3375, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.16726513, Loss/BoxClassifierLoss/localization_loss = 0.1361958, Loss/RPNLoss/localization_loss = 0.327314, Loss/RPNLoss/objectness_loss = 0.29318315, Loss/total_loss = 0.923958, global_step = 181, learning_rate = 0.0002, loss = 0.923958\n",
            "I1213 07:39:15.925480 139941885183872 estimator.py:2049] Saving dict for global step 181: DetectionBoxes_Precision/mAP = 0.054154832, DetectionBoxes_Precision/mAP (large) = 0.054154832, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.14370996, DetectionBoxes_Precision/mAP@.75IOU = 0.05130513, DetectionBoxes_Recall/AR@1 = 0.2, DetectionBoxes_Recall/AR@10 = 0.3375, DetectionBoxes_Recall/AR@100 = 0.3375, DetectionBoxes_Recall/AR@100 (large) = 0.3375, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.16726513, Loss/BoxClassifierLoss/localization_loss = 0.1361958, Loss/RPNLoss/localization_loss = 0.327314, Loss/RPNLoss/objectness_loss = 0.29318315, Loss/total_loss = 0.923958, global_step = 181, learning_rate = 0.0002, loss = 0.923958\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 181: training/model.ckpt-181\n",
            "I1213 07:39:15.931809 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 181: training/model.ckpt-181\n",
            "INFO:tensorflow:Saving checkpoints for 193 into training/model.ckpt.\n",
            "I1213 07:48:59.538094 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 193 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 07:49:01.879620 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 07:49:01.880672 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 07:49:01.880805 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463b92be10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 07:49:01.928586 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463b92be10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463b9312f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 07:49:02.120156 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463b9312f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 07:49:02.727965 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 07:49:04.195983 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 07:49:04.340558 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 07:49:04.341044 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 07:49:05.446041 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 07:49:05.466317 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 07:49:07.252862 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T07:49:07Z\n",
            "I1213 07:49:07.270250 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T07:49:07Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 07:49:07.717768 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-193\n",
            "I1213 07:49:07.719325 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-193\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 07:49:08.760348 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 07:49:08.943694 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 07:49:27.128420 139939724338944 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 07:49:27.128956 139939724338944 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 07:49:27.129740 139939724338944 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.051\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.116\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.037\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.051\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.075\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.312\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.312\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.312\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-07:49:28\n",
            "I1213 07:49:28.713446 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-07:49:28\n",
            "INFO:tensorflow:Saving dict for global step 193: DetectionBoxes_Precision/mAP = 0.050919376, DetectionBoxes_Precision/mAP (large) = 0.050919376, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.11584158, DetectionBoxes_Precision/mAP@.75IOU = 0.036775105, DetectionBoxes_Recall/AR@1 = 0.075, DetectionBoxes_Recall/AR@10 = 0.3125, DetectionBoxes_Recall/AR@100 = 0.3125, DetectionBoxes_Recall/AR@100 (large) = 0.3125, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.12889583, Loss/BoxClassifierLoss/localization_loss = 0.14505419, Loss/RPNLoss/localization_loss = 0.33494303, Loss/RPNLoss/objectness_loss = 0.28556994, Loss/total_loss = 0.89446306, global_step = 193, learning_rate = 0.0002, loss = 0.89446306\n",
            "I1213 07:49:28.713771 139941885183872 estimator.py:2049] Saving dict for global step 193: DetectionBoxes_Precision/mAP = 0.050919376, DetectionBoxes_Precision/mAP (large) = 0.050919376, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.11584158, DetectionBoxes_Precision/mAP@.75IOU = 0.036775105, DetectionBoxes_Recall/AR@1 = 0.075, DetectionBoxes_Recall/AR@10 = 0.3125, DetectionBoxes_Recall/AR@100 = 0.3125, DetectionBoxes_Recall/AR@100 (large) = 0.3125, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.12889583, Loss/BoxClassifierLoss/localization_loss = 0.14505419, Loss/RPNLoss/localization_loss = 0.33494303, Loss/RPNLoss/objectness_loss = 0.28556994, Loss/total_loss = 0.89446306, global_step = 193, learning_rate = 0.0002, loss = 0.89446306\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 193: training/model.ckpt-193\n",
            "I1213 07:49:28.719391 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 193: training/model.ckpt-193\n",
            "INFO:tensorflow:global_step/sec: 0.0196864\n",
            "I1213 07:55:59.462721 139941885183872 basic_session_run_hooks.py:692] global_step/sec: 0.0196864\n",
            "INFO:tensorflow:loss = 0.3296847, step = 201 (5079.660 sec)\n",
            "I1213 07:55:59.463645 139941885183872 basic_session_run_hooks.py:260] loss = 0.3296847, step = 201 (5079.660 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 205 into training/model.ckpt.\n",
            "I1213 07:59:14.832979 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 205 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 07:59:17.159631 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 07:59:17.160604 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 07:59:17.160739 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463aa399e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 07:59:17.208433 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463aa399e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463aaedb70> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 07:59:17.399539 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463aaedb70> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 07:59:18.444506 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 07:59:19.954667 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 07:59:20.126934 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 07:59:20.127391 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 07:59:21.207161 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 07:59:21.224080 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 07:59:22.919734 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T07:59:22Z\n",
            "I1213 07:59:22.937158 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T07:59:22Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 07:59:23.399391 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-205\n",
            "I1213 07:59:23.401096 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-205\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 07:59:24.408825 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 07:59:24.581901 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 07:59:42.818846 139939732731648 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 07:59:42.819247 139939732731648 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 07:59:42.819824 139939732731648 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.07s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.058\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.141\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.011\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.058\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.100\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.287\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.287\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.287\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-07:59:44\n",
            "I1213 07:59:44.378743 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-07:59:44\n",
            "INFO:tensorflow:Saving dict for global step 205: DetectionBoxes_Precision/mAP = 0.058309652, DetectionBoxes_Precision/mAP (large) = 0.058309652, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.14146991, DetectionBoxes_Precision/mAP@.75IOU = 0.010726073, DetectionBoxes_Recall/AR@1 = 0.1, DetectionBoxes_Recall/AR@10 = 0.2875, DetectionBoxes_Recall/AR@100 = 0.2875, DetectionBoxes_Recall/AR@100 (large) = 0.2875, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.16084456, Loss/BoxClassifierLoss/localization_loss = 0.14778842, Loss/RPNLoss/localization_loss = 0.3278042, Loss/RPNLoss/objectness_loss = 0.27546155, Loss/total_loss = 0.91189873, global_step = 205, learning_rate = 0.0002, loss = 0.91189873\n",
            "I1213 07:59:44.379094 139941885183872 estimator.py:2049] Saving dict for global step 205: DetectionBoxes_Precision/mAP = 0.058309652, DetectionBoxes_Precision/mAP (large) = 0.058309652, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.14146991, DetectionBoxes_Precision/mAP@.75IOU = 0.010726073, DetectionBoxes_Recall/AR@1 = 0.1, DetectionBoxes_Recall/AR@10 = 0.2875, DetectionBoxes_Recall/AR@100 = 0.2875, DetectionBoxes_Recall/AR@100 (large) = 0.2875, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.16084456, Loss/BoxClassifierLoss/localization_loss = 0.14778842, Loss/RPNLoss/localization_loss = 0.3278042, Loss/RPNLoss/objectness_loss = 0.27546155, Loss/total_loss = 0.91189873, global_step = 205, learning_rate = 0.0002, loss = 0.91189873\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 205: training/model.ckpt-205\n",
            "I1213 07:59:44.385092 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 205: training/model.ckpt-205\n",
            "INFO:tensorflow:Saving checkpoints for 217 into training/model.ckpt.\n",
            "I1213 08:09:26.582092 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 217 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 08:09:28.906897 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 08:09:28.907804 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 08:09:28.907943 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f4637fe37f0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 08:09:28.953467 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f4637fe37f0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f4637fea2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 08:09:29.148128 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f4637fea2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 08:09:29.748843 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 08:09:31.219171 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 08:09:31.366487 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 08:09:31.366934 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 08:09:32.448538 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 08:09:32.467168 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 08:09:34.496832 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T08:09:34Z\n",
            "I1213 08:09:34.513708 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T08:09:34Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 08:09:34.977041 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-217\n",
            "I1213 08:09:34.978688 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-217\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 08:09:35.967836 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 08:09:36.141001 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 08:09:54.258656 139939724338944 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 08:09:54.259261 139939724338944 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 08:09:54.260034 139939724338944 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.070\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.151\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.052\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.070\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.150\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.325\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.325\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.325\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-08:09:55\n",
            "I1213 08:09:55.807378 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-08:09:55\n",
            "INFO:tensorflow:Saving dict for global step 217: DetectionBoxes_Precision/mAP = 0.070434175, DetectionBoxes_Precision/mAP (large) = 0.070434175, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.15070912, DetectionBoxes_Precision/mAP@.75IOU = 0.051980197, DetectionBoxes_Recall/AR@1 = 0.15, DetectionBoxes_Recall/AR@10 = 0.325, DetectionBoxes_Recall/AR@100 = 0.325, DetectionBoxes_Recall/AR@100 (large) = 0.325, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.16216864, Loss/BoxClassifierLoss/localization_loss = 0.14837031, Loss/RPNLoss/localization_loss = 0.32889768, Loss/RPNLoss/objectness_loss = 0.28239098, Loss/total_loss = 0.9218276, global_step = 217, learning_rate = 0.0002, loss = 0.9218276\n",
            "I1213 08:09:55.807698 139941885183872 estimator.py:2049] Saving dict for global step 217: DetectionBoxes_Precision/mAP = 0.070434175, DetectionBoxes_Precision/mAP (large) = 0.070434175, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.15070912, DetectionBoxes_Precision/mAP@.75IOU = 0.051980197, DetectionBoxes_Recall/AR@1 = 0.15, DetectionBoxes_Recall/AR@10 = 0.325, DetectionBoxes_Recall/AR@100 = 0.325, DetectionBoxes_Recall/AR@100 (large) = 0.325, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.16216864, Loss/BoxClassifierLoss/localization_loss = 0.14837031, Loss/RPNLoss/localization_loss = 0.32889768, Loss/RPNLoss/objectness_loss = 0.28239098, Loss/total_loss = 0.9218276, global_step = 217, learning_rate = 0.0002, loss = 0.9218276\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 217: training/model.ckpt-217\n",
            "I1213 08:09:55.813235 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 217: training/model.ckpt-217\n",
            "INFO:tensorflow:Saving checkpoints for 229 into training/model.ckpt.\n",
            "I1213 08:19:39.482849 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 229 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 08:19:41.837780 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 08:19:41.839461 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 08:19:41.839621 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463a602a58>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 08:19:41.889887 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463a602a58>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463a5ed2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 08:19:42.087060 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463a5ed2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 08:19:42.676323 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 08:19:44.120144 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 08:19:44.267316 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 08:19:44.267742 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 08:19:45.374249 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 08:19:45.394538 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 08:19:47.120754 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T08:19:47Z\n",
            "I1213 08:19:47.137952 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T08:19:47Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 08:19:47.585810 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-229\n",
            "I1213 08:19:47.587487 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-229\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 08:19:48.522427 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 08:19:48.689973 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 08:20:06.661574 139939724338944 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 08:20:06.662035 139939724338944 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 08:20:06.662690 139939724338944 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.053\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.143\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.009\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.053\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.113\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.300\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.300\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.300\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-08:20:08\n",
            "I1213 08:20:08.218268 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-08:20:08\n",
            "INFO:tensorflow:Saving dict for global step 229: DetectionBoxes_Precision/mAP = 0.052563537, DetectionBoxes_Precision/mAP (large) = 0.052563537, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.14273928, DetectionBoxes_Precision/mAP@.75IOU = 0.009193776, DetectionBoxes_Recall/AR@1 = 0.1125, DetectionBoxes_Recall/AR@10 = 0.3, DetectionBoxes_Recall/AR@100 = 0.3, DetectionBoxes_Recall/AR@100 (large) = 0.3, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.10542913, Loss/BoxClassifierLoss/localization_loss = 0.12189245, Loss/RPNLoss/localization_loss = 0.32916397, Loss/RPNLoss/objectness_loss = 0.28132942, Loss/total_loss = 0.83781505, global_step = 229, learning_rate = 0.0002, loss = 0.83781505\n",
            "I1213 08:20:08.218617 139941885183872 estimator.py:2049] Saving dict for global step 229: DetectionBoxes_Precision/mAP = 0.052563537, DetectionBoxes_Precision/mAP (large) = 0.052563537, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.14273928, DetectionBoxes_Precision/mAP@.75IOU = 0.009193776, DetectionBoxes_Recall/AR@1 = 0.1125, DetectionBoxes_Recall/AR@10 = 0.3, DetectionBoxes_Recall/AR@100 = 0.3, DetectionBoxes_Recall/AR@100 (large) = 0.3, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.10542913, Loss/BoxClassifierLoss/localization_loss = 0.12189245, Loss/RPNLoss/localization_loss = 0.32916397, Loss/RPNLoss/objectness_loss = 0.28132942, Loss/total_loss = 0.83781505, global_step = 229, learning_rate = 0.0002, loss = 0.83781505\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 229: training/model.ckpt-229\n",
            "I1213 08:20:08.223931 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 229: training/model.ckpt-229\n",
            "INFO:tensorflow:Saving checkpoints for 241 into training/model.ckpt.\n",
            "I1213 08:29:50.460934 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 241 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 08:29:52.734700 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 08:29:52.736326 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 08:29:52.736474 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463ba70940>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 08:29:52.783636 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463ba70940>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f4637f1c8c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 08:29:52.977663 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f4637f1c8c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 08:29:53.586290 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 08:29:55.045619 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 08:29:55.202572 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 08:29:55.203060 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 08:29:56.295664 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 08:29:56.313424 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 08:29:58.483005 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T08:29:58Z\n",
            "I1213 08:29:58.500260 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T08:29:58Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 08:29:58.954499 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-241\n",
            "I1213 08:29:58.956322 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-241\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 08:30:00.001244 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 08:30:00.196935 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 08:30:18.295478 139939732731648 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 08:30:18.295885 139939732731648 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 08:30:18.296495 139939732731648 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.063\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.159\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.009\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.063\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.100\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.325\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.325\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.325\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-08:30:19\n",
            "I1213 08:30:19.873726 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-08:30:19\n",
            "INFO:tensorflow:Saving dict for global step 241: DetectionBoxes_Precision/mAP = 0.062646456, DetectionBoxes_Precision/mAP (large) = 0.062646456, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.15928999, DetectionBoxes_Precision/mAP@.75IOU = 0.008580858, DetectionBoxes_Recall/AR@1 = 0.1, DetectionBoxes_Recall/AR@10 = 0.325, DetectionBoxes_Recall/AR@100 = 0.325, DetectionBoxes_Recall/AR@100 (large) = 0.325, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.13644643, Loss/BoxClassifierLoss/localization_loss = 0.1497618, Loss/RPNLoss/localization_loss = 0.33550963, Loss/RPNLoss/objectness_loss = 0.27177894, Loss/total_loss = 0.8934969, global_step = 241, learning_rate = 0.0002, loss = 0.8934969\n",
            "I1213 08:30:19.874046 139941885183872 estimator.py:2049] Saving dict for global step 241: DetectionBoxes_Precision/mAP = 0.062646456, DetectionBoxes_Precision/mAP (large) = 0.062646456, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.15928999, DetectionBoxes_Precision/mAP@.75IOU = 0.008580858, DetectionBoxes_Recall/AR@1 = 0.1, DetectionBoxes_Recall/AR@10 = 0.325, DetectionBoxes_Recall/AR@100 = 0.325, DetectionBoxes_Recall/AR@100 (large) = 0.325, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.13644643, Loss/BoxClassifierLoss/localization_loss = 0.1497618, Loss/RPNLoss/localization_loss = 0.33550963, Loss/RPNLoss/objectness_loss = 0.27177894, Loss/total_loss = 0.8934969, global_step = 241, learning_rate = 0.0002, loss = 0.8934969\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 241: training/model.ckpt-241\n",
            "I1213 08:30:19.879337 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 241: training/model.ckpt-241\n",
            "INFO:tensorflow:Saving checkpoints for 253 into training/model.ckpt.\n",
            "I1213 08:40:01.757614 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 253 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 08:40:04.066814 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 08:40:04.070008 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 08:40:04.070251 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f46379d8be0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 08:40:04.117627 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f46379d8be0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f4637a012f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 08:40:04.323376 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f4637a012f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 08:40:04.922654 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 08:40:06.343667 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 08:40:06.499750 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 08:40:06.500196 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 08:40:07.616466 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 08:40:07.634494 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 08:40:09.361350 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T08:40:09Z\n",
            "I1213 08:40:09.378835 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T08:40:09Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 08:40:09.847951 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-253\n",
            "I1213 08:40:09.849455 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-253\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 08:40:10.844743 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 08:40:11.027460 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 08:40:28.982023 139939732731648 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 08:40:28.982431 139939732731648 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 08:40:28.983141 139939732731648 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.069\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.175\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.023\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.069\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.138\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.312\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.312\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.312\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-08:40:30\n",
            "I1213 08:40:30.525599 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-08:40:30\n",
            "INFO:tensorflow:Saving dict for global step 253: DetectionBoxes_Precision/mAP = 0.06927161, DetectionBoxes_Precision/mAP (large) = 0.06927161, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.17517136, DetectionBoxes_Precision/mAP@.75IOU = 0.02340234, DetectionBoxes_Recall/AR@1 = 0.1375, DetectionBoxes_Recall/AR@10 = 0.3125, DetectionBoxes_Recall/AR@100 = 0.3125, DetectionBoxes_Recall/AR@100 (large) = 0.3125, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.12064405, Loss/BoxClassifierLoss/localization_loss = 0.14664781, Loss/RPNLoss/localization_loss = 0.3298885, Loss/RPNLoss/objectness_loss = 0.26582026, Loss/total_loss = 0.8630005, global_step = 253, learning_rate = 0.0002, loss = 0.8630005\n",
            "I1213 08:40:30.525922 139941885183872 estimator.py:2049] Saving dict for global step 253: DetectionBoxes_Precision/mAP = 0.06927161, DetectionBoxes_Precision/mAP (large) = 0.06927161, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.17517136, DetectionBoxes_Precision/mAP@.75IOU = 0.02340234, DetectionBoxes_Recall/AR@1 = 0.1375, DetectionBoxes_Recall/AR@10 = 0.3125, DetectionBoxes_Recall/AR@100 = 0.3125, DetectionBoxes_Recall/AR@100 (large) = 0.3125, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.12064405, Loss/BoxClassifierLoss/localization_loss = 0.14664781, Loss/RPNLoss/localization_loss = 0.3298885, Loss/RPNLoss/objectness_loss = 0.26582026, Loss/total_loss = 0.8630005, global_step = 253, learning_rate = 0.0002, loss = 0.8630005\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 253: training/model.ckpt-253\n",
            "I1213 08:40:30.531043 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 253: training/model.ckpt-253\n",
            "INFO:tensorflow:Saving checkpoints for 265 into training/model.ckpt.\n",
            "I1213 08:50:12.248079 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 265 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 08:50:14.571709 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 08:50:14.573077 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 08:50:14.573255 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463ac919e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 08:50:14.620428 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463ac919e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463891fc80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 08:50:14.817059 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463891fc80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 08:50:15.416427 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 08:50:16.899193 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 08:50:17.048373 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 08:50:17.048792 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 08:50:18.580088 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 08:50:18.597295 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 08:50:20.317378 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T08:50:20Z\n",
            "I1213 08:50:20.338724 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T08:50:20Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 08:50:20.813142 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-265\n",
            "I1213 08:50:20.814922 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-265\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 08:50:21.767521 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 08:50:21.944894 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 08:50:39.955204 139939724338944 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 08:50:39.955576 139939724338944 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 08:50:39.956279 139939724338944 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.094\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.194\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.057\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.094\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.138\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.300\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.300\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.300\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-08:50:41\n",
            "I1213 08:50:41.542263 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-08:50:41\n",
            "INFO:tensorflow:Saving dict for global step 265: DetectionBoxes_Precision/mAP = 0.0940423, DetectionBoxes_Precision/mAP (large) = 0.0940423, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.19365172, DetectionBoxes_Precision/mAP@.75IOU = 0.05720572, DetectionBoxes_Recall/AR@1 = 0.1375, DetectionBoxes_Recall/AR@10 = 0.3, DetectionBoxes_Recall/AR@100 = 0.3, DetectionBoxes_Recall/AR@100 (large) = 0.3, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.10373449, Loss/BoxClassifierLoss/localization_loss = 0.123879425, Loss/RPNLoss/localization_loss = 0.33270153, Loss/RPNLoss/objectness_loss = 0.26634786, Loss/total_loss = 0.8266633, global_step = 265, learning_rate = 0.0002, loss = 0.8266633\n",
            "I1213 08:50:41.542580 139941885183872 estimator.py:2049] Saving dict for global step 265: DetectionBoxes_Precision/mAP = 0.0940423, DetectionBoxes_Precision/mAP (large) = 0.0940423, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.19365172, DetectionBoxes_Precision/mAP@.75IOU = 0.05720572, DetectionBoxes_Recall/AR@1 = 0.1375, DetectionBoxes_Recall/AR@10 = 0.3, DetectionBoxes_Recall/AR@100 = 0.3, DetectionBoxes_Recall/AR@100 (large) = 0.3, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.10373449, Loss/BoxClassifierLoss/localization_loss = 0.123879425, Loss/RPNLoss/localization_loss = 0.33270153, Loss/RPNLoss/objectness_loss = 0.26634786, Loss/total_loss = 0.8266633, global_step = 265, learning_rate = 0.0002, loss = 0.8266633\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 265: training/model.ckpt-265\n",
            "I1213 08:50:41.547515 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 265: training/model.ckpt-265\n",
            "INFO:tensorflow:Saving checkpoints for 277 into training/model.ckpt.\n",
            "I1213 09:00:23.411858 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 277 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 09:00:25.757080 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 09:00:25.758214 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 09:00:25.758349 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463b655e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 09:00:25.806779 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463b655e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463b6622f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 09:00:26.004131 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463b6622f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 09:00:26.608210 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 09:00:28.042024 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 09:00:28.190191 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 09:00:28.190665 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 09:00:29.302673 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 09:00:29.323480 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 09:00:31.067589 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T09:00:31Z\n",
            "I1213 09:00:31.085921 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T09:00:31Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 09:00:31.531348 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-277\n",
            "I1213 09:00:31.532940 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-277\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 09:00:32.477297 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 09:00:32.642690 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 09:00:50.549360 139939724338944 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 09:00:50.549754 139939724338944 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 09:00:50.550519 139939724338944 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.080\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.158\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.116\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.080\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.150\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.312\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.312\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.312\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-09:00:52\n",
            "I1213 09:00:52.149694 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-09:00:52\n",
            "INFO:tensorflow:Saving dict for global step 277: DetectionBoxes_Precision/mAP = 0.080308065, DetectionBoxes_Precision/mAP (large) = 0.08032069, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.15843649, DetectionBoxes_Precision/mAP@.75IOU = 0.11551155, DetectionBoxes_Recall/AR@1 = 0.15, DetectionBoxes_Recall/AR@10 = 0.3125, DetectionBoxes_Recall/AR@100 = 0.3125, DetectionBoxes_Recall/AR@100 (large) = 0.3125, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.10014906, Loss/BoxClassifierLoss/localization_loss = 0.116696715, Loss/RPNLoss/localization_loss = 0.33140635, Loss/RPNLoss/objectness_loss = 0.26421982, Loss/total_loss = 0.8124719, global_step = 277, learning_rate = 0.0002, loss = 0.8124719\n",
            "I1213 09:00:52.150012 139941885183872 estimator.py:2049] Saving dict for global step 277: DetectionBoxes_Precision/mAP = 0.080308065, DetectionBoxes_Precision/mAP (large) = 0.08032069, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.15843649, DetectionBoxes_Precision/mAP@.75IOU = 0.11551155, DetectionBoxes_Recall/AR@1 = 0.15, DetectionBoxes_Recall/AR@10 = 0.3125, DetectionBoxes_Recall/AR@100 = 0.3125, DetectionBoxes_Recall/AR@100 (large) = 0.3125, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.10014906, Loss/BoxClassifierLoss/localization_loss = 0.116696715, Loss/RPNLoss/localization_loss = 0.33140635, Loss/RPNLoss/objectness_loss = 0.26421982, Loss/total_loss = 0.8124719, global_step = 277, learning_rate = 0.0002, loss = 0.8124719\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 277: training/model.ckpt-277\n",
            "I1213 09:00:52.155965 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 277: training/model.ckpt-277\n",
            "INFO:tensorflow:Saving checkpoints for 289 into training/model.ckpt.\n",
            "I1213 09:10:33.697873 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 289 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 09:10:36.090262 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 09:10:36.091405 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 09:10:36.091542 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463a3989e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 09:10:36.139018 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463a3989e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463822cc80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 09:10:36.335191 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463822cc80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 09:10:36.956026 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 09:10:38.857480 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 09:10:39.030023 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 09:10:39.030465 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 09:10:40.111258 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 09:10:40.129178 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 09:10:41.865928 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T09:10:41Z\n",
            "I1213 09:10:41.883835 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T09:10:41Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 09:10:42.331638 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-289\n",
            "I1213 09:10:42.333223 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-289\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 09:10:43.306504 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 09:10:43.485019 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 09:11:01.488975 139939724338944 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 09:11:01.489362 139939724338944 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 09:11:01.490045 139939724338944 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.067\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.163\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.027\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.067\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.125\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.325\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.325\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.325\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-09:11:03\n",
            "I1213 09:11:03.097632 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-09:11:03\n",
            "INFO:tensorflow:Saving dict for global step 289: DetectionBoxes_Precision/mAP = 0.06705548, DetectionBoxes_Precision/mAP (large) = 0.06705548, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.16277628, DetectionBoxes_Precision/mAP@.75IOU = 0.026815182, DetectionBoxes_Recall/AR@1 = 0.125, DetectionBoxes_Recall/AR@10 = 0.325, DetectionBoxes_Recall/AR@100 = 0.325, DetectionBoxes_Recall/AR@100 (large) = 0.325, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.13647035, Loss/BoxClassifierLoss/localization_loss = 0.15958762, Loss/RPNLoss/localization_loss = 0.3322815, Loss/RPNLoss/objectness_loss = 0.28623566, Loss/total_loss = 0.9145752, global_step = 289, learning_rate = 0.0002, loss = 0.9145752\n",
            "I1213 09:11:03.097946 139941885183872 estimator.py:2049] Saving dict for global step 289: DetectionBoxes_Precision/mAP = 0.06705548, DetectionBoxes_Precision/mAP (large) = 0.06705548, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.16277628, DetectionBoxes_Precision/mAP@.75IOU = 0.026815182, DetectionBoxes_Recall/AR@1 = 0.125, DetectionBoxes_Recall/AR@10 = 0.325, DetectionBoxes_Recall/AR@100 = 0.325, DetectionBoxes_Recall/AR@100 (large) = 0.325, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.13647035, Loss/BoxClassifierLoss/localization_loss = 0.15958762, Loss/RPNLoss/localization_loss = 0.3322815, Loss/RPNLoss/objectness_loss = 0.28623566, Loss/total_loss = 0.9145752, global_step = 289, learning_rate = 0.0002, loss = 0.9145752\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 289: training/model.ckpt-289\n",
            "I1213 09:11:03.103341 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 289: training/model.ckpt-289\n",
            "INFO:tensorflow:Saving checkpoints for 301 into training/model.ckpt.\n",
            "I1213 09:20:44.477581 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 301 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 09:20:46.819503 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 09:20:46.820536 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 09:20:46.820670 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f4636969e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 09:20:46.868023 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f4636969e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f46369597b8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 09:20:47.058302 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f46369597b8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 09:20:47.640788 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 09:20:49.110623 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 09:20:49.262264 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 09:20:49.262689 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 09:20:50.328909 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 09:20:50.346477 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 09:20:52.381623 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T09:20:52Z\n",
            "I1213 09:20:52.398882 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T09:20:52Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 09:20:52.861835 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-301\n",
            "I1213 09:20:52.863486 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-301\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 09:20:53.893064 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 09:20:54.076375 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 09:21:12.196141 139939724338944 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 09:21:12.196559 139939724338944 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 09:21:12.197354 139939724338944 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.066\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.169\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.067\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.066\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.087\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.338\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.338\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.338\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-09:21:13\n",
            "I1213 09:21:13.755334 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-09:21:13\n",
            "INFO:tensorflow:Saving dict for global step 301: DetectionBoxes_Precision/mAP = 0.06596742, DetectionBoxes_Precision/mAP (large) = 0.06596742, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.16947079, DetectionBoxes_Precision/mAP@.75IOU = 0.06657714, DetectionBoxes_Recall/AR@1 = 0.0875, DetectionBoxes_Recall/AR@10 = 0.3375, DetectionBoxes_Recall/AR@100 = 0.3375, DetectionBoxes_Recall/AR@100 (large) = 0.3375, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.13858014, Loss/BoxClassifierLoss/localization_loss = 0.13280906, Loss/RPNLoss/localization_loss = 0.3248239, Loss/RPNLoss/objectness_loss = 0.2736331, Loss/total_loss = 0.86984617, global_step = 301, learning_rate = 0.0002, loss = 0.86984617\n",
            "I1213 09:21:13.755670 139941885183872 estimator.py:2049] Saving dict for global step 301: DetectionBoxes_Precision/mAP = 0.06596742, DetectionBoxes_Precision/mAP (large) = 0.06596742, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.16947079, DetectionBoxes_Precision/mAP@.75IOU = 0.06657714, DetectionBoxes_Recall/AR@1 = 0.0875, DetectionBoxes_Recall/AR@10 = 0.3375, DetectionBoxes_Recall/AR@100 = 0.3375, DetectionBoxes_Recall/AR@100 (large) = 0.3375, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.13858014, Loss/BoxClassifierLoss/localization_loss = 0.13280906, Loss/RPNLoss/localization_loss = 0.3248239, Loss/RPNLoss/objectness_loss = 0.2736331, Loss/total_loss = 0.86984617, global_step = 301, learning_rate = 0.0002, loss = 0.86984617\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 301: training/model.ckpt-301\n",
            "I1213 09:21:13.761612 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 301: training/model.ckpt-301\n",
            "INFO:tensorflow:global_step/sec: 0.019553\n",
            "I1213 09:21:13.763266 139941885183872 basic_session_run_hooks.py:692] global_step/sec: 0.019553\n",
            "INFO:tensorflow:loss = 0.44894594, step = 301 (5114.300 sec)\n",
            "I1213 09:21:13.764019 139941885183872 basic_session_run_hooks.py:260] loss = 0.44894594, step = 301 (5114.300 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 313 into training/model.ckpt.\n",
            "I1213 09:30:56.058077 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 313 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 09:30:58.399863 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 09:30:58.401024 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 09:30:58.401179 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f4637fd6a58>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 09:30:58.448962 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f4637fd6a58>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f4637fe02f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 09:30:58.642208 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f4637fe02f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 09:30:59.236529 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 09:31:00.723727 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 09:31:00.873907 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 09:31:00.874363 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 09:31:01.953855 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 09:31:01.972534 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 09:31:03.713647 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T09:31:03Z\n",
            "I1213 09:31:03.731504 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T09:31:03Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 09:31:04.211321 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-313\n",
            "I1213 09:31:04.212943 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-313\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 09:31:05.167228 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 09:31:05.355090 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 09:31:23.446423 139939724338944 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 09:31:23.446883 139939724338944 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 09:31:23.447669 139939724338944 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.07s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.060\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.159\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.047\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.060\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.037\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.350\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.350\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.350\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-09:31:25\n",
            "I1213 09:31:25.038540 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-09:31:25\n",
            "INFO:tensorflow:Saving dict for global step 313: DetectionBoxes_Precision/mAP = 0.06048863, DetectionBoxes_Precision/mAP (large) = 0.06048863, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.15860625, DetectionBoxes_Precision/mAP@.75IOU = 0.04732091, DetectionBoxes_Recall/AR@1 = 0.0375, DetectionBoxes_Recall/AR@10 = 0.35, DetectionBoxes_Recall/AR@100 = 0.35, DetectionBoxes_Recall/AR@100 (large) = 0.35, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.10766169, Loss/BoxClassifierLoss/localization_loss = 0.14200105, Loss/RPNLoss/localization_loss = 0.33025122, Loss/RPNLoss/objectness_loss = 0.2632836, Loss/total_loss = 0.8431975, global_step = 313, learning_rate = 0.0002, loss = 0.8431975\n",
            "I1213 09:31:25.038865 139941885183872 estimator.py:2049] Saving dict for global step 313: DetectionBoxes_Precision/mAP = 0.06048863, DetectionBoxes_Precision/mAP (large) = 0.06048863, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.15860625, DetectionBoxes_Precision/mAP@.75IOU = 0.04732091, DetectionBoxes_Recall/AR@1 = 0.0375, DetectionBoxes_Recall/AR@10 = 0.35, DetectionBoxes_Recall/AR@100 = 0.35, DetectionBoxes_Recall/AR@100 (large) = 0.35, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.10766169, Loss/BoxClassifierLoss/localization_loss = 0.14200105, Loss/RPNLoss/localization_loss = 0.33025122, Loss/RPNLoss/objectness_loss = 0.2632836, Loss/total_loss = 0.8431975, global_step = 313, learning_rate = 0.0002, loss = 0.8431975\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 313: training/model.ckpt-313\n",
            "I1213 09:31:25.044356 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 313: training/model.ckpt-313\n",
            "INFO:tensorflow:Saving checkpoints for 325 into training/model.ckpt.\n",
            "I1213 09:41:08.135321 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 325 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 09:41:10.442063 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 09:41:10.443076 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 09:41:10.443252 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f46384c3940>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 09:41:10.490998 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f46384c3940>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f46385218c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 09:41:10.680930 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f46385218c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 09:41:11.293163 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 09:41:12.805200 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 09:41:12.953936 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 09:41:12.954425 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 09:41:14.079637 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 09:41:14.097744 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 09:41:16.313957 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T09:41:16Z\n",
            "I1213 09:41:16.330909 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T09:41:16Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 09:41:16.797033 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-325\n",
            "I1213 09:41:16.798702 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-325\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 09:41:17.800722 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 09:41:17.982410 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 09:41:36.080381 139939732731648 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 09:41:36.080774 139939732731648 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 09:41:36.081490 139939732731648 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.075\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.180\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.044\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.075\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.138\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.300\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.300\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.300\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-09:41:37\n",
            "I1213 09:41:37.727031 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-09:41:37\n",
            "INFO:tensorflow:Saving dict for global step 325: DetectionBoxes_Precision/mAP = 0.07489115, DetectionBoxes_Precision/mAP (large) = 0.07489115, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.18047805, DetectionBoxes_Precision/mAP@.75IOU = 0.044130128, DetectionBoxes_Recall/AR@1 = 0.1375, DetectionBoxes_Recall/AR@10 = 0.3, DetectionBoxes_Recall/AR@100 = 0.3, DetectionBoxes_Recall/AR@100 (large) = 0.3, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.13167635, Loss/BoxClassifierLoss/localization_loss = 0.13167296, Loss/RPNLoss/localization_loss = 0.32790774, Loss/RPNLoss/objectness_loss = 0.26906598, Loss/total_loss = 0.8603231, global_step = 325, learning_rate = 0.0002, loss = 0.8603231\n",
            "I1213 09:41:37.727408 139941885183872 estimator.py:2049] Saving dict for global step 325: DetectionBoxes_Precision/mAP = 0.07489115, DetectionBoxes_Precision/mAP (large) = 0.07489115, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.18047805, DetectionBoxes_Precision/mAP@.75IOU = 0.044130128, DetectionBoxes_Recall/AR@1 = 0.1375, DetectionBoxes_Recall/AR@10 = 0.3, DetectionBoxes_Recall/AR@100 = 0.3, DetectionBoxes_Recall/AR@100 (large) = 0.3, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.13167635, Loss/BoxClassifierLoss/localization_loss = 0.13167296, Loss/RPNLoss/localization_loss = 0.32790774, Loss/RPNLoss/objectness_loss = 0.26906598, Loss/total_loss = 0.8603231, global_step = 325, learning_rate = 0.0002, loss = 0.8603231\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 325: training/model.ckpt-325\n",
            "I1213 09:41:37.732691 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 325: training/model.ckpt-325\n",
            "INFO:tensorflow:Saving checkpoints for 337 into training/model.ckpt.\n",
            "I1213 09:51:20.798007 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 337 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 09:51:23.173242 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 09:51:23.174451 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 09:51:23.174588 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f4637f84c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 09:51:23.226512 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f4637f84c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f4637f852f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 09:51:23.425517 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f4637f852f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 09:51:24.021379 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 09:51:25.477064 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 09:51:25.623459 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 09:51:25.623878 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 09:51:26.736493 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 09:51:26.759556 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 09:51:28.517214 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T09:51:28Z\n",
            "I1213 09:51:28.536503 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T09:51:28Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 09:51:29.006195 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-337\n",
            "I1213 09:51:29.007954 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-337\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 09:51:30.004829 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 09:51:30.183579 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 09:51:48.254355 139939724338944 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 09:51:48.254971 139939724338944 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 09:51:48.255725 139939724338944 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.100\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.183\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.090\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.100\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.163\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.362\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.362\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.362\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-09:51:49\n",
            "I1213 09:51:49.859287 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-09:51:49\n",
            "INFO:tensorflow:Saving dict for global step 337: DetectionBoxes_Precision/mAP = 0.100181, DetectionBoxes_Precision/mAP (large) = 0.100181, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.18271582, DetectionBoxes_Precision/mAP@.75IOU = 0.08959852, DetectionBoxes_Recall/AR@1 = 0.1625, DetectionBoxes_Recall/AR@10 = 0.3625, DetectionBoxes_Recall/AR@100 = 0.3625, DetectionBoxes_Recall/AR@100 (large) = 0.3625, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.13853242, Loss/BoxClassifierLoss/localization_loss = 0.16113853, Loss/RPNLoss/localization_loss = 0.3277948, Loss/RPNLoss/objectness_loss = 0.26889974, Loss/total_loss = 0.8963655, global_step = 337, learning_rate = 0.0002, loss = 0.8963655\n",
            "I1213 09:51:49.859618 139941885183872 estimator.py:2049] Saving dict for global step 337: DetectionBoxes_Precision/mAP = 0.100181, DetectionBoxes_Precision/mAP (large) = 0.100181, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.18271582, DetectionBoxes_Precision/mAP@.75IOU = 0.08959852, DetectionBoxes_Recall/AR@1 = 0.1625, DetectionBoxes_Recall/AR@10 = 0.3625, DetectionBoxes_Recall/AR@100 = 0.3625, DetectionBoxes_Recall/AR@100 (large) = 0.3625, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.13853242, Loss/BoxClassifierLoss/localization_loss = 0.16113853, Loss/RPNLoss/localization_loss = 0.3277948, Loss/RPNLoss/objectness_loss = 0.26889974, Loss/total_loss = 0.8963655, global_step = 337, learning_rate = 0.0002, loss = 0.8963655\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 337: training/model.ckpt-337\n",
            "I1213 09:51:49.865382 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 337: training/model.ckpt-337\n",
            "INFO:tensorflow:Saving checkpoints for 349 into training/model.ckpt.\n",
            "I1213 10:01:33.546531 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 349 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 10:01:35.882135 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 10:01:35.883841 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 10:01:35.884005 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f4637ac29e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 10:01:35.932134 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f4637ac29e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f4634842c80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 10:01:36.129723 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f4634842c80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 10:01:36.737035 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 10:01:38.179464 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 10:01:38.332163 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 10:01:38.332604 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 10:01:39.859042 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 10:01:39.877125 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 10:01:41.613846 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T10:01:41Z\n",
            "I1213 10:01:41.630965 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T10:01:41Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 10:01:42.095315 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-349\n",
            "I1213 10:01:42.097199 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-349\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 10:01:43.083336 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 10:01:43.271654 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 10:02:01.550179 139939724338944 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 10:02:01.550578 139939724338944 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 10:02:01.551362 139939724338944 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.074\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.167\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.037\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.074\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.087\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.300\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.300\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.300\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-10:02:03\n",
            "I1213 10:02:03.105916 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-10:02:03\n",
            "INFO:tensorflow:Saving dict for global step 349: DetectionBoxes_Precision/mAP = 0.07426245, DetectionBoxes_Precision/mAP (large) = 0.07426245, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.16677667, DetectionBoxes_Precision/mAP@.75IOU = 0.036594834, DetectionBoxes_Recall/AR@1 = 0.0875, DetectionBoxes_Recall/AR@10 = 0.3, DetectionBoxes_Recall/AR@100 = 0.3, DetectionBoxes_Recall/AR@100 (large) = 0.3, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.27537623, Loss/BoxClassifierLoss/localization_loss = 0.12130382, Loss/RPNLoss/localization_loss = 0.32773346, Loss/RPNLoss/objectness_loss = 0.26976627, Loss/total_loss = 0.9941798, global_step = 349, learning_rate = 0.0002, loss = 0.9941798\n",
            "I1213 10:02:03.106256 139941885183872 estimator.py:2049] Saving dict for global step 349: DetectionBoxes_Precision/mAP = 0.07426245, DetectionBoxes_Precision/mAP (large) = 0.07426245, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.16677667, DetectionBoxes_Precision/mAP@.75IOU = 0.036594834, DetectionBoxes_Recall/AR@1 = 0.0875, DetectionBoxes_Recall/AR@10 = 0.3, DetectionBoxes_Recall/AR@100 = 0.3, DetectionBoxes_Recall/AR@100 (large) = 0.3, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.27537623, Loss/BoxClassifierLoss/localization_loss = 0.12130382, Loss/RPNLoss/localization_loss = 0.32773346, Loss/RPNLoss/objectness_loss = 0.26976627, Loss/total_loss = 0.9941798, global_step = 349, learning_rate = 0.0002, loss = 0.9941798\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 349: training/model.ckpt-349\n",
            "I1213 10:02:03.112318 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 349: training/model.ckpt-349\n",
            "INFO:tensorflow:Saving checkpoints for 361 into training/model.ckpt.\n",
            "I1213 10:11:46.110077 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 361 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 10:11:48.481609 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 10:11:48.482681 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 10:11:48.482820 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f4637d9be10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 10:11:48.530832 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f4637d9be10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f4637daf2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 10:11:48.727436 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f4637daf2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 10:11:49.332068 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 10:11:50.816872 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 10:11:50.960558 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 10:11:50.960983 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 10:11:52.080056 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 10:11:52.097909 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 10:11:53.846621 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T10:11:53Z\n",
            "I1213 10:11:53.864153 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T10:11:53Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 10:11:54.326895 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-361\n",
            "I1213 10:11:54.328542 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-361\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 10:11:55.313541 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 10:11:55.498996 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 10:12:13.553562 139939732731648 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 10:12:13.554029 139939732731648 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 10:12:13.554822 139939732731648 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.083\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.204\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.018\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.083\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.175\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.338\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.338\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.338\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-10:12:15\n",
            "I1213 10:12:15.119319 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-10:12:15\n",
            "INFO:tensorflow:Saving dict for global step 361: DetectionBoxes_Precision/mAP = 0.08269367, DetectionBoxes_Precision/mAP (large) = 0.08269367, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.20378287, DetectionBoxes_Precision/mAP@.75IOU = 0.018387552, DetectionBoxes_Recall/AR@1 = 0.175, DetectionBoxes_Recall/AR@10 = 0.3375, DetectionBoxes_Recall/AR@100 = 0.3375, DetectionBoxes_Recall/AR@100 (large) = 0.3375, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.10863519, Loss/BoxClassifierLoss/localization_loss = 0.15587473, Loss/RPNLoss/localization_loss = 0.32926407, Loss/RPNLoss/objectness_loss = 0.26115343, Loss/total_loss = 0.8549275, global_step = 361, learning_rate = 0.0002, loss = 0.8549275\n",
            "I1213 10:12:15.119649 139941885183872 estimator.py:2049] Saving dict for global step 361: DetectionBoxes_Precision/mAP = 0.08269367, DetectionBoxes_Precision/mAP (large) = 0.08269367, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.20378287, DetectionBoxes_Precision/mAP@.75IOU = 0.018387552, DetectionBoxes_Recall/AR@1 = 0.175, DetectionBoxes_Recall/AR@10 = 0.3375, DetectionBoxes_Recall/AR@100 = 0.3375, DetectionBoxes_Recall/AR@100 (large) = 0.3375, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.10863519, Loss/BoxClassifierLoss/localization_loss = 0.15587473, Loss/RPNLoss/localization_loss = 0.32926407, Loss/RPNLoss/objectness_loss = 0.26115343, Loss/total_loss = 0.8549275, global_step = 361, learning_rate = 0.0002, loss = 0.8549275\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 361: training/model.ckpt-361\n",
            "I1213 10:12:15.125034 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 361: training/model.ckpt-361\n",
            "INFO:tensorflow:Saving checkpoints for 373 into training/model.ckpt.\n",
            "I1213 10:21:58.825687 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 373 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 10:22:01.160410 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 10:22:01.161802 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 10:22:01.161959 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463843e9e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 10:22:01.213212 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463843e9e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f46385b2c80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 10:22:01.405550 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f46385b2c80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 10:22:02.008727 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 10:22:03.994827 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 10:22:04.151062 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 10:22:04.151561 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 10:22:05.297009 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 10:22:05.314471 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 10:22:07.041688 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T10:22:07Z\n",
            "I1213 10:22:07.059167 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T10:22:07Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 10:22:07.527154 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-373\n",
            "I1213 10:22:07.529061 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-373\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 10:22:08.547568 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 10:22:08.729369 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 10:22:26.855040 139939732731648 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 10:22:26.855458 139939732731648 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 10:22:26.856178 139939732731648 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.071\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.188\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.014\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.071\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.100\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.312\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.312\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.312\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-10:22:28\n",
            "I1213 10:22:28.453967 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-10:22:28\n",
            "INFO:tensorflow:Saving dict for global step 373: DetectionBoxes_Precision/mAP = 0.07108814, DetectionBoxes_Precision/mAP (large) = 0.07108814, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.18811882, DetectionBoxes_Precision/mAP@.75IOU = 0.01430143, DetectionBoxes_Recall/AR@1 = 0.1, DetectionBoxes_Recall/AR@10 = 0.3125, DetectionBoxes_Recall/AR@100 = 0.3125, DetectionBoxes_Recall/AR@100 (large) = 0.3125, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.11454063, Loss/BoxClassifierLoss/localization_loss = 0.123868644, Loss/RPNLoss/localization_loss = 0.33598495, Loss/RPNLoss/objectness_loss = 0.2719206, Loss/total_loss = 0.8463148, global_step = 373, learning_rate = 0.0002, loss = 0.8463148\n",
            "I1213 10:22:28.454349 139941885183872 estimator.py:2049] Saving dict for global step 373: DetectionBoxes_Precision/mAP = 0.07108814, DetectionBoxes_Precision/mAP (large) = 0.07108814, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.18811882, DetectionBoxes_Precision/mAP@.75IOU = 0.01430143, DetectionBoxes_Recall/AR@1 = 0.1, DetectionBoxes_Recall/AR@10 = 0.3125, DetectionBoxes_Recall/AR@100 = 0.3125, DetectionBoxes_Recall/AR@100 (large) = 0.3125, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.11454063, Loss/BoxClassifierLoss/localization_loss = 0.123868644, Loss/RPNLoss/localization_loss = 0.33598495, Loss/RPNLoss/objectness_loss = 0.2719206, Loss/total_loss = 0.8463148, global_step = 373, learning_rate = 0.0002, loss = 0.8463148\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 373: training/model.ckpt-373\n",
            "I1213 10:22:28.459846 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 373: training/model.ckpt-373\n",
            "INFO:tensorflow:Saving checkpoints for 385 into training/model.ckpt.\n",
            "I1213 10:32:11.473811 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 385 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 10:32:13.923307 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 10:32:13.924192 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 10:32:13.924334 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f46382f3e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 10:32:13.970144 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f46382f3e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f46382cc2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 10:32:14.161512 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f46382cc2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 10:32:14.762410 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 10:32:16.240381 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 10:32:16.384776 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 10:32:16.385241 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 10:32:17.466783 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 10:32:17.484531 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 10:32:19.216380 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T10:32:19Z\n",
            "I1213 10:32:19.234490 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T10:32:19Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 10:32:20.020613 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-385\n",
            "I1213 10:32:20.022305 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-385\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 10:32:21.085953 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 10:32:21.268960 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 10:32:39.584985 139939732731648 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 10:32:39.585410 139939732731648 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 10:32:39.586095 139939732731648 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.080\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.184\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.056\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.080\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.163\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.362\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.362\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.362\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-10:32:41\n",
            "I1213 10:32:41.111387 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-10:32:41\n",
            "INFO:tensorflow:Saving dict for global step 385: DetectionBoxes_Precision/mAP = 0.07961968, DetectionBoxes_Precision/mAP (large) = 0.07961968, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.18418123, DetectionBoxes_Precision/mAP@.75IOU = 0.056397475, DetectionBoxes_Recall/AR@1 = 0.1625, DetectionBoxes_Recall/AR@10 = 0.3625, DetectionBoxes_Recall/AR@100 = 0.3625, DetectionBoxes_Recall/AR@100 (large) = 0.3625, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.098423816, Loss/BoxClassifierLoss/localization_loss = 0.10945265, Loss/RPNLoss/localization_loss = 0.33201915, Loss/RPNLoss/objectness_loss = 0.25606418, Loss/total_loss = 0.7959597, global_step = 385, learning_rate = 0.0002, loss = 0.7959597\n",
            "I1213 10:32:41.111747 139941885183872 estimator.py:2049] Saving dict for global step 385: DetectionBoxes_Precision/mAP = 0.07961968, DetectionBoxes_Precision/mAP (large) = 0.07961968, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.18418123, DetectionBoxes_Precision/mAP@.75IOU = 0.056397475, DetectionBoxes_Recall/AR@1 = 0.1625, DetectionBoxes_Recall/AR@10 = 0.3625, DetectionBoxes_Recall/AR@100 = 0.3625, DetectionBoxes_Recall/AR@100 (large) = 0.3625, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.098423816, Loss/BoxClassifierLoss/localization_loss = 0.10945265, Loss/RPNLoss/localization_loss = 0.33201915, Loss/RPNLoss/objectness_loss = 0.25606418, Loss/total_loss = 0.7959597, global_step = 385, learning_rate = 0.0002, loss = 0.7959597\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 385: training/model.ckpt-385\n",
            "I1213 10:32:41.117303 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 385: training/model.ckpt-385\n",
            "INFO:tensorflow:Saving checkpoints for 397 into training/model.ckpt.\n",
            "I1213 10:42:24.603283 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 397 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 10:42:26.949248 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 10:42:26.950363 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 10:42:26.950505 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463b3be240>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 10:42:26.997404 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463b3be240>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463a9ae840> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 10:42:27.200017 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463a9ae840> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 10:42:27.812661 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 10:42:29.257956 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 10:42:29.420348 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 10:42:29.420798 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 10:42:30.559819 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 10:42:30.577062 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 10:42:32.320099 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T10:42:32Z\n",
            "I1213 10:42:32.337643 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T10:42:32Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 10:42:32.801505 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-397\n",
            "I1213 10:42:32.803066 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-397\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 10:42:33.786089 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 10:42:33.969298 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 10:42:52.179732 139939724338944 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 10:42:52.180199 139939724338944 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 10:42:52.181177 139939724338944 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.082\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.186\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.100\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.082\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.100\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.350\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.350\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.350\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-10:42:53\n",
            "I1213 10:42:53.732066 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-10:42:53\n",
            "INFO:tensorflow:Saving dict for global step 397: DetectionBoxes_Precision/mAP = 0.08154077, DetectionBoxes_Precision/mAP (large) = 0.08154077, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.186104, DetectionBoxes_Precision/mAP@.75IOU = 0.1000017, DetectionBoxes_Recall/AR@1 = 0.1, DetectionBoxes_Recall/AR@10 = 0.35, DetectionBoxes_Recall/AR@100 = 0.35, DetectionBoxes_Recall/AR@100 (large) = 0.35, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.12282202, Loss/BoxClassifierLoss/localization_loss = 0.1322689, Loss/RPNLoss/localization_loss = 0.33342046, Loss/RPNLoss/objectness_loss = 0.28709987, Loss/total_loss = 0.87561125, global_step = 397, learning_rate = 0.0002, loss = 0.87561125\n",
            "I1213 10:42:53.732450 139941885183872 estimator.py:2049] Saving dict for global step 397: DetectionBoxes_Precision/mAP = 0.08154077, DetectionBoxes_Precision/mAP (large) = 0.08154077, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.186104, DetectionBoxes_Precision/mAP@.75IOU = 0.1000017, DetectionBoxes_Recall/AR@1 = 0.1, DetectionBoxes_Recall/AR@10 = 0.35, DetectionBoxes_Recall/AR@100 = 0.35, DetectionBoxes_Recall/AR@100 (large) = 0.35, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.12282202, Loss/BoxClassifierLoss/localization_loss = 0.1322689, Loss/RPNLoss/localization_loss = 0.33342046, Loss/RPNLoss/objectness_loss = 0.28709987, Loss/total_loss = 0.87561125, global_step = 397, learning_rate = 0.0002, loss = 0.87561125\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 397: training/model.ckpt-397\n",
            "I1213 10:42:53.738016 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 397: training/model.ckpt-397\n",
            "INFO:tensorflow:global_step/sec: 0.019628\n",
            "I1213 10:46:08.535392 139941885183872 basic_session_run_hooks.py:692] global_step/sec: 0.019628\n",
            "INFO:tensorflow:loss = 0.58330286, step = 401 (5094.772 sec)\n",
            "I1213 10:46:08.536436 139941885183872 basic_session_run_hooks.py:260] loss = 0.58330286, step = 401 (5094.772 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 409 into training/model.ckpt.\n",
            "I1213 10:52:37.612273 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 409 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 10:52:39.922381 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 10:52:39.923563 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 10:52:39.923700 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f46386109b0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 10:52:39.971048 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f46386109b0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463869f488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 10:52:40.176535 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463869f488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 10:52:40.771123 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 10:52:42.235205 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 10:52:42.387273 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 10:52:42.387757 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 10:52:43.475097 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 10:52:43.492337 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 10:52:45.690742 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T10:52:45Z\n",
            "I1213 10:52:45.707833 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T10:52:45Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 10:52:46.172589 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-409\n",
            "I1213 10:52:46.174091 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-409\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 10:52:47.189122 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 10:52:47.371051 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 10:53:05.528543 139939732731648 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 10:53:05.528956 139939732731648 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 10:53:05.529674 139939732731648 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.07s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.087\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.224\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.019\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.087\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.087\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.312\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.350\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.350\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-10:53:07\n",
            "I1213 10:53:07.153813 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-10:53:07\n",
            "INFO:tensorflow:Saving dict for global step 409: DetectionBoxes_Precision/mAP = 0.08656335, DetectionBoxes_Precision/mAP (large) = 0.086609885, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.22371523, DetectionBoxes_Precision/mAP@.75IOU = 0.018989602, DetectionBoxes_Recall/AR@1 = 0.0875, DetectionBoxes_Recall/AR@10 = 0.3125, DetectionBoxes_Recall/AR@100 = 0.35, DetectionBoxes_Recall/AR@100 (large) = 0.35, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.10527964, Loss/BoxClassifierLoss/localization_loss = 0.17051892, Loss/RPNLoss/localization_loss = 0.32902583, Loss/RPNLoss/objectness_loss = 0.27049336, Loss/total_loss = 0.87531775, global_step = 409, learning_rate = 0.0002, loss = 0.87531775\n",
            "I1213 10:53:07.154183 139941885183872 estimator.py:2049] Saving dict for global step 409: DetectionBoxes_Precision/mAP = 0.08656335, DetectionBoxes_Precision/mAP (large) = 0.086609885, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.22371523, DetectionBoxes_Precision/mAP@.75IOU = 0.018989602, DetectionBoxes_Recall/AR@1 = 0.0875, DetectionBoxes_Recall/AR@10 = 0.3125, DetectionBoxes_Recall/AR@100 = 0.35, DetectionBoxes_Recall/AR@100 (large) = 0.35, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.10527964, Loss/BoxClassifierLoss/localization_loss = 0.17051892, Loss/RPNLoss/localization_loss = 0.32902583, Loss/RPNLoss/objectness_loss = 0.27049336, Loss/total_loss = 0.87531775, global_step = 409, learning_rate = 0.0002, loss = 0.87531775\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 409: training/model.ckpt-409\n",
            "I1213 10:53:07.160210 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 409: training/model.ckpt-409\n",
            "INFO:tensorflow:Saving checkpoints for 421 into training/model.ckpt.\n",
            "I1213 11:02:51.208132 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 421 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 11:02:53.552684 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 11:02:53.553681 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 11:02:53.553833 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463af63c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 11:02:53.602596 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463af63c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463af6d2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 11:02:53.798526 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463af6d2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 11:02:54.385993 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 11:02:55.838305 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 11:02:55.982682 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 11:02:55.983146 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 11:02:57.077180 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 11:02:57.095213 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 11:02:58.805570 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T11:02:58Z\n",
            "I1213 11:02:58.822701 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T11:02:58Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 11:02:59.293943 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-421\n",
            "I1213 11:02:59.295587 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-421\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 11:03:00.292202 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 11:03:00.475605 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 11:03:18.536590 139939724338944 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 11:03:18.537026 139939724338944 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 11:03:18.537801 139939724338944 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.096\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.216\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.105\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.096\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.150\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.362\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.362\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.362\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-11:03:20\n",
            "I1213 11:03:20.076936 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-11:03:20\n",
            "INFO:tensorflow:Saving dict for global step 421: DetectionBoxes_Precision/mAP = 0.0962223, DetectionBoxes_Precision/mAP (large) = 0.0962223, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.21635914, DetectionBoxes_Precision/mAP@.75IOU = 0.105323285, DetectionBoxes_Recall/AR@1 = 0.15, DetectionBoxes_Recall/AR@10 = 0.3625, DetectionBoxes_Recall/AR@100 = 0.3625, DetectionBoxes_Recall/AR@100 (large) = 0.3625, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.14050388, Loss/BoxClassifierLoss/localization_loss = 0.13504674, Loss/RPNLoss/localization_loss = 0.336817, Loss/RPNLoss/objectness_loss = 0.26600802, Loss/total_loss = 0.87837565, global_step = 421, learning_rate = 0.0002, loss = 0.87837565\n",
            "I1213 11:03:20.077288 139941885183872 estimator.py:2049] Saving dict for global step 421: DetectionBoxes_Precision/mAP = 0.0962223, DetectionBoxes_Precision/mAP (large) = 0.0962223, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.21635914, DetectionBoxes_Precision/mAP@.75IOU = 0.105323285, DetectionBoxes_Recall/AR@1 = 0.15, DetectionBoxes_Recall/AR@10 = 0.3625, DetectionBoxes_Recall/AR@100 = 0.3625, DetectionBoxes_Recall/AR@100 (large) = 0.3625, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.14050388, Loss/BoxClassifierLoss/localization_loss = 0.13504674, Loss/RPNLoss/localization_loss = 0.336817, Loss/RPNLoss/objectness_loss = 0.26600802, Loss/total_loss = 0.87837565, global_step = 421, learning_rate = 0.0002, loss = 0.87837565\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 421: training/model.ckpt-421\n",
            "I1213 11:03:20.083082 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 421: training/model.ckpt-421\n",
            "INFO:tensorflow:Saving checkpoints for 433 into training/model.ckpt.\n",
            "I1213 11:13:03.844671 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 433 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 11:13:06.154799 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 11:13:06.155998 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 11:13:06.156157 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f46384e7940>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 11:13:06.202743 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f46384e7940>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f46384d38c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 11:13:06.399620 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f46384d38c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 11:13:07.016194 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 11:13:08.505960 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 11:13:08.655153 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 11:13:08.655608 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 11:13:09.754479 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 11:13:09.771954 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 11:13:12.012036 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T11:13:12Z\n",
            "I1213 11:13:12.029854 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T11:13:12Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 11:13:12.485585 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-433\n",
            "I1213 11:13:12.487226 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-433\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 11:13:13.469307 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 11:13:13.646017 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 11:13:31.847949 139939732731648 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 11:13:31.848444 139939732731648 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 11:13:31.849184 139939732731648 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.100\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.268\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.044\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.100\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.138\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.375\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.375\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.375\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-11:13:33\n",
            "I1213 11:13:33.395698 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-11:13:33\n",
            "INFO:tensorflow:Saving dict for global step 433: DetectionBoxes_Precision/mAP = 0.09956068, DetectionBoxes_Precision/mAP (large) = 0.09956068, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.2681084, DetectionBoxes_Precision/mAP@.75IOU = 0.043993562, DetectionBoxes_Recall/AR@1 = 0.1375, DetectionBoxes_Recall/AR@10 = 0.375, DetectionBoxes_Recall/AR@100 = 0.375, DetectionBoxes_Recall/AR@100 (large) = 0.375, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.15636505, Loss/BoxClassifierLoss/localization_loss = 0.15447567, Loss/RPNLoss/localization_loss = 0.335837, Loss/RPNLoss/objectness_loss = 0.2581325, Loss/total_loss = 0.90481025, global_step = 433, learning_rate = 0.0002, loss = 0.90481025\n",
            "I1213 11:13:33.396016 139941885183872 estimator.py:2049] Saving dict for global step 433: DetectionBoxes_Precision/mAP = 0.09956068, DetectionBoxes_Precision/mAP (large) = 0.09956068, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.2681084, DetectionBoxes_Precision/mAP@.75IOU = 0.043993562, DetectionBoxes_Recall/AR@1 = 0.1375, DetectionBoxes_Recall/AR@10 = 0.375, DetectionBoxes_Recall/AR@100 = 0.375, DetectionBoxes_Recall/AR@100 (large) = 0.375, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.15636505, Loss/BoxClassifierLoss/localization_loss = 0.15447567, Loss/RPNLoss/localization_loss = 0.335837, Loss/RPNLoss/objectness_loss = 0.2581325, Loss/total_loss = 0.90481025, global_step = 433, learning_rate = 0.0002, loss = 0.90481025\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 433: training/model.ckpt-433\n",
            "I1213 11:13:33.401701 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 433: training/model.ckpt-433\n",
            "INFO:tensorflow:Saving checkpoints for 445 into training/model.ckpt.\n",
            "I1213 11:23:18.660904 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 445 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 11:23:21.028182 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 11:23:21.029308 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 11:23:21.029464 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f46377aec18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 11:23:21.077875 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f46377aec18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f46377872f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 11:23:21.277515 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f46377872f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 11:23:21.876925 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 11:23:23.344046 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 11:23:23.500683 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 11:23:23.501159 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 11:23:24.592673 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 11:23:24.610321 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 11:23:26.327158 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T11:23:26Z\n",
            "I1213 11:23:26.344651 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T11:23:26Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 11:23:26.798706 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-445\n",
            "I1213 11:23:26.800414 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-445\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 11:23:27.816685 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 11:23:27.988948 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 11:23:46.056785 139939724338944 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 11:23:46.057262 139939724338944 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 11:23:46.058076 139939724338944 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.076\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.200\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.027\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.076\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.150\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.325\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.325\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.325\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-11:23:47\n",
            "I1213 11:23:47.631366 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-11:23:47\n",
            "INFO:tensorflow:Saving dict for global step 445: DetectionBoxes_Precision/mAP = 0.07609957, DetectionBoxes_Precision/mAP (large) = 0.07609957, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.19969545, DetectionBoxes_Precision/mAP@.75IOU = 0.027172718, DetectionBoxes_Recall/AR@1 = 0.15, DetectionBoxes_Recall/AR@10 = 0.325, DetectionBoxes_Recall/AR@100 = 0.325, DetectionBoxes_Recall/AR@100 (large) = 0.325, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.10894986, Loss/BoxClassifierLoss/localization_loss = 0.14281066, Loss/RPNLoss/localization_loss = 0.33957177, Loss/RPNLoss/objectness_loss = 0.25950548, Loss/total_loss = 0.85083777, global_step = 445, learning_rate = 0.0002, loss = 0.85083777\n",
            "I1213 11:23:47.631699 139941885183872 estimator.py:2049] Saving dict for global step 445: DetectionBoxes_Precision/mAP = 0.07609957, DetectionBoxes_Precision/mAP (large) = 0.07609957, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.19969545, DetectionBoxes_Precision/mAP@.75IOU = 0.027172718, DetectionBoxes_Recall/AR@1 = 0.15, DetectionBoxes_Recall/AR@10 = 0.325, DetectionBoxes_Recall/AR@100 = 0.325, DetectionBoxes_Recall/AR@100 (large) = 0.325, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.10894986, Loss/BoxClassifierLoss/localization_loss = 0.14281066, Loss/RPNLoss/localization_loss = 0.33957177, Loss/RPNLoss/objectness_loss = 0.25950548, Loss/total_loss = 0.85083777, global_step = 445, learning_rate = 0.0002, loss = 0.85083777\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 445: training/model.ckpt-445\n",
            "I1213 11:23:47.637189 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 445: training/model.ckpt-445\n",
            "INFO:tensorflow:Saving checkpoints for 457 into training/model.ckpt.\n",
            "I1213 11:33:34.376315 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 457 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 11:33:36.688408 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 11:33:36.689649 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 11:33:36.689824 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f46386019e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 11:33:36.738142 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f46386019e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f4638675b70> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 11:33:36.932183 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f4638675b70> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 11:33:37.533396 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 11:33:39.454075 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 11:33:39.604211 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 11:33:39.604654 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 11:33:40.734160 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 11:33:40.751832 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 11:33:42.541909 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T11:33:42Z\n",
            "I1213 11:33:42.559726 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T11:33:42Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 11:33:43.035264 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-457\n",
            "I1213 11:33:43.037179 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-457\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 11:33:44.070310 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 11:33:44.255287 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 11:34:02.468463 139939724338944 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 11:34:02.468874 139939724338944 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 11:34:02.469635 139939724338944 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.093\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.207\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.016\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.093\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.163\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.312\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.312\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.312\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-11:34:04\n",
            "I1213 11:34:04.077506 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-11:34:04\n",
            "INFO:tensorflow:Saving dict for global step 457: DetectionBoxes_Precision/mAP = 0.09334168, DetectionBoxes_Precision/mAP (large) = 0.09334168, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.2071348, DetectionBoxes_Precision/mAP@.75IOU = 0.01608911, DetectionBoxes_Recall/AR@1 = 0.1625, DetectionBoxes_Recall/AR@10 = 0.3125, DetectionBoxes_Recall/AR@100 = 0.3125, DetectionBoxes_Recall/AR@100 (large) = 0.3125, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.099257395, Loss/BoxClassifierLoss/localization_loss = 0.10583302, Loss/RPNLoss/localization_loss = 0.33359855, Loss/RPNLoss/objectness_loss = 0.26228097, Loss/total_loss = 0.8009699, global_step = 457, learning_rate = 0.0002, loss = 0.8009699\n",
            "I1213 11:34:04.077822 139941885183872 estimator.py:2049] Saving dict for global step 457: DetectionBoxes_Precision/mAP = 0.09334168, DetectionBoxes_Precision/mAP (large) = 0.09334168, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.2071348, DetectionBoxes_Precision/mAP@.75IOU = 0.01608911, DetectionBoxes_Recall/AR@1 = 0.1625, DetectionBoxes_Recall/AR@10 = 0.3125, DetectionBoxes_Recall/AR@100 = 0.3125, DetectionBoxes_Recall/AR@100 (large) = 0.3125, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.099257395, Loss/BoxClassifierLoss/localization_loss = 0.10583302, Loss/RPNLoss/localization_loss = 0.33359855, Loss/RPNLoss/objectness_loss = 0.26228097, Loss/total_loss = 0.8009699, global_step = 457, learning_rate = 0.0002, loss = 0.8009699\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 457: training/model.ckpt-457\n",
            "I1213 11:34:04.083251 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 457: training/model.ckpt-457\n",
            "INFO:tensorflow:Saving checkpoints for 469 into training/model.ckpt.\n",
            "I1213 11:43:51.731879 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 469 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 11:43:54.115523 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 11:43:54.116738 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 11:43:54.116894 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463b867e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 11:43:54.166085 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463b867e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463b8482f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 11:43:54.368392 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463b8482f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 11:43:54.971570 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 11:43:56.471543 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 11:43:56.614960 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 11:43:56.615419 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 11:43:57.750631 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 11:43:57.769492 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 11:43:59.506142 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T11:43:59Z\n",
            "I1213 11:43:59.527560 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T11:43:59Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 11:43:59.995437 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-469\n",
            "I1213 11:43:59.996984 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-469\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 11:44:01.004140 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 11:44:01.210516 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 11:44:19.697589 139939732731648 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 11:44:19.698021 139939732731648 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 11:44:19.698693 139939732731648 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.07s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.086\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.233\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.004\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.086\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.100\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.312\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.338\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.338\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-11:44:21\n",
            "I1213 11:44:21.290437 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-11:44:21\n",
            "INFO:tensorflow:Saving dict for global step 469: DetectionBoxes_Precision/mAP = 0.086330734, DetectionBoxes_Precision/mAP (large) = 0.08635661, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.2328763, DetectionBoxes_Precision/mAP@.75IOU = 0.004152028, DetectionBoxes_Recall/AR@1 = 0.1, DetectionBoxes_Recall/AR@10 = 0.3125, DetectionBoxes_Recall/AR@100 = 0.3375, DetectionBoxes_Recall/AR@100 (large) = 0.3375, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.12097493, Loss/BoxClassifierLoss/localization_loss = 0.14933133, Loss/RPNLoss/localization_loss = 0.32876828, Loss/RPNLoss/objectness_loss = 0.25621936, Loss/total_loss = 0.85529387, global_step = 469, learning_rate = 0.0002, loss = 0.85529387\n",
            "I1213 11:44:21.290851 139941885183872 estimator.py:2049] Saving dict for global step 469: DetectionBoxes_Precision/mAP = 0.086330734, DetectionBoxes_Precision/mAP (large) = 0.08635661, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.2328763, DetectionBoxes_Precision/mAP@.75IOU = 0.004152028, DetectionBoxes_Recall/AR@1 = 0.1, DetectionBoxes_Recall/AR@10 = 0.3125, DetectionBoxes_Recall/AR@100 = 0.3375, DetectionBoxes_Recall/AR@100 (large) = 0.3375, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.12097493, Loss/BoxClassifierLoss/localization_loss = 0.14933133, Loss/RPNLoss/localization_loss = 0.32876828, Loss/RPNLoss/objectness_loss = 0.25621936, Loss/total_loss = 0.85529387, global_step = 469, learning_rate = 0.0002, loss = 0.85529387\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 469: training/model.ckpt-469\n",
            "I1213 11:44:21.296489 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 469: training/model.ckpt-469\n",
            "INFO:tensorflow:Saving checkpoints for 481 into training/model.ckpt.\n",
            "I1213 11:54:10.090193 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 481 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 11:54:12.445058 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 11:54:12.446993 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 11:54:12.447222 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463abc79e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 11:54:12.502415 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463abc79e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463af3bb70> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 11:54:12.701414 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463af3bb70> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 11:54:13.785975 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 11:54:15.347272 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 11:54:15.539200 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 11:54:15.539625 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 11:54:16.620983 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 11:54:16.638196 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 11:54:18.357769 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T11:54:18Z\n",
            "I1213 11:54:18.375869 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T11:54:18Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 11:54:18.844681 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-481\n",
            "I1213 11:54:18.846317 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-481\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 11:54:19.950255 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 11:54:20.159887 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 11:54:38.617661 139939724338944 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 11:54:38.618252 139939724338944 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 11:54:38.618965 139939724338944 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.091\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.272\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.005\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.091\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.100\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.300\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.338\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.338\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-11:54:40\n",
            "I1213 11:54:40.149724 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-11:54:40\n",
            "INFO:tensorflow:Saving dict for global step 481: DetectionBoxes_Precision/mAP = 0.09077274, DetectionBoxes_Precision/mAP (large) = 0.09077274, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.27163845, DetectionBoxes_Precision/mAP@.75IOU = 0.0053755376, DetectionBoxes_Recall/AR@1 = 0.1, DetectionBoxes_Recall/AR@10 = 0.3, DetectionBoxes_Recall/AR@100 = 0.3375, DetectionBoxes_Recall/AR@100 (large) = 0.3375, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.14291973, Loss/BoxClassifierLoss/localization_loss = 0.17066509, Loss/RPNLoss/localization_loss = 0.3367371, Loss/RPNLoss/objectness_loss = 0.26184362, Loss/total_loss = 0.9121655, global_step = 481, learning_rate = 0.0002, loss = 0.9121655\n",
            "I1213 11:54:40.150067 139941885183872 estimator.py:2049] Saving dict for global step 481: DetectionBoxes_Precision/mAP = 0.09077274, DetectionBoxes_Precision/mAP (large) = 0.09077274, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.27163845, DetectionBoxes_Precision/mAP@.75IOU = 0.0053755376, DetectionBoxes_Recall/AR@1 = 0.1, DetectionBoxes_Recall/AR@10 = 0.3, DetectionBoxes_Recall/AR@100 = 0.3375, DetectionBoxes_Recall/AR@100 (large) = 0.3375, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.14291973, Loss/BoxClassifierLoss/localization_loss = 0.17066509, Loss/RPNLoss/localization_loss = 0.3367371, Loss/RPNLoss/objectness_loss = 0.26184362, Loss/total_loss = 0.9121655, global_step = 481, learning_rate = 0.0002, loss = 0.9121655\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 481: training/model.ckpt-481\n",
            "I1213 11:54:40.155788 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 481: training/model.ckpt-481\n",
            "INFO:tensorflow:Saving checkpoints for 493 into training/model.ckpt.\n",
            "I1213 12:04:29.576217 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 493 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 12:04:31.968194 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 12:04:31.969178 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 12:04:31.969317 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463a53c7f0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 12:04:32.014504 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463a53c7f0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463a4e22f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 12:04:32.212792 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463a4e22f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 12:04:32.856267 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 12:04:34.413923 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 12:04:34.566439 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 12:04:34.566889 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 12:04:35.648735 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 12:04:35.665778 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 12:04:37.800083 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T12:04:37Z\n",
            "I1213 12:04:37.818657 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T12:04:37Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 12:04:38.294303 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-493\n",
            "I1213 12:04:38.296086 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-493\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 12:04:39.371652 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 12:04:39.583668 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 12:04:57.775433 139939732731648 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 12:04:57.775818 139939732731648 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 12:04:57.776552 139939732731648 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.093\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.276\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.051\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.093\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.125\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.338\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.350\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.350\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-12:04:59\n",
            "I1213 12:04:59.352725 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-12:04:59\n",
            "INFO:tensorflow:Saving dict for global step 493: DetectionBoxes_Precision/mAP = 0.093401365, DetectionBoxes_Precision/mAP (large) = 0.09341621, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.27623764, DetectionBoxes_Precision/mAP@.75IOU = 0.05130513, DetectionBoxes_Recall/AR@1 = 0.125, DetectionBoxes_Recall/AR@10 = 0.3375, DetectionBoxes_Recall/AR@100 = 0.35, DetectionBoxes_Recall/AR@100 (large) = 0.35, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.09864512, Loss/BoxClassifierLoss/localization_loss = 0.117560476, Loss/RPNLoss/localization_loss = 0.33079576, Loss/RPNLoss/objectness_loss = 0.2633012, Loss/total_loss = 0.8103025, global_step = 493, learning_rate = 0.0002, loss = 0.8103025\n",
            "I1213 12:04:59.353055 139941885183872 estimator.py:2049] Saving dict for global step 493: DetectionBoxes_Precision/mAP = 0.093401365, DetectionBoxes_Precision/mAP (large) = 0.09341621, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.27623764, DetectionBoxes_Precision/mAP@.75IOU = 0.05130513, DetectionBoxes_Recall/AR@1 = 0.125, DetectionBoxes_Recall/AR@10 = 0.3375, DetectionBoxes_Recall/AR@100 = 0.35, DetectionBoxes_Recall/AR@100 (large) = 0.35, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.09864512, Loss/BoxClassifierLoss/localization_loss = 0.117560476, Loss/RPNLoss/localization_loss = 0.33079576, Loss/RPNLoss/objectness_loss = 0.2633012, Loss/total_loss = 0.8103025, global_step = 493, learning_rate = 0.0002, loss = 0.8103025\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 493: training/model.ckpt-493\n",
            "I1213 12:04:59.358797 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 493: training/model.ckpt-493\n",
            "INFO:tensorflow:global_step/sec: 0.0195172\n",
            "I1213 12:11:32.214154 139941885183872 basic_session_run_hooks.py:692] global_step/sec: 0.0195172\n",
            "INFO:tensorflow:loss = 0.4073419, step = 501 (5123.679 sec)\n",
            "I1213 12:11:32.215212 139941885183872 basic_session_run_hooks.py:260] loss = 0.4073419, step = 501 (5123.679 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 505 into training/model.ckpt.\n",
            "I1213 12:14:48.899782 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 505 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 12:14:51.268886 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 12:14:51.269883 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 12:14:51.270020 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463a5aaa58>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 12:14:51.318219 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463a5aaa58>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463a58b2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 12:14:51.522604 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463a58b2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 12:14:52.134860 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 12:14:53.645607 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 12:14:53.808020 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 12:14:53.808499 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 12:14:55.021979 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 12:14:55.041064 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 12:14:56.807746 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T12:14:56Z\n",
            "I1213 12:14:56.827386 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T12:14:56Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 12:14:57.280051 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-505\n",
            "I1213 12:14:57.281707 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-505\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 12:14:58.363039 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 12:14:58.547508 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 12:15:17.176599 139939732731648 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 12:15:17.177051 139939732731648 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 12:15:17.178077 139939732731648 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.119\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.269\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.057\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.119\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.163\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.325\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.350\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.350\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-12:15:18\n",
            "I1213 12:15:18.716923 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-12:15:18\n",
            "INFO:tensorflow:Saving dict for global step 505: DetectionBoxes_Precision/mAP = 0.11898783, DetectionBoxes_Precision/mAP (large) = 0.119015925, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.26944837, DetectionBoxes_Precision/mAP@.75IOU = 0.05720572, DetectionBoxes_Recall/AR@1 = 0.1625, DetectionBoxes_Recall/AR@10 = 0.325, DetectionBoxes_Recall/AR@100 = 0.35, DetectionBoxes_Recall/AR@100 (large) = 0.35, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.12095478, Loss/BoxClassifierLoss/localization_loss = 0.10521954, Loss/RPNLoss/localization_loss = 0.33370844, Loss/RPNLoss/objectness_loss = 0.26964256, Loss/total_loss = 0.82952535, global_step = 505, learning_rate = 0.0002, loss = 0.82952535\n",
            "I1213 12:15:18.717288 139941885183872 estimator.py:2049] Saving dict for global step 505: DetectionBoxes_Precision/mAP = 0.11898783, DetectionBoxes_Precision/mAP (large) = 0.119015925, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.26944837, DetectionBoxes_Precision/mAP@.75IOU = 0.05720572, DetectionBoxes_Recall/AR@1 = 0.1625, DetectionBoxes_Recall/AR@10 = 0.325, DetectionBoxes_Recall/AR@100 = 0.35, DetectionBoxes_Recall/AR@100 (large) = 0.35, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.12095478, Loss/BoxClassifierLoss/localization_loss = 0.10521954, Loss/RPNLoss/localization_loss = 0.33370844, Loss/RPNLoss/objectness_loss = 0.26964256, Loss/total_loss = 0.82952535, global_step = 505, learning_rate = 0.0002, loss = 0.82952535\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 505: training/model.ckpt-505\n",
            "I1213 12:15:18.723186 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 505: training/model.ckpt-505\n",
            "INFO:tensorflow:Saving checkpoints for 517 into training/model.ckpt.\n",
            "I1213 12:25:08.288615 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 517 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 12:25:10.610926 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 12:25:10.612100 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 12:25:10.612272 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f4637c09940>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 12:25:10.659793 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f4637c09940>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f4637c678c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 12:25:10.863822 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f4637c678c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 12:25:11.464506 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 12:25:12.969133 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 12:25:13.127053 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 12:25:13.127551 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 12:25:14.273260 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 12:25:14.291476 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 12:25:16.538607 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T12:25:16Z\n",
            "I1213 12:25:16.555572 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T12:25:16Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 12:25:17.016153 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-517\n",
            "I1213 12:25:17.018006 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-517\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 12:25:18.127270 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 12:25:18.343611 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 12:25:36.872562 139939724338944 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 12:25:36.872963 139939724338944 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 12:25:36.873587 139939724338944 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.07s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.102\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.232\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.065\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.102\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.163\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.350\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.375\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.375\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-12:25:38\n",
            "I1213 12:25:38.468300 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-12:25:38\n",
            "INFO:tensorflow:Saving dict for global step 517: DetectionBoxes_Precision/mAP = 0.10180777, DetectionBoxes_Precision/mAP (large) = 0.10183007, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.2318246, DetectionBoxes_Precision/mAP@.75IOU = 0.06482543, DetectionBoxes_Recall/AR@1 = 0.1625, DetectionBoxes_Recall/AR@10 = 0.35, DetectionBoxes_Recall/AR@100 = 0.375, DetectionBoxes_Recall/AR@100 (large) = 0.375, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.17091615, Loss/BoxClassifierLoss/localization_loss = 0.11039949, Loss/RPNLoss/localization_loss = 0.3383081, Loss/RPNLoss/objectness_loss = 0.27592385, Loss/total_loss = 0.89554757, global_step = 517, learning_rate = 0.0002, loss = 0.89554757\n",
            "I1213 12:25:38.468637 139941885183872 estimator.py:2049] Saving dict for global step 517: DetectionBoxes_Precision/mAP = 0.10180777, DetectionBoxes_Precision/mAP (large) = 0.10183007, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.2318246, DetectionBoxes_Precision/mAP@.75IOU = 0.06482543, DetectionBoxes_Recall/AR@1 = 0.1625, DetectionBoxes_Recall/AR@10 = 0.35, DetectionBoxes_Recall/AR@100 = 0.375, DetectionBoxes_Recall/AR@100 (large) = 0.375, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.17091615, Loss/BoxClassifierLoss/localization_loss = 0.11039949, Loss/RPNLoss/localization_loss = 0.3383081, Loss/RPNLoss/objectness_loss = 0.27592385, Loss/total_loss = 0.89554757, global_step = 517, learning_rate = 0.0002, loss = 0.89554757\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 517: training/model.ckpt-517\n",
            "I1213 12:25:38.474141 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 517: training/model.ckpt-517\n",
            "INFO:tensorflow:Saving checkpoints for 529 into training/model.ckpt.\n",
            "I1213 12:35:27.338241 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 529 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 12:35:29.714656 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 12:35:29.715682 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 12:35:29.715832 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463ac9bbe0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 12:35:29.768526 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463ac9bbe0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463ac972f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 12:35:29.986156 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463ac972f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 12:35:30.593896 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 12:35:32.172651 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 12:35:32.327909 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 12:35:32.328396 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 12:35:33.474529 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 12:35:33.493142 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 12:35:35.284636 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T12:35:35Z\n",
            "I1213 12:35:35.303470 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T12:35:35Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 12:35:35.765851 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-529\n",
            "I1213 12:35:35.767436 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-529\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 12:35:36.813336 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 12:35:37.005901 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 12:35:55.456336 139939724338944 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 12:35:55.456787 139939724338944 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 12:35:55.457421 139939724338944 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.111\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.248\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.018\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.111\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.212\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.338\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.362\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.362\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-12:35:56\n",
            "I1213 12:35:57.000943 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-12:35:56\n",
            "INFO:tensorflow:Saving dict for global step 529: DetectionBoxes_Precision/mAP = 0.11110633, DetectionBoxes_Precision/mAP (large) = 0.11114119, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.24762882, DetectionBoxes_Precision/mAP@.75IOU = 0.017753499, DetectionBoxes_Recall/AR@1 = 0.2125, DetectionBoxes_Recall/AR@10 = 0.3375, DetectionBoxes_Recall/AR@100 = 0.3625, DetectionBoxes_Recall/AR@100 (large) = 0.3625, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.107311465, Loss/BoxClassifierLoss/localization_loss = 0.12466085, Loss/RPNLoss/localization_loss = 0.33590528, Loss/RPNLoss/objectness_loss = 0.25838962, Loss/total_loss = 0.8262673, global_step = 529, learning_rate = 0.0002, loss = 0.8262673\n",
            "I1213 12:35:57.001321 139941885183872 estimator.py:2049] Saving dict for global step 529: DetectionBoxes_Precision/mAP = 0.11110633, DetectionBoxes_Precision/mAP (large) = 0.11114119, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.24762882, DetectionBoxes_Precision/mAP@.75IOU = 0.017753499, DetectionBoxes_Recall/AR@1 = 0.2125, DetectionBoxes_Recall/AR@10 = 0.3375, DetectionBoxes_Recall/AR@100 = 0.3625, DetectionBoxes_Recall/AR@100 (large) = 0.3625, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.107311465, Loss/BoxClassifierLoss/localization_loss = 0.12466085, Loss/RPNLoss/localization_loss = 0.33590528, Loss/RPNLoss/objectness_loss = 0.25838962, Loss/total_loss = 0.8262673, global_step = 529, learning_rate = 0.0002, loss = 0.8262673\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 529: training/model.ckpt-529\n",
            "I1213 12:35:57.007027 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 529: training/model.ckpt-529\n",
            "INFO:tensorflow:Saving checkpoints for 541 into training/model.ckpt.\n",
            "I1213 12:45:46.507986 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 541 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 12:45:48.846066 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 12:45:48.847383 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 12:45:48.847521 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463866a9e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 12:45:48.894613 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463866a9e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463b125c80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 12:45:49.087469 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463b125c80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 12:45:49.693120 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 12:45:51.278164 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 12:45:51.430834 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 12:45:51.431375 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 12:45:53.001463 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 12:45:53.019475 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 12:45:54.762803 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T12:45:54Z\n",
            "I1213 12:45:54.780131 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T12:45:54Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 12:45:55.251701 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-541\n",
            "I1213 12:45:55.253664 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-541\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 12:45:56.279435 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 12:45:56.470759 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 12:46:14.861472 139939732731648 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 12:46:14.862009 139939732731648 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 12:46:14.862773 139939732731648 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.090\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.269\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.036\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.090\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.113\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.300\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.312\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.312\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-12:46:16\n",
            "I1213 12:46:16.468911 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-12:46:16\n",
            "INFO:tensorflow:Saving dict for global step 541: DetectionBoxes_Precision/mAP = 0.09014749, DetectionBoxes_Precision/mAP (large) = 0.09015544, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.2685309, DetectionBoxes_Precision/mAP@.75IOU = 0.035753574, DetectionBoxes_Recall/AR@1 = 0.1125, DetectionBoxes_Recall/AR@10 = 0.3, DetectionBoxes_Recall/AR@100 = 0.3125, DetectionBoxes_Recall/AR@100 (large) = 0.3125, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.14235812, Loss/BoxClassifierLoss/localization_loss = 0.12132267, Loss/RPNLoss/localization_loss = 0.3339424, Loss/RPNLoss/objectness_loss = 0.26986766, Loss/total_loss = 0.8674908, global_step = 541, learning_rate = 0.0002, loss = 0.8674908\n",
            "I1213 12:46:16.469277 139941885183872 estimator.py:2049] Saving dict for global step 541: DetectionBoxes_Precision/mAP = 0.09014749, DetectionBoxes_Precision/mAP (large) = 0.09015544, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.2685309, DetectionBoxes_Precision/mAP@.75IOU = 0.035753574, DetectionBoxes_Recall/AR@1 = 0.1125, DetectionBoxes_Recall/AR@10 = 0.3, DetectionBoxes_Recall/AR@100 = 0.3125, DetectionBoxes_Recall/AR@100 (large) = 0.3125, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.14235812, Loss/BoxClassifierLoss/localization_loss = 0.12132267, Loss/RPNLoss/localization_loss = 0.3339424, Loss/RPNLoss/objectness_loss = 0.26986766, Loss/total_loss = 0.8674908, global_step = 541, learning_rate = 0.0002, loss = 0.8674908\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 541: training/model.ckpt-541\n",
            "I1213 12:46:16.475182 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 541: training/model.ckpt-541\n",
            "INFO:tensorflow:Saving checkpoints for 553 into training/model.ckpt.\n",
            "I1213 12:56:06.180729 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 553 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 12:56:08.557863 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 12:56:08.558952 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 12:56:08.559091 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463a9abe10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 12:56:08.605513 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463a9abe10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463a98c2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 12:56:08.795753 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463a98c2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 12:56:09.398668 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 12:56:10.927194 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 12:56:11.083603 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 12:56:11.084044 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 12:56:12.235645 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 12:56:12.253430 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 12:56:14.022471 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T12:56:14Z\n",
            "I1213 12:56:14.039430 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T12:56:14Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 12:56:14.503381 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-553\n",
            "I1213 12:56:14.504994 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-553\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 12:56:15.535939 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 12:56:15.713305 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 12:56:33.973589 139939732731648 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 12:56:33.974004 139939732731648 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 12:56:33.974817 139939732731648 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.107\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.269\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.094\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.107\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.175\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.400\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.400\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.400\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-12:56:35\n",
            "I1213 12:56:35.564283 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-12:56:35\n",
            "INFO:tensorflow:Saving dict for global step 553: DetectionBoxes_Precision/mAP = 0.107467085, DetectionBoxes_Precision/mAP (large) = 0.107467085, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.2689769, DetectionBoxes_Precision/mAP@.75IOU = 0.093564354, DetectionBoxes_Recall/AR@1 = 0.175, DetectionBoxes_Recall/AR@10 = 0.4, DetectionBoxes_Recall/AR@100 = 0.4, DetectionBoxes_Recall/AR@100 (large) = 0.4, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.13102175, Loss/BoxClassifierLoss/localization_loss = 0.13046736, Loss/RPNLoss/localization_loss = 0.33449394, Loss/RPNLoss/objectness_loss = 0.24702454, Loss/total_loss = 0.84300756, global_step = 553, learning_rate = 0.0002, loss = 0.84300756\n",
            "I1213 12:56:35.564624 139941885183872 estimator.py:2049] Saving dict for global step 553: DetectionBoxes_Precision/mAP = 0.107467085, DetectionBoxes_Precision/mAP (large) = 0.107467085, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.2689769, DetectionBoxes_Precision/mAP@.75IOU = 0.093564354, DetectionBoxes_Recall/AR@1 = 0.175, DetectionBoxes_Recall/AR@10 = 0.4, DetectionBoxes_Recall/AR@100 = 0.4, DetectionBoxes_Recall/AR@100 (large) = 0.4, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.13102175, Loss/BoxClassifierLoss/localization_loss = 0.13046736, Loss/RPNLoss/localization_loss = 0.33449394, Loss/RPNLoss/objectness_loss = 0.24702454, Loss/total_loss = 0.84300756, global_step = 553, learning_rate = 0.0002, loss = 0.84300756\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 553: training/model.ckpt-553\n",
            "I1213 12:56:35.570756 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 553: training/model.ckpt-553\n",
            "INFO:tensorflow:Saving checkpoints for 565 into training/model.ckpt.\n",
            "I1213 13:06:24.681713 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 565 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 13:06:27.065948 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 13:06:27.067042 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 13:06:27.067217 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463822b9e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 13:06:27.117920 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463822b9e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f4638275c80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 13:06:27.316152 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f4638275c80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 13:06:27.929247 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 13:06:29.889547 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 13:06:30.068192 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 13:06:30.068722 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 13:06:31.192731 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 13:06:31.210944 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 13:06:32.932991 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T13:06:32Z\n",
            "I1213 13:06:32.950042 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T13:06:32Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 13:06:33.433942 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-565\n",
            "I1213 13:06:33.435972 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-565\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 13:06:34.530699 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 13:06:34.734854 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 13:06:53.096343 139939732731648 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 13:06:53.096755 139939732731648 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 13:06:53.097569 139939732731648 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.104\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.270\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.004\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.104\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.125\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.325\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.325\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.325\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-13:06:54\n",
            "I1213 13:06:54.663063 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-13:06:54\n",
            "INFO:tensorflow:Saving dict for global step 565: DetectionBoxes_Precision/mAP = 0.10363613, DetectionBoxes_Precision/mAP (large) = 0.10363613, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.2699476, DetectionBoxes_Precision/mAP@.75IOU = 0.0044383747, DetectionBoxes_Recall/AR@1 = 0.125, DetectionBoxes_Recall/AR@10 = 0.325, DetectionBoxes_Recall/AR@100 = 0.325, DetectionBoxes_Recall/AR@100 (large) = 0.325, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.113089845, Loss/BoxClassifierLoss/localization_loss = 0.13608342, Loss/RPNLoss/localization_loss = 0.3378234, Loss/RPNLoss/objectness_loss = 0.26056904, Loss/total_loss = 0.8475657, global_step = 565, learning_rate = 0.0002, loss = 0.8475657\n",
            "I1213 13:06:54.663451 139941885183872 estimator.py:2049] Saving dict for global step 565: DetectionBoxes_Precision/mAP = 0.10363613, DetectionBoxes_Precision/mAP (large) = 0.10363613, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.2699476, DetectionBoxes_Precision/mAP@.75IOU = 0.0044383747, DetectionBoxes_Recall/AR@1 = 0.125, DetectionBoxes_Recall/AR@10 = 0.325, DetectionBoxes_Recall/AR@100 = 0.325, DetectionBoxes_Recall/AR@100 (large) = 0.325, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.113089845, Loss/BoxClassifierLoss/localization_loss = 0.13608342, Loss/RPNLoss/localization_loss = 0.3378234, Loss/RPNLoss/objectness_loss = 0.26056904, Loss/total_loss = 0.8475657, global_step = 565, learning_rate = 0.0002, loss = 0.8475657\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 565: training/model.ckpt-565\n",
            "I1213 13:06:54.669917 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 565: training/model.ckpt-565\n",
            "INFO:tensorflow:Saving checkpoints for 577 into training/model.ckpt.\n",
            "I1213 13:16:44.310130 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 577 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 13:16:46.677152 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 13:16:46.678185 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 13:16:46.678319 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f46383cde10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 13:16:46.728355 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f46383cde10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f46383fd2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 13:16:46.933788 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f46383fd2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 13:16:47.547527 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 13:16:48.988945 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 13:16:49.136362 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 13:16:49.136816 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 13:16:50.276058 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 13:16:50.296724 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 13:16:52.427043 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T13:16:52Z\n",
            "I1213 13:16:52.444680 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T13:16:52Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 13:16:52.918545 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-577\n",
            "I1213 13:16:52.921302 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-577\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 13:16:53.986615 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 13:16:54.184722 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 13:17:12.698356 139939732731648 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 13:17:12.698742 139939732731648 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 13:17:12.699420 139939732731648 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.098\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.272\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.030\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.098\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.150\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.325\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.325\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.325\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-13:17:14\n",
            "I1213 13:17:14.272658 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-13:17:14\n",
            "INFO:tensorflow:Saving dict for global step 577: DetectionBoxes_Precision/mAP = 0.09828351, DetectionBoxes_Precision/mAP (large) = 0.09828351, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.27227724, DetectionBoxes_Precision/mAP@.75IOU = 0.03028538, DetectionBoxes_Recall/AR@1 = 0.15, DetectionBoxes_Recall/AR@10 = 0.325, DetectionBoxes_Recall/AR@100 = 0.325, DetectionBoxes_Recall/AR@100 (large) = 0.325, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.105472796, Loss/BoxClassifierLoss/localization_loss = 0.1308642, Loss/RPNLoss/localization_loss = 0.33989602, Loss/RPNLoss/objectness_loss = 0.25785208, Loss/total_loss = 0.8340851, global_step = 577, learning_rate = 0.0002, loss = 0.8340851\n",
            "I1213 13:17:14.272994 139941885183872 estimator.py:2049] Saving dict for global step 577: DetectionBoxes_Precision/mAP = 0.09828351, DetectionBoxes_Precision/mAP (large) = 0.09828351, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.27227724, DetectionBoxes_Precision/mAP@.75IOU = 0.03028538, DetectionBoxes_Recall/AR@1 = 0.15, DetectionBoxes_Recall/AR@10 = 0.325, DetectionBoxes_Recall/AR@100 = 0.325, DetectionBoxes_Recall/AR@100 (large) = 0.325, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.105472796, Loss/BoxClassifierLoss/localization_loss = 0.1308642, Loss/RPNLoss/localization_loss = 0.33989602, Loss/RPNLoss/objectness_loss = 0.25785208, Loss/total_loss = 0.8340851, global_step = 577, learning_rate = 0.0002, loss = 0.8340851\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 577: training/model.ckpt-577\n",
            "I1213 13:17:14.278384 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 577: training/model.ckpt-577\n",
            "INFO:tensorflow:Saving checkpoints for 589 into training/model.ckpt.\n",
            "I1213 13:27:03.089302 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 589 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 13:27:05.466000 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 13:27:05.467059 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 13:27:05.467222 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463ac79a58>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 13:27:05.512979 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463ac79a58>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463b079400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 13:27:05.701174 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463b079400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 13:27:06.311696 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 13:27:07.760142 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 13:27:07.903919 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 13:27:07.904366 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 13:27:09.008050 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 13:27:09.027237 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 13:27:10.789229 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T13:27:10Z\n",
            "I1213 13:27:10.808719 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T13:27:10Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 13:27:11.275035 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-589\n",
            "I1213 13:27:11.276715 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-589\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 13:27:12.297219 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 13:27:12.486577 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 13:27:30.768464 139939724338944 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 13:27:30.768883 139939724338944 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 13:27:30.769664 139939724338944 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.111\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.268\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.004\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.111\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.150\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.312\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.325\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.325\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-13:27:32\n",
            "I1213 13:27:32.348655 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-13:27:32\n",
            "INFO:tensorflow:Saving dict for global step 589: DetectionBoxes_Precision/mAP = 0.11139939, DetectionBoxes_Precision/mAP (large) = 0.11141495, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.26770753, DetectionBoxes_Precision/mAP@.75IOU = 0.004152028, DetectionBoxes_Recall/AR@1 = 0.15, DetectionBoxes_Recall/AR@10 = 0.3125, DetectionBoxes_Recall/AR@100 = 0.325, DetectionBoxes_Recall/AR@100 (large) = 0.325, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.13392109, Loss/BoxClassifierLoss/localization_loss = 0.13004199, Loss/RPNLoss/localization_loss = 0.34271115, Loss/RPNLoss/objectness_loss = 0.2521717, Loss/total_loss = 0.85884595, global_step = 589, learning_rate = 0.0002, loss = 0.85884595\n",
            "I1213 13:27:32.349005 139941885183872 estimator.py:2049] Saving dict for global step 589: DetectionBoxes_Precision/mAP = 0.11139939, DetectionBoxes_Precision/mAP (large) = 0.11141495, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.26770753, DetectionBoxes_Precision/mAP@.75IOU = 0.004152028, DetectionBoxes_Recall/AR@1 = 0.15, DetectionBoxes_Recall/AR@10 = 0.3125, DetectionBoxes_Recall/AR@100 = 0.325, DetectionBoxes_Recall/AR@100 (large) = 0.325, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.13392109, Loss/BoxClassifierLoss/localization_loss = 0.13004199, Loss/RPNLoss/localization_loss = 0.34271115, Loss/RPNLoss/objectness_loss = 0.2521717, Loss/total_loss = 0.85884595, global_step = 589, learning_rate = 0.0002, loss = 0.85884595\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 589: training/model.ckpt-589\n",
            "I1213 13:27:32.355176 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 589: training/model.ckpt-589\n",
            "INFO:tensorflow:Saving checkpoints for 601 into training/model.ckpt.\n",
            "I1213 13:37:21.430860 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 601 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 13:37:23.833184 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 13:37:23.834355 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 13:37:23.834503 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463827dc18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 13:37:23.885176 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463827dc18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f46384a86a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 13:37:24.086121 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f46384a86a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 13:37:24.677034 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 13:37:26.156141 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 13:37:26.302512 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 13:37:26.302948 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 13:37:27.422388 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 13:37:27.441345 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 13:37:29.682854 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T13:37:29Z\n",
            "I1213 13:37:29.702584 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T13:37:29Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 13:37:30.188622 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-601\n",
            "I1213 13:37:30.190303 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-601\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 13:37:31.287283 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 13:37:31.484020 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 13:37:49.949911 139939724338944 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 13:37:49.950322 139939724338944 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 13:37:49.950963 139939724338944 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.07s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.083\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.269\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.026\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.083\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.138\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.312\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.312\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.312\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-13:37:51\n",
            "I1213 13:37:51.510980 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-13:37:51\n",
            "INFO:tensorflow:Saving dict for global step 601: DetectionBoxes_Precision/mAP = 0.08325254, DetectionBoxes_Precision/mAP (large) = 0.08325254, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.2689769, DetectionBoxes_Precision/mAP@.75IOU = 0.025742574, DetectionBoxes_Recall/AR@1 = 0.1375, DetectionBoxes_Recall/AR@10 = 0.3125, DetectionBoxes_Recall/AR@100 = 0.3125, DetectionBoxes_Recall/AR@100 (large) = 0.3125, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.13429274, Loss/BoxClassifierLoss/localization_loss = 0.14038646, Loss/RPNLoss/localization_loss = 0.34073016, Loss/RPNLoss/objectness_loss = 0.2635654, Loss/total_loss = 0.8789747, global_step = 601, learning_rate = 0.0002, loss = 0.8789747\n",
            "I1213 13:37:51.511339 139941885183872 estimator.py:2049] Saving dict for global step 601: DetectionBoxes_Precision/mAP = 0.08325254, DetectionBoxes_Precision/mAP (large) = 0.08325254, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.2689769, DetectionBoxes_Precision/mAP@.75IOU = 0.025742574, DetectionBoxes_Recall/AR@1 = 0.1375, DetectionBoxes_Recall/AR@10 = 0.3125, DetectionBoxes_Recall/AR@100 = 0.3125, DetectionBoxes_Recall/AR@100 (large) = 0.3125, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.13429274, Loss/BoxClassifierLoss/localization_loss = 0.14038646, Loss/RPNLoss/localization_loss = 0.34073016, Loss/RPNLoss/objectness_loss = 0.2635654, Loss/total_loss = 0.8789747, global_step = 601, learning_rate = 0.0002, loss = 0.8789747\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 601: training/model.ckpt-601\n",
            "I1213 13:37:51.517074 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 601: training/model.ckpt-601\n",
            "INFO:tensorflow:global_step/sec: 0.0193076\n",
            "I1213 13:37:51.518824 139941885183872 basic_session_run_hooks.py:692] global_step/sec: 0.0193076\n",
            "INFO:tensorflow:loss = 0.5842593, step = 601 (5179.304 sec)\n",
            "I1213 13:37:51.519630 139941885183872 basic_session_run_hooks.py:260] loss = 0.5842593, step = 601 (5179.304 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 613 into training/model.ckpt.\n",
            "I1213 13:47:40.271896 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 613 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 13:47:42.668248 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 13:47:42.669430 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 13:47:42.669575 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463a469c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 13:47:42.716672 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463a469c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463a486378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 13:47:42.916139 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463a486378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 13:47:43.532645 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 13:47:45.026300 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 13:47:45.173033 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 13:47:45.173492 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 13:47:46.276871 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 13:47:46.294015 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 13:47:48.012583 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T13:47:48Z\n",
            "I1213 13:47:48.030161 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T13:47:48Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 13:47:48.484353 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-613\n",
            "I1213 13:47:48.486085 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-613\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 13:47:49.543571 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 13:47:49.735313 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 13:48:07.855853 139939732731648 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 13:48:07.856239 139939732731648 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 13:48:07.856930 139939732731648 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.07s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.130\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.270\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.148\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.130\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.212\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.362\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.400\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.400\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-13:48:09\n",
            "I1213 13:48:09.405221 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-13:48:09\n",
            "INFO:tensorflow:Saving dict for global step 613: DetectionBoxes_Precision/mAP = 0.13043362, DetectionBoxes_Precision/mAP (large) = 0.13047703, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.27047706, DetectionBoxes_Precision/mAP@.75IOU = 0.14840877, DetectionBoxes_Recall/AR@1 = 0.2125, DetectionBoxes_Recall/AR@10 = 0.3625, DetectionBoxes_Recall/AR@100 = 0.4, DetectionBoxes_Recall/AR@100 (large) = 0.4, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.13502204, Loss/BoxClassifierLoss/localization_loss = 0.13962597, Loss/RPNLoss/localization_loss = 0.34150487, Loss/RPNLoss/objectness_loss = 0.26004696, Loss/total_loss = 0.87619984, global_step = 613, learning_rate = 0.0002, loss = 0.87619984\n",
            "I1213 13:48:09.405550 139941885183872 estimator.py:2049] Saving dict for global step 613: DetectionBoxes_Precision/mAP = 0.13043362, DetectionBoxes_Precision/mAP (large) = 0.13047703, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.27047706, DetectionBoxes_Precision/mAP@.75IOU = 0.14840877, DetectionBoxes_Recall/AR@1 = 0.2125, DetectionBoxes_Recall/AR@10 = 0.3625, DetectionBoxes_Recall/AR@100 = 0.4, DetectionBoxes_Recall/AR@100 (large) = 0.4, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.13502204, Loss/BoxClassifierLoss/localization_loss = 0.13962597, Loss/RPNLoss/localization_loss = 0.34150487, Loss/RPNLoss/objectness_loss = 0.26004696, Loss/total_loss = 0.87619984, global_step = 613, learning_rate = 0.0002, loss = 0.87619984\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 613: training/model.ckpt-613\n",
            "I1213 13:48:09.411081 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 613: training/model.ckpt-613\n",
            "INFO:tensorflow:Saving checkpoints for 625 into training/model.ckpt.\n",
            "I1213 13:57:58.010678 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 625 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 13:58:00.356816 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 13:58:00.357945 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 13:58:00.358084 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463a53a940>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 13:58:00.404149 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463a53a940>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f46386388c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 13:58:00.592320 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f46386388c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 13:58:01.229470 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 13:58:02.701200 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 13:58:02.854143 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 13:58:02.854639 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 13:58:04.382375 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 13:58:04.400446 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 13:58:06.152173 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T13:58:06Z\n",
            "I1213 13:58:06.170405 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T13:58:06Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 13:58:06.629480 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-625\n",
            "I1213 13:58:06.631055 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-625\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 13:58:07.630658 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 13:58:07.826689 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 13:58:26.273596 139939732731648 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 13:58:26.274003 139939732731648 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 13:58:26.274856 139939732731648 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.086\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.229\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.021\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.086\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.113\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.375\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.375\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.375\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-13:58:27\n",
            "I1213 13:58:27.823055 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-13:58:27\n",
            "INFO:tensorflow:Saving dict for global step 625: DetectionBoxes_Precision/mAP = 0.08562688, DetectionBoxes_Precision/mAP (large) = 0.08564627, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.2286191, DetectionBoxes_Precision/mAP@.75IOU = 0.021023102, DetectionBoxes_Recall/AR@1 = 0.1125, DetectionBoxes_Recall/AR@10 = 0.375, DetectionBoxes_Recall/AR@100 = 0.375, DetectionBoxes_Recall/AR@100 (large) = 0.375, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.14126107, Loss/BoxClassifierLoss/localization_loss = 0.13349672, Loss/RPNLoss/localization_loss = 0.3423222, Loss/RPNLoss/objectness_loss = 0.26349506, Loss/total_loss = 0.8805751, global_step = 625, learning_rate = 0.0002, loss = 0.8805751\n",
            "I1213 13:58:27.823415 139941885183872 estimator.py:2049] Saving dict for global step 625: DetectionBoxes_Precision/mAP = 0.08562688, DetectionBoxes_Precision/mAP (large) = 0.08564627, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.2286191, DetectionBoxes_Precision/mAP@.75IOU = 0.021023102, DetectionBoxes_Recall/AR@1 = 0.1125, DetectionBoxes_Recall/AR@10 = 0.375, DetectionBoxes_Recall/AR@100 = 0.375, DetectionBoxes_Recall/AR@100 (large) = 0.375, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.14126107, Loss/BoxClassifierLoss/localization_loss = 0.13349672, Loss/RPNLoss/localization_loss = 0.3423222, Loss/RPNLoss/objectness_loss = 0.26349506, Loss/total_loss = 0.8805751, global_step = 625, learning_rate = 0.0002, loss = 0.8805751\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 625: training/model.ckpt-625\n",
            "I1213 13:58:27.828864 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 625: training/model.ckpt-625\n",
            "INFO:tensorflow:Saving checkpoints for 637 into training/model.ckpt.\n",
            "I1213 14:08:15.981988 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 637 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 14:08:18.372643 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 14:08:18.373598 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 14:08:18.373735 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463b283e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 14:08:18.421472 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463b283e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463b24b2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 14:08:18.610857 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463b24b2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 14:08:19.220861 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 14:08:20.688750 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 14:08:20.837208 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 14:08:20.837660 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 14:08:21.938323 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 14:08:21.956460 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 14:08:23.717745 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T14:08:23Z\n",
            "I1213 14:08:23.736777 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T14:08:23Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 14:08:24.229534 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-637\n",
            "I1213 14:08:24.231230 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-637\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 14:08:25.305937 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 14:08:25.490884 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 14:08:43.717372 139939724338944 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 14:08:43.717793 139939724338944 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 14:08:43.718597 139939724338944 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.07s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.114\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.271\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.145\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.114\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.163\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.362\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.362\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.362\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-14:08:45\n",
            "I1213 14:08:45.297715 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-14:08:45\n",
            "INFO:tensorflow:Saving dict for global step 637: DetectionBoxes_Precision/mAP = 0.11403227, DetectionBoxes_Precision/mAP (large) = 0.11403227, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.2710396, DetectionBoxes_Precision/mAP@.75IOU = 0.14487988, DetectionBoxes_Recall/AR@1 = 0.1625, DetectionBoxes_Recall/AR@10 = 0.3625, DetectionBoxes_Recall/AR@100 = 0.3625, DetectionBoxes_Recall/AR@100 (large) = 0.3625, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.11927922, Loss/BoxClassifierLoss/localization_loss = 0.12969081, Loss/RPNLoss/localization_loss = 0.34028676, Loss/RPNLoss/objectness_loss = 0.2606066, Loss/total_loss = 0.84986335, global_step = 637, learning_rate = 0.0002, loss = 0.84986335\n",
            "I1213 14:08:45.298053 139941885183872 estimator.py:2049] Saving dict for global step 637: DetectionBoxes_Precision/mAP = 0.11403227, DetectionBoxes_Precision/mAP (large) = 0.11403227, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.2710396, DetectionBoxes_Precision/mAP@.75IOU = 0.14487988, DetectionBoxes_Recall/AR@1 = 0.1625, DetectionBoxes_Recall/AR@10 = 0.3625, DetectionBoxes_Recall/AR@100 = 0.3625, DetectionBoxes_Recall/AR@100 (large) = 0.3625, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.11927922, Loss/BoxClassifierLoss/localization_loss = 0.12969081, Loss/RPNLoss/localization_loss = 0.34028676, Loss/RPNLoss/objectness_loss = 0.2606066, Loss/total_loss = 0.84986335, global_step = 637, learning_rate = 0.0002, loss = 0.84986335\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 637: training/model.ckpt-637\n",
            "I1213 14:08:45.303468 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 637: training/model.ckpt-637\n",
            "INFO:tensorflow:Saving checkpoints for 649 into training/model.ckpt.\n",
            "I1213 14:18:35.288418 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 649 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 14:18:37.620632 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 14:18:37.621744 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 14:18:37.621904 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f4637ee2940>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 14:18:37.669523 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f4637ee2940>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f46382a88c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 14:18:37.868233 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f46382a88c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 14:18:38.497854 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 14:18:40.459969 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 14:18:40.635265 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 14:18:40.635695 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 14:18:41.714561 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 14:18:41.732868 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 14:18:43.510699 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T14:18:43Z\n",
            "I1213 14:18:43.529066 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T14:18:43Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 14:18:43.989844 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-649\n",
            "I1213 14:18:43.991600 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-649\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 14:18:45.019037 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 14:18:45.229259 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 14:19:03.760397 139939724338944 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 14:19:03.760822 139939724338944 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 14:19:03.761565 139939724338944 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.116\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.274\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.098\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.116\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.188\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.350\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.350\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.350\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-14:19:05\n",
            "I1213 14:19:05.388450 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-14:19:05\n",
            "INFO:tensorflow:Saving dict for global step 649: DetectionBoxes_Precision/mAP = 0.116272405, DetectionBoxes_Precision/mAP (large) = 0.116272405, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.27447745, DetectionBoxes_Precision/mAP@.75IOU = 0.09824119, DetectionBoxes_Recall/AR@1 = 0.1875, DetectionBoxes_Recall/AR@10 = 0.35, DetectionBoxes_Recall/AR@100 = 0.35, DetectionBoxes_Recall/AR@100 (large) = 0.35, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.12765986, Loss/BoxClassifierLoss/localization_loss = 0.124207534, Loss/RPNLoss/localization_loss = 0.33965614, Loss/RPNLoss/objectness_loss = 0.26137513, Loss/total_loss = 0.8528986, global_step = 649, learning_rate = 0.0002, loss = 0.8528986\n",
            "I1213 14:19:05.388810 139941885183872 estimator.py:2049] Saving dict for global step 649: DetectionBoxes_Precision/mAP = 0.116272405, DetectionBoxes_Precision/mAP (large) = 0.116272405, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.27447745, DetectionBoxes_Precision/mAP@.75IOU = 0.09824119, DetectionBoxes_Recall/AR@1 = 0.1875, DetectionBoxes_Recall/AR@10 = 0.35, DetectionBoxes_Recall/AR@100 = 0.35, DetectionBoxes_Recall/AR@100 (large) = 0.35, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.12765986, Loss/BoxClassifierLoss/localization_loss = 0.124207534, Loss/RPNLoss/localization_loss = 0.33965614, Loss/RPNLoss/objectness_loss = 0.26137513, Loss/total_loss = 0.8528986, global_step = 649, learning_rate = 0.0002, loss = 0.8528986\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 649: training/model.ckpt-649\n",
            "I1213 14:19:05.399140 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 649: training/model.ckpt-649\n",
            "INFO:tensorflow:Saving checkpoints for 661 into training/model.ckpt.\n",
            "I1213 14:28:55.184472 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 661 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 14:28:57.541863 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 14:28:57.542804 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 14:28:57.542938 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463b3b0e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 14:28:57.590584 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463b3b0e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463b3952f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 14:28:57.791274 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463b3952f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 14:28:58.414254 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 14:28:59.951686 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 14:29:00.106607 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 14:29:00.107069 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 14:29:01.216749 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 14:29:01.235698 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 14:29:02.961098 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T14:29:02Z\n",
            "I1213 14:29:02.979002 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T14:29:02Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 14:29:03.770710 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-661\n",
            "I1213 14:29:03.772399 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-661\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 14:29:04.848232 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 14:29:05.032467 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 14:29:23.577974 139939732731648 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 14:29:23.578498 139939732731648 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 14:29:23.579375 139939732731648 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.141\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.307\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.119\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.141\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.237\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.362\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.362\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.362\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-14:29:25\n",
            "I1213 14:29:25.161846 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-14:29:25\n",
            "INFO:tensorflow:Saving dict for global step 661: DetectionBoxes_Precision/mAP = 0.14075862, DetectionBoxes_Precision/mAP (large) = 0.14075862, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.3071075, DetectionBoxes_Precision/mAP@.75IOU = 0.118953325, DetectionBoxes_Recall/AR@1 = 0.2375, DetectionBoxes_Recall/AR@10 = 0.3625, DetectionBoxes_Recall/AR@100 = 0.3625, DetectionBoxes_Recall/AR@100 (large) = 0.3625, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.18974228, Loss/BoxClassifierLoss/localization_loss = 0.12523915, Loss/RPNLoss/localization_loss = 0.34409675, Loss/RPNLoss/objectness_loss = 0.26702663, Loss/total_loss = 0.9261048, global_step = 661, learning_rate = 0.0002, loss = 0.9261048\n",
            "I1213 14:29:25.162215 139941885183872 estimator.py:2049] Saving dict for global step 661: DetectionBoxes_Precision/mAP = 0.14075862, DetectionBoxes_Precision/mAP (large) = 0.14075862, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.3071075, DetectionBoxes_Precision/mAP@.75IOU = 0.118953325, DetectionBoxes_Recall/AR@1 = 0.2375, DetectionBoxes_Recall/AR@10 = 0.3625, DetectionBoxes_Recall/AR@100 = 0.3625, DetectionBoxes_Recall/AR@100 (large) = 0.3625, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.18974228, Loss/BoxClassifierLoss/localization_loss = 0.12523915, Loss/RPNLoss/localization_loss = 0.34409675, Loss/RPNLoss/objectness_loss = 0.26702663, Loss/total_loss = 0.9261048, global_step = 661, learning_rate = 0.0002, loss = 0.9261048\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 661: training/model.ckpt-661\n",
            "I1213 14:29:25.168516 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 661: training/model.ckpt-661\n",
            "INFO:tensorflow:Saving checkpoints for 673 into training/model.ckpt.\n",
            "I1213 14:39:15.169849 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 673 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 14:39:17.503158 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 14:39:17.504158 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 14:39:17.504297 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463baf3240>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 14:39:17.550768 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463baf3240>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f46408f0378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 14:39:17.745043 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f46408f0378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 14:39:18.348247 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 14:39:19.873835 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 14:39:20.018596 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 14:39:20.019047 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 14:39:21.166235 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 14:39:21.186249 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 14:39:23.109435 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T14:39:23Z\n",
            "I1213 14:39:23.126950 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T14:39:23Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 14:39:23.599395 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-673\n",
            "I1213 14:39:23.600982 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-673\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 14:39:24.643292 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 14:39:24.844757 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 14:39:43.190277 139939724338944 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 14:39:43.190699 139939724338944 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 14:39:43.191421 139939724338944 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.07s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.147\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.371\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.043\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.147\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.237\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.312\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.312\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.312\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-14:39:44\n",
            "I1213 14:39:44.746461 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-14:39:44\n",
            "INFO:tensorflow:Saving dict for global step 673: DetectionBoxes_Precision/mAP = 0.14717107, DetectionBoxes_Precision/mAP (large) = 0.14717107, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.3707085, DetectionBoxes_Precision/mAP@.75IOU = 0.04290429, DetectionBoxes_Recall/AR@1 = 0.2375, DetectionBoxes_Recall/AR@10 = 0.3125, DetectionBoxes_Recall/AR@100 = 0.3125, DetectionBoxes_Recall/AR@100 (large) = 0.3125, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.10842863, Loss/BoxClassifierLoss/localization_loss = 0.12797509, Loss/RPNLoss/localization_loss = 0.33887628, Loss/RPNLoss/objectness_loss = 0.25575817, Loss/total_loss = 0.8310382, global_step = 673, learning_rate = 0.0002, loss = 0.8310382\n",
            "I1213 14:39:44.746790 139941885183872 estimator.py:2049] Saving dict for global step 673: DetectionBoxes_Precision/mAP = 0.14717107, DetectionBoxes_Precision/mAP (large) = 0.14717107, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.3707085, DetectionBoxes_Precision/mAP@.75IOU = 0.04290429, DetectionBoxes_Recall/AR@1 = 0.2375, DetectionBoxes_Recall/AR@10 = 0.3125, DetectionBoxes_Recall/AR@100 = 0.3125, DetectionBoxes_Recall/AR@100 (large) = 0.3125, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.10842863, Loss/BoxClassifierLoss/localization_loss = 0.12797509, Loss/RPNLoss/localization_loss = 0.33887628, Loss/RPNLoss/objectness_loss = 0.25575817, Loss/total_loss = 0.8310382, global_step = 673, learning_rate = 0.0002, loss = 0.8310382\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 673: training/model.ckpt-673\n",
            "I1213 14:39:44.752237 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 673: training/model.ckpt-673\n",
            "INFO:tensorflow:Saving checkpoints for 685 into training/model.ckpt.\n",
            "I1213 14:49:33.651882 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 685 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 14:49:36.027630 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 14:49:36.028692 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 14:49:36.028836 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f4638236780>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 14:49:36.077915 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f4638236780>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f46384f1d90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 14:49:36.280814 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f46384f1d90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 14:49:36.883959 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 14:49:38.412230 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 14:49:38.564916 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 14:49:38.565400 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 14:49:39.700149 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 14:49:39.717327 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 14:49:41.921567 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T14:49:41Z\n",
            "I1213 14:49:41.940546 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T14:49:41Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 14:49:42.394658 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-685\n",
            "I1213 14:49:42.396301 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-685\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 14:49:43.479509 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 14:49:43.669594 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 14:50:02.096799 139939732731648 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 14:50:02.097260 139939732731648 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 14:50:02.097879 139939732731648 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.07s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.120\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.272\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.137\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.120\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.175\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.350\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.375\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.375\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-14:50:03\n",
            "I1213 14:50:03.635475 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-14:50:03\n",
            "INFO:tensorflow:Saving dict for global step 685: DetectionBoxes_Precision/mAP = 0.12017502, DetectionBoxes_Precision/mAP (large) = 0.1202265, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.27227724, DetectionBoxes_Precision/mAP@.75IOU = 0.13726373, DetectionBoxes_Recall/AR@1 = 0.175, DetectionBoxes_Recall/AR@10 = 0.35, DetectionBoxes_Recall/AR@100 = 0.375, DetectionBoxes_Recall/AR@100 (large) = 0.375, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.1044382, Loss/BoxClassifierLoss/localization_loss = 0.1389849, Loss/RPNLoss/localization_loss = 0.3425621, Loss/RPNLoss/objectness_loss = 0.2598143, Loss/total_loss = 0.84579945, global_step = 685, learning_rate = 0.0002, loss = 0.84579945\n",
            "I1213 14:50:03.635807 139941885183872 estimator.py:2049] Saving dict for global step 685: DetectionBoxes_Precision/mAP = 0.12017502, DetectionBoxes_Precision/mAP (large) = 0.1202265, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.27227724, DetectionBoxes_Precision/mAP@.75IOU = 0.13726373, DetectionBoxes_Recall/AR@1 = 0.175, DetectionBoxes_Recall/AR@10 = 0.35, DetectionBoxes_Recall/AR@100 = 0.375, DetectionBoxes_Recall/AR@100 (large) = 0.375, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.1044382, Loss/BoxClassifierLoss/localization_loss = 0.1389849, Loss/RPNLoss/localization_loss = 0.3425621, Loss/RPNLoss/objectness_loss = 0.2598143, Loss/total_loss = 0.84579945, global_step = 685, learning_rate = 0.0002, loss = 0.84579945\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 685: training/model.ckpt-685\n",
            "I1213 14:50:03.641869 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 685: training/model.ckpt-685\n",
            "INFO:tensorflow:Saving checkpoints for 697 into training/model.ckpt.\n",
            "I1213 14:59:54.631854 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 697 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 14:59:57.082880 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 14:59:57.084943 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 14:59:57.085134 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f4638a65c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 14:59:57.134909 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f4638a65c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f4638a5f2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 14:59:57.336750 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f4638a5f2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 14:59:57.982601 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 14:59:59.511998 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 14:59:59.656845 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 14:59:59.657310 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 15:00:00.789446 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 15:00:00.808482 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 15:00:02.567708 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T15:00:02Z\n",
            "I1213 15:00:02.584800 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T15:00:02Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 15:00:03.053082 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-697\n",
            "I1213 15:00:03.055163 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-697\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 15:00:04.151242 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 15:00:04.346020 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 15:00:22.852164 139939724338944 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 15:00:22.852557 139939724338944 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 15:00:22.853308 139939724338944 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.07s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.125\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.315\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.100\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.125\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.163\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.362\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.375\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.375\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-15:00:24\n",
            "I1213 15:00:24.402193 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-15:00:24\n",
            "INFO:tensorflow:Saving dict for global step 697: DetectionBoxes_Precision/mAP = 0.12496447, DetectionBoxes_Precision/mAP (large) = 0.1249735, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.31518152, DetectionBoxes_Precision/mAP@.75IOU = 0.09971712, DetectionBoxes_Recall/AR@1 = 0.1625, DetectionBoxes_Recall/AR@10 = 0.3625, DetectionBoxes_Recall/AR@100 = 0.375, DetectionBoxes_Recall/AR@100 (large) = 0.375, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.17129041, Loss/BoxClassifierLoss/localization_loss = 0.13974065, Loss/RPNLoss/localization_loss = 0.34204513, Loss/RPNLoss/objectness_loss = 0.269791, Loss/total_loss = 0.92286724, global_step = 697, learning_rate = 0.0002, loss = 0.92286724\n",
            "I1213 15:00:24.402545 139941885183872 estimator.py:2049] Saving dict for global step 697: DetectionBoxes_Precision/mAP = 0.12496447, DetectionBoxes_Precision/mAP (large) = 0.1249735, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.31518152, DetectionBoxes_Precision/mAP@.75IOU = 0.09971712, DetectionBoxes_Recall/AR@1 = 0.1625, DetectionBoxes_Recall/AR@10 = 0.3625, DetectionBoxes_Recall/AR@100 = 0.375, DetectionBoxes_Recall/AR@100 (large) = 0.375, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.17129041, Loss/BoxClassifierLoss/localization_loss = 0.13974065, Loss/RPNLoss/localization_loss = 0.34204513, Loss/RPNLoss/objectness_loss = 0.269791, Loss/total_loss = 0.92286724, global_step = 697, learning_rate = 0.0002, loss = 0.92286724\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 697: training/model.ckpt-697\n",
            "I1213 15:00:24.408979 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 697: training/model.ckpt-697\n",
            "INFO:tensorflow:global_step/sec: 0.019418\n",
            "I1213 15:03:41.387041 139941885183872 basic_session_run_hooks.py:692] global_step/sec: 0.019418\n",
            "INFO:tensorflow:loss = 0.4447961, step = 701 (5149.869 sec)\n",
            "I1213 15:03:41.388181 139941885183872 basic_session_run_hooks.py:260] loss = 0.4447961, step = 701 (5149.869 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 709 into training/model.ckpt.\n",
            "I1213 15:10:14.622091 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 709 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 15:10:16.996996 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 15:10:16.998079 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 15:10:16.998243 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463b012c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 15:10:17.045084 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463b012c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463a4b76a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 15:10:17.248389 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463a4b76a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 15:10:17.856603 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 15:10:19.376546 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 15:10:19.533669 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 15:10:19.534154 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 15:10:20.661808 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 15:10:20.680680 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 15:10:22.957670 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T15:10:22Z\n",
            "I1213 15:10:22.976954 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T15:10:22Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 15:10:23.454953 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-709\n",
            "I1213 15:10:23.456607 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-709\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 15:10:24.501543 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 15:10:24.702782 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 15:10:43.152177 139939724338944 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 15:10:43.152569 139939724338944 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 15:10:43.153194 139939724338944 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.134\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.273\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.117\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.134\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.200\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.338\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.338\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.338\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-15:10:44\n",
            "I1213 15:10:44.715858 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-15:10:44\n",
            "INFO:tensorflow:Saving dict for global step 709: DetectionBoxes_Precision/mAP = 0.13373844, DetectionBoxes_Precision/mAP (large) = 0.13373844, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.27296007, DetectionBoxes_Precision/mAP@.75IOU = 0.116721675, DetectionBoxes_Recall/AR@1 = 0.2, DetectionBoxes_Recall/AR@10 = 0.3375, DetectionBoxes_Recall/AR@100 = 0.3375, DetectionBoxes_Recall/AR@100 (large) = 0.3375, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.111341804, Loss/BoxClassifierLoss/localization_loss = 0.1276708, Loss/RPNLoss/localization_loss = 0.3418598, Loss/RPNLoss/objectness_loss = 0.25044623, Loss/total_loss = 0.8313186, global_step = 709, learning_rate = 0.0002, loss = 0.8313186\n",
            "I1213 15:10:44.716206 139941885183872 estimator.py:2049] Saving dict for global step 709: DetectionBoxes_Precision/mAP = 0.13373844, DetectionBoxes_Precision/mAP (large) = 0.13373844, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.27296007, DetectionBoxes_Precision/mAP@.75IOU = 0.116721675, DetectionBoxes_Recall/AR@1 = 0.2, DetectionBoxes_Recall/AR@10 = 0.3375, DetectionBoxes_Recall/AR@100 = 0.3375, DetectionBoxes_Recall/AR@100 (large) = 0.3375, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.111341804, Loss/BoxClassifierLoss/localization_loss = 0.1276708, Loss/RPNLoss/localization_loss = 0.3418598, Loss/RPNLoss/objectness_loss = 0.25044623, Loss/total_loss = 0.8313186, global_step = 709, learning_rate = 0.0002, loss = 0.8313186\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 709: training/model.ckpt-709\n",
            "I1213 15:10:44.722259 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 709: training/model.ckpt-709\n",
            "INFO:tensorflow:Saving checkpoints for 721 into training/model.ckpt.\n",
            "I1213 15:20:35.570312 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 721 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 15:20:37.985694 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 15:20:37.986649 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 15:20:37.986790 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463803cc18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 15:20:38.033726 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463803cc18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f46380322f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 15:20:38.238540 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f46380322f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 15:20:38.854618 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 15:20:40.365729 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 15:20:40.509077 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 15:20:40.509537 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 15:20:41.623368 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 15:20:41.641649 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 15:20:43.425869 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T15:20:43Z\n",
            "I1213 15:20:43.443742 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T15:20:43Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 15:20:43.907060 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-721\n",
            "I1213 15:20:43.908704 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-721\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 15:20:44.936863 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 15:20:45.128363 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 15:21:03.302699 139939724338944 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 15:21:03.303268 139939724338944 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 15:21:03.304045 139939724338944 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.07s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.165\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.377\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.146\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.165\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.163\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.312\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.312\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.312\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-15:21:04\n",
            "I1213 15:21:04.846408 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-15:21:04\n",
            "INFO:tensorflow:Saving dict for global step 721: DetectionBoxes_Precision/mAP = 0.16460212, DetectionBoxes_Precision/mAP (large) = 0.16460212, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.37718058, DetectionBoxes_Precision/mAP@.75IOU = 0.14587459, DetectionBoxes_Recall/AR@1 = 0.1625, DetectionBoxes_Recall/AR@10 = 0.3125, DetectionBoxes_Recall/AR@100 = 0.3125, DetectionBoxes_Recall/AR@100 (large) = 0.3125, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.14771967, Loss/BoxClassifierLoss/localization_loss = 0.14617471, Loss/RPNLoss/localization_loss = 0.34082642, Loss/RPNLoss/objectness_loss = 0.25656664, Loss/total_loss = 0.89128745, global_step = 721, learning_rate = 0.0002, loss = 0.89128745\n",
            "I1213 15:21:04.846742 139941885183872 estimator.py:2049] Saving dict for global step 721: DetectionBoxes_Precision/mAP = 0.16460212, DetectionBoxes_Precision/mAP (large) = 0.16460212, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.37718058, DetectionBoxes_Precision/mAP@.75IOU = 0.14587459, DetectionBoxes_Recall/AR@1 = 0.1625, DetectionBoxes_Recall/AR@10 = 0.3125, DetectionBoxes_Recall/AR@100 = 0.3125, DetectionBoxes_Recall/AR@100 (large) = 0.3125, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.14771967, Loss/BoxClassifierLoss/localization_loss = 0.14617471, Loss/RPNLoss/localization_loss = 0.34082642, Loss/RPNLoss/objectness_loss = 0.25656664, Loss/total_loss = 0.89128745, global_step = 721, learning_rate = 0.0002, loss = 0.89128745\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 721: training/model.ckpt-721\n",
            "I1213 15:21:04.852289 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 721: training/model.ckpt-721\n",
            "INFO:tensorflow:Saving checkpoints for 733 into training/model.ckpt.\n",
            "I1213 15:30:55.729766 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 733 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 15:30:58.078629 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 15:30:58.080503 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 15:30:58.080646 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f4637fa2940>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 15:30:58.128329 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f4637fa2940>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f46381288c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 15:30:58.332671 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f46381288c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 15:30:58.927074 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 15:31:00.423020 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 15:31:01.048079 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 15:31:01.048534 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 15:31:02.150494 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 15:31:02.167904 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 15:31:03.942433 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T15:31:03Z\n",
            "I1213 15:31:03.959602 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T15:31:03Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 15:31:04.435656 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-733\n",
            "I1213 15:31:04.437324 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-733\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 15:31:05.541231 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 15:31:05.739437 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 15:31:24.098213 139939724338944 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 15:31:24.098632 139939724338944 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 15:31:24.099266 139939724338944 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.163\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.369\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.016\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.163\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.237\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.312\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.325\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.325\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-15:31:25\n",
            "I1213 15:31:25.729895 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-15:31:25\n",
            "INFO:tensorflow:Saving dict for global step 733: DetectionBoxes_Precision/mAP = 0.16309504, DetectionBoxes_Precision/mAP (large) = 0.16310932, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.36932823, DetectionBoxes_Precision/mAP@.75IOU = 0.01608911, DetectionBoxes_Recall/AR@1 = 0.2375, DetectionBoxes_Recall/AR@10 = 0.3125, DetectionBoxes_Recall/AR@100 = 0.325, DetectionBoxes_Recall/AR@100 (large) = 0.325, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.09603598, Loss/BoxClassifierLoss/localization_loss = 0.10626239, Loss/RPNLoss/localization_loss = 0.34712386, Loss/RPNLoss/objectness_loss = 0.26134562, Loss/total_loss = 0.8107678, global_step = 733, learning_rate = 0.0002, loss = 0.8107678\n",
            "I1213 15:31:25.730250 139941885183872 estimator.py:2049] Saving dict for global step 733: DetectionBoxes_Precision/mAP = 0.16309504, DetectionBoxes_Precision/mAP (large) = 0.16310932, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.36932823, DetectionBoxes_Precision/mAP@.75IOU = 0.01608911, DetectionBoxes_Recall/AR@1 = 0.2375, DetectionBoxes_Recall/AR@10 = 0.3125, DetectionBoxes_Recall/AR@100 = 0.325, DetectionBoxes_Recall/AR@100 (large) = 0.325, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.09603598, Loss/BoxClassifierLoss/localization_loss = 0.10626239, Loss/RPNLoss/localization_loss = 0.34712386, Loss/RPNLoss/objectness_loss = 0.26134562, Loss/total_loss = 0.8107678, global_step = 733, learning_rate = 0.0002, loss = 0.8107678\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 733: training/model.ckpt-733\n",
            "I1213 15:31:25.736246 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 733: training/model.ckpt-733\n",
            "INFO:tensorflow:Saving checkpoints for 745 into training/model.ckpt.\n",
            "I1213 15:41:16.324468 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 745 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 15:41:18.688015 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 15:41:18.689157 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 15:41:18.689304 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463b86be10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 15:41:18.737207 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463b86be10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463b86c2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 15:41:18.936785 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463b86c2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 15:41:19.556389 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 15:41:21.042859 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 15:41:21.201084 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 15:41:21.201547 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 15:41:22.358155 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 15:41:22.377050 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 15:41:24.138477 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T15:41:24Z\n",
            "I1213 15:41:24.159166 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T15:41:24Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 15:41:24.619167 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-745\n",
            "I1213 15:41:24.620894 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-745\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 15:41:25.672629 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 15:41:25.881904 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 15:41:44.250232 139939724338944 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 15:41:44.250671 139939724338944 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 15:41:44.251430 139939724338944 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.095\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.216\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.057\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.095\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.150\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.388\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.388\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.388\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-15:41:45\n",
            "I1213 15:41:45.801735 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-15:41:45\n",
            "INFO:tensorflow:Saving dict for global step 745: DetectionBoxes_Precision/mAP = 0.09504479, DetectionBoxes_Precision/mAP (large) = 0.09504479, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.21625413, DetectionBoxes_Precision/mAP@.75IOU = 0.05742574, DetectionBoxes_Recall/AR@1 = 0.15, DetectionBoxes_Recall/AR@10 = 0.3875, DetectionBoxes_Recall/AR@100 = 0.3875, DetectionBoxes_Recall/AR@100 (large) = 0.3875, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.14285995, Loss/BoxClassifierLoss/localization_loss = 0.13036145, Loss/RPNLoss/localization_loss = 0.34086785, Loss/RPNLoss/objectness_loss = 0.26612896, Loss/total_loss = 0.8802182, global_step = 745, learning_rate = 0.0002, loss = 0.8802182\n",
            "I1213 15:41:45.802089 139941885183872 estimator.py:2049] Saving dict for global step 745: DetectionBoxes_Precision/mAP = 0.09504479, DetectionBoxes_Precision/mAP (large) = 0.09504479, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.21625413, DetectionBoxes_Precision/mAP@.75IOU = 0.05742574, DetectionBoxes_Recall/AR@1 = 0.15, DetectionBoxes_Recall/AR@10 = 0.3875, DetectionBoxes_Recall/AR@100 = 0.3875, DetectionBoxes_Recall/AR@100 (large) = 0.3875, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.14285995, Loss/BoxClassifierLoss/localization_loss = 0.13036145, Loss/RPNLoss/localization_loss = 0.34086785, Loss/RPNLoss/objectness_loss = 0.26612896, Loss/total_loss = 0.8802182, global_step = 745, learning_rate = 0.0002, loss = 0.8802182\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 745: training/model.ckpt-745\n",
            "I1213 15:41:45.808179 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 745: training/model.ckpt-745\n",
            "INFO:tensorflow:Saving checkpoints for 757 into training/model.ckpt.\n",
            "I1213 15:51:37.397254 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 757 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 15:51:39.770344 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 15:51:39.771656 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 15:51:39.771848 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463abc2940>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 15:51:39.823029 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463abc2940>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463af2e8c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 15:51:40.023420 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463af2e8c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 15:51:41.132211 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 15:51:42.627032 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 15:51:42.794297 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 15:51:42.794856 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 15:51:43.939312 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 15:51:43.958364 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 15:51:45.735009 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T15:51:45Z\n",
            "I1213 15:51:45.753775 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T15:51:45Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 15:51:46.234772 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-757\n",
            "I1213 15:51:46.236887 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-757\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 15:51:47.248577 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 15:51:47.437702 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 15:52:06.031482 139939732731648 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 15:52:06.031898 139939732731648 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 15:52:06.032697 139939732731648 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.119\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.307\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.043\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.119\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.200\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.350\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.350\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.350\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-15:52:07\n",
            "I1213 15:52:07.624722 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-15:52:07\n",
            "INFO:tensorflow:Saving dict for global step 757: DetectionBoxes_Precision/mAP = 0.11880317, DetectionBoxes_Precision/mAP (large) = 0.11885675, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.30654493, DetectionBoxes_Precision/mAP@.75IOU = 0.04290429, DetectionBoxes_Recall/AR@1 = 0.2, DetectionBoxes_Recall/AR@10 = 0.35, DetectionBoxes_Recall/AR@100 = 0.35, DetectionBoxes_Recall/AR@100 (large) = 0.35, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.115084164, Loss/BoxClassifierLoss/localization_loss = 0.12525977, Loss/RPNLoss/localization_loss = 0.34112686, Loss/RPNLoss/objectness_loss = 0.25647447, Loss/total_loss = 0.8379452, global_step = 757, learning_rate = 0.0002, loss = 0.8379452\n",
            "I1213 15:52:07.625064 139941885183872 estimator.py:2049] Saving dict for global step 757: DetectionBoxes_Precision/mAP = 0.11880317, DetectionBoxes_Precision/mAP (large) = 0.11885675, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.30654493, DetectionBoxes_Precision/mAP@.75IOU = 0.04290429, DetectionBoxes_Recall/AR@1 = 0.2, DetectionBoxes_Recall/AR@10 = 0.35, DetectionBoxes_Recall/AR@100 = 0.35, DetectionBoxes_Recall/AR@100 (large) = 0.35, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.115084164, Loss/BoxClassifierLoss/localization_loss = 0.12525977, Loss/RPNLoss/localization_loss = 0.34112686, Loss/RPNLoss/objectness_loss = 0.25647447, Loss/total_loss = 0.8379452, global_step = 757, learning_rate = 0.0002, loss = 0.8379452\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 757: training/model.ckpt-757\n",
            "I1213 15:52:07.630830 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 757: training/model.ckpt-757\n",
            "INFO:tensorflow:Saving checkpoints for 769 into training/model.ckpt.\n",
            "I1213 16:01:59.205642 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 769 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 16:02:01.583972 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 16:02:01.585129 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 16:02:01.585282 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f46348567f0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 16:02:01.632937 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f46348567f0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463484d2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 16:02:01.828989 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463484d2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 16:02:02.445318 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 16:02:03.958979 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 16:02:04.112139 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 16:02:04.112611 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 16:02:05.231939 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 16:02:05.249149 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 16:02:07.349015 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T16:02:07Z\n",
            "I1213 16:02:07.366465 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T16:02:07Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 16:02:07.838690 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-769\n",
            "I1213 16:02:07.840467 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-769\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 16:02:08.914165 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 16:02:09.109708 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 16:02:27.506838 139939724338944 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 16:02:27.507285 139939724338944 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 16:02:27.508013 139939724338944 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.07s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.180\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.360\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.021\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.180\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.263\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.300\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.325\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.325\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-16:02:29\n",
            "I1213 16:02:29.110810 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-16:02:29\n",
            "INFO:tensorflow:Saving dict for global step 769: DetectionBoxes_Precision/mAP = 0.17963538, DetectionBoxes_Precision/mAP (large) = 0.17968202, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.36020744, DetectionBoxes_Precision/mAP@.75IOU = 0.021452146, DetectionBoxes_Recall/AR@1 = 0.2625, DetectionBoxes_Recall/AR@10 = 0.3, DetectionBoxes_Recall/AR@100 = 0.325, DetectionBoxes_Recall/AR@100 (large) = 0.325, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.10535169, Loss/BoxClassifierLoss/localization_loss = 0.110038675, Loss/RPNLoss/localization_loss = 0.34890231, Loss/RPNLoss/objectness_loss = 0.26198888, Loss/total_loss = 0.8262815, global_step = 769, learning_rate = 0.0002, loss = 0.8262815\n",
            "I1213 16:02:29.111183 139941885183872 estimator.py:2049] Saving dict for global step 769: DetectionBoxes_Precision/mAP = 0.17963538, DetectionBoxes_Precision/mAP (large) = 0.17968202, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.36020744, DetectionBoxes_Precision/mAP@.75IOU = 0.021452146, DetectionBoxes_Recall/AR@1 = 0.2625, DetectionBoxes_Recall/AR@10 = 0.3, DetectionBoxes_Recall/AR@100 = 0.325, DetectionBoxes_Recall/AR@100 (large) = 0.325, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.10535169, Loss/BoxClassifierLoss/localization_loss = 0.110038675, Loss/RPNLoss/localization_loss = 0.34890231, Loss/RPNLoss/objectness_loss = 0.26198888, Loss/total_loss = 0.8262815, global_step = 769, learning_rate = 0.0002, loss = 0.8262815\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 769: training/model.ckpt-769\n",
            "I1213 16:02:29.118872 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 769: training/model.ckpt-769\n",
            "INFO:tensorflow:Saving checkpoints for 781 into training/model.ckpt.\n",
            "I1213 16:12:19.453220 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 781 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 16:12:21.835850 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 16:12:21.837929 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 16:12:21.838121 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463b10ea58>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 16:12:21.893519 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f463b10ea58>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463a3d02f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 16:12:22.086842 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f463a3d02f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 16:12:22.698202 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 16:12:24.168421 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 16:12:24.319275 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 16:12:24.319708 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 16:12:25.489672 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 16:12:25.508978 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 16:12:27.287056 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T16:12:27Z\n",
            "I1213 16:12:27.304397 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T16:12:27Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 16:12:27.774975 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-781\n",
            "I1213 16:12:27.776661 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-781\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 16:12:28.759797 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 16:12:28.940491 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 16:12:47.174767 139939724338944 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 16:12:47.175349 139939724338944 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 16:12:47.176147 139939724338944 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.07s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.178\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.336\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.165\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.263\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.362\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.362\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.362\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-16:12:48\n",
            "I1213 16:12:48.750841 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-16:12:48\n",
            "INFO:tensorflow:Saving dict for global step 781: DetectionBoxes_Precision/mAP = 0.17780545, DetectionBoxes_Precision/mAP (large) = 0.17780545, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.3359949, DetectionBoxes_Precision/mAP@.75IOU = 0.16548797, DetectionBoxes_Recall/AR@1 = 0.2625, DetectionBoxes_Recall/AR@10 = 0.3625, DetectionBoxes_Recall/AR@100 = 0.3625, DetectionBoxes_Recall/AR@100 (large) = 0.3625, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.12727982, Loss/BoxClassifierLoss/localization_loss = 0.12402426, Loss/RPNLoss/localization_loss = 0.3428203, Loss/RPNLoss/objectness_loss = 0.2620269, Loss/total_loss = 0.8561512, global_step = 781, learning_rate = 0.0002, loss = 0.8561512\n",
            "I1213 16:12:48.751233 139941885183872 estimator.py:2049] Saving dict for global step 781: DetectionBoxes_Precision/mAP = 0.17780545, DetectionBoxes_Precision/mAP (large) = 0.17780545, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.3359949, DetectionBoxes_Precision/mAP@.75IOU = 0.16548797, DetectionBoxes_Recall/AR@1 = 0.2625, DetectionBoxes_Recall/AR@10 = 0.3625, DetectionBoxes_Recall/AR@100 = 0.3625, DetectionBoxes_Recall/AR@100 (large) = 0.3625, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.12727982, Loss/BoxClassifierLoss/localization_loss = 0.12402426, Loss/RPNLoss/localization_loss = 0.3428203, Loss/RPNLoss/objectness_loss = 0.2620269, Loss/total_loss = 0.8561512, global_step = 781, learning_rate = 0.0002, loss = 0.8561512\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 781: training/model.ckpt-781\n",
            "I1213 16:12:48.758013 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 781: training/model.ckpt-781\n",
            "INFO:tensorflow:Saving checkpoints for 793 into training/model.ckpt.\n",
            "I1213 16:22:38.702250 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 793 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 16:22:41.045080 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 16:22:41.046176 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 16:22:41.046320 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f4637b3ec18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 16:22:41.092657 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f4637b3ec18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f4637ba98c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 16:22:41.302397 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f4637ba98c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 16:22:41.906925 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 16:22:43.403266 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 16:22:43.559054 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 16:22:43.559515 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 16:22:44.680024 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 16:22:44.697793 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 16:22:46.908390 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T16:22:46Z\n",
            "I1213 16:22:46.927235 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T16:22:46Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 16:22:47.397564 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-793\n",
            "I1213 16:22:47.399215 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-793\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 16:22:48.446527 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 16:22:48.634166 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 16:23:06.990536 139939732731648 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 16:23:06.990949 139939732731648 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 16:23:06.991518 139939732731648 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.07s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.141\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.313\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.180\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.141\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.225\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.362\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.362\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.362\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-16:23:08\n",
            "I1213 16:23:08.598355 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-16:23:08\n",
            "INFO:tensorflow:Saving dict for global step 793: DetectionBoxes_Precision/mAP = 0.14099286, DetectionBoxes_Precision/mAP (large) = 0.14099286, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.31338134, DetectionBoxes_Precision/mAP@.75IOU = 0.18012185, DetectionBoxes_Recall/AR@1 = 0.225, DetectionBoxes_Recall/AR@10 = 0.3625, DetectionBoxes_Recall/AR@100 = 0.3625, DetectionBoxes_Recall/AR@100 (large) = 0.3625, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.1399986, Loss/BoxClassifierLoss/localization_loss = 0.12328938, Loss/RPNLoss/localization_loss = 0.34605488, Loss/RPNLoss/objectness_loss = 0.26574427, Loss/total_loss = 0.8750872, global_step = 793, learning_rate = 0.0002, loss = 0.8750872\n",
            "I1213 16:23:08.598683 139941885183872 estimator.py:2049] Saving dict for global step 793: DetectionBoxes_Precision/mAP = 0.14099286, DetectionBoxes_Precision/mAP (large) = 0.14099286, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.31338134, DetectionBoxes_Precision/mAP@.75IOU = 0.18012185, DetectionBoxes_Recall/AR@1 = 0.225, DetectionBoxes_Recall/AR@10 = 0.3625, DetectionBoxes_Recall/AR@100 = 0.3625, DetectionBoxes_Recall/AR@100 (large) = 0.3625, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.1399986, Loss/BoxClassifierLoss/localization_loss = 0.12328938, Loss/RPNLoss/localization_loss = 0.34605488, Loss/RPNLoss/objectness_loss = 0.26574427, Loss/total_loss = 0.8750872, global_step = 793, learning_rate = 0.0002, loss = 0.8750872\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 793: training/model.ckpt-793\n",
            "I1213 16:23:08.604299 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 793: training/model.ckpt-793\n",
            "INFO:tensorflow:Saving checkpoints for 800 into training/model.ckpt.\n",
            "I1213 16:28:52.850836 139941885183872 basic_session_run_hooks.py:606] Saving checkpoints for 800 into training/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "I1213 16:28:55.194366 139941885183872 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 16:28:55.215597 139941885183872 dataset_builder.py:148] Reading unweighted datasets: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "I1213 16:28:55.216690 139941885183872 dataset_builder.py:77] Reading record datasets for input file: ['/content/detection_demo/data/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1213 16:28:55.216827 139941885183872 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f46388a2be0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W1213 16:28:55.263881 139941885183872 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f46388a2be0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f4638885488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1213 16:28:55.457283 139941885183872 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f4638885488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 16:28:56.054965 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 16:28:57.577474 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 16:28:57.724380 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 16:28:57.724811 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 16:28:58.882553 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 16:28:58.899855 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 16:29:00.674088 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-12-13T16:29:00Z\n",
            "I1213 16:29:00.694927 139941885183872 evaluation.py:255] Starting evaluation at 2020-12-13T16:29:00Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1213 16:29:01.162199 139941885183872 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-800\n",
            "I1213 16:29:01.163966 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-800\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1213 16:29:02.270478 139941885183872 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1213 16:29:02.473147 139941885183872 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 8 images.\n",
            "I1213 16:29:20.811014 139939732731648 coco_evaluation.py:293] Performing evaluation on 8 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1213 16:29:20.811432 139939732731648 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1213 16:29:20.812049 139939732731648 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.114\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.315\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.059\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.114\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.150\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.400\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.400\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.400\n",
            "INFO:tensorflow:Finished evaluation at 2020-12-13-16:29:22\n",
            "I1213 16:29:22.355257 139941885183872 evaluation.py:275] Finished evaluation at 2020-12-13-16:29:22\n",
            "INFO:tensorflow:Saving dict for global step 800: DetectionBoxes_Precision/mAP = 0.113643326, DetectionBoxes_Precision/mAP (large) = 0.113643326, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.3148515, DetectionBoxes_Precision/mAP@.75IOU = 0.059075907, DetectionBoxes_Recall/AR@1 = 0.15, DetectionBoxes_Recall/AR@10 = 0.4, DetectionBoxes_Recall/AR@100 = 0.4, DetectionBoxes_Recall/AR@100 (large) = 0.4, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.10106459, Loss/BoxClassifierLoss/localization_loss = 0.16899268, Loss/RPNLoss/localization_loss = 0.33941242, Loss/RPNLoss/objectness_loss = 0.26703992, Loss/total_loss = 0.8765096, global_step = 800, learning_rate = 0.0002, loss = 0.8765096\n",
            "I1213 16:29:22.355595 139941885183872 estimator.py:2049] Saving dict for global step 800: DetectionBoxes_Precision/mAP = 0.113643326, DetectionBoxes_Precision/mAP (large) = 0.113643326, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.3148515, DetectionBoxes_Precision/mAP@.75IOU = 0.059075907, DetectionBoxes_Recall/AR@1 = 0.15, DetectionBoxes_Recall/AR@10 = 0.4, DetectionBoxes_Recall/AR@100 = 0.4, DetectionBoxes_Recall/AR@100 (large) = 0.4, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.10106459, Loss/BoxClassifierLoss/localization_loss = 0.16899268, Loss/RPNLoss/localization_loss = 0.33941242, Loss/RPNLoss/objectness_loss = 0.26703992, Loss/total_loss = 0.8765096, global_step = 800, learning_rate = 0.0002, loss = 0.8765096\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 800: training/model.ckpt-800\n",
            "I1213 16:29:22.361175 139941885183872 estimator.py:2109] Saving 'checkpoint_path' summary for global step 800: training/model.ckpt-800\n",
            "INFO:tensorflow:Performing the final export in the end of training.\n",
            "I1213 16:29:22.362166 139941885183872 exporter.py:410] Performing the final export in the end of training.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1213 16:29:22.695565 139941885183872 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 16:29:24.143547 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 16:29:24.292068 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 16:29:24.292516 139941885183872 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 16:29:25.855452 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 16:29:25.872915 139941885183872 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1213 16:29:26.637647 139941885183872 estimator.py:1150] Done calling model_fn.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "W1213 16:29:26.638018 139941885183872 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "I1213 16:29:26.638952 139941885183872 export_utils.py:170] Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "I1213 16:29:26.639089 139941885183872 export_utils.py:170] Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n",
            "I1213 16:29:26.639275 139941885183872 export_utils.py:170] Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "I1213 16:29:26.639379 139941885183872 export_utils.py:170] Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "I1213 16:29:26.639489 139941885183872 export_utils.py:170] Signatures INCLUDED in export for Eval: None\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-800\n",
            "I1213 16:29:26.643280 139941885183872 saver.py:1284] Restoring parameters from training/model.ckpt-800\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "I1213 16:29:27.196951 139941885183872 builder_impl.py:665] Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "I1213 16:29:27.197221 139941885183872 builder_impl.py:460] No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: training/export/Servo/temp-b'1607876962'/saved_model.pb\n",
            "I1213 16:29:28.214245 139941885183872 builder_impl.py:425] SavedModel written to: training/export/Servo/temp-b'1607876962'/saved_model.pb\n",
            "INFO:tensorflow:Loss for final step: 0.629367.\n",
            "I1213 16:29:28.651396 139941885183872 estimator.py:371] Loss for final step: 0.629367.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KP-tUdtnRybs",
        "outputId": "3bca1e62-1ab1-4148-9b8f-92840a96aa69"
      },
      "source": [
        "!ls {model_dir}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\t\t\t\t     model.ckpt-769.meta\n",
            "eval_0\t\t\t\t\t     model.ckpt-781.data-00000-of-00001\n",
            "events.out.tfevents.1607835934.0b6d36a6b087  model.ckpt-781.index\n",
            "export\t\t\t\t\t     model.ckpt-781.meta\n",
            "graph.pbtxt\t\t\t\t     model.ckpt-793.data-00000-of-00001\n",
            "model.ckpt-757.data-00000-of-00001\t     model.ckpt-793.index\n",
            "model.ckpt-757.index\t\t\t     model.ckpt-793.meta\n",
            "model.ckpt-757.meta\t\t\t     model.ckpt-800.data-00000-of-00001\n",
            "model.ckpt-769.data-00000-of-00001\t     model.ckpt-800.index\n",
            "model.ckpt-769.index\t\t\t     model.ckpt-800.meta\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1Nrqw3nqnCh"
      },
      "source": [
        "# Legacy way of training(also works).\n",
        "# !python /content/models/research/object_detection/legacy/train.py --logtostderr --train_dir={model_dir} --pipeline_config_path={pipeline_fname}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmSESMetj1sa"
      },
      "source": [
        "## Exporting a Trained Inference Graph\n",
        "Once your training job is complete, you need to extract the newly trained inference graph, which will be later used to perform the object detection. This can be done as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHoP90pUyKSq",
        "outputId": "26475251-188b-4f18-a99e-a7a232fe7ef0"
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "\n",
        "output_directory = './fine_tuned_model'\n",
        "\n",
        "lst = os.listdir(model_dir)\n",
        "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n",
        "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
        "last_model = lst[steps.argmax()].replace('.meta', '')\n",
        "\n",
        "last_model_path = os.path.join(model_dir, last_model)\n",
        "print(last_model_path)\n",
        "!python /content/models/research/object_detection/export_inference_graph.py \\\n",
        "    --input_type=image_tensor \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --output_directory={output_directory} \\\n",
        "    --trained_checkpoint_prefix={last_model_path}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training/model.ckpt-800\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:2802: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W1213 16:30:28.048474 140484751837056 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:2802: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 16:30:29.613733 140484751837056 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 16:30:29.787272 140484751837056 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1213 16:30:29.787795 140484751837056 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/box_list_ops.py:169: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W1213 16:30:29.862700 140484751837056 deprecation.py:323] From /content/models/research/object_detection/core/box_list_ops.py:169: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/spatial_transform_ops.py:478: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "W1213 16:30:30.534520 140484751837056 deprecation.py:506] From /content/models/research/object_detection/utils/spatial_transform_ops.py:478: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1666: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "W1213 16:30:31.329603 140484751837056 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1666: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 16:30:31.336480 140484751837056 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I1213 16:30:31.358907 140484751837056 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:474: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "W1213 16:30:32.075978 140484751837056 deprecation.py:323] From /content/models/research/object_detection/exporter.py:474: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:653: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "W1213 16:30:32.079873 140484751837056 deprecation.py:323] From /content/models/research/object_detection/exporter.py:653: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "W1213 16:30:32.081352 140484751837056 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "204 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              0\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   name\n",
            "-account_type_regexes       _trainable_variables\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     params\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "param: Number of parameters (in the Variable).\n",
            "\n",
            "Profile:\n",
            "node name | # parameters\n",
            "_TFProfRoot (--/12.84m params)\n",
            "  Conv (--/2.65m params)\n",
            "    Conv/biases (512, 512/512 params)\n",
            "    Conv/weights (3x3x576x512, 2.65m/2.65m params)\n",
            "  FirstStageBoxPredictor (--/36.94k params)\n",
            "    FirstStageBoxPredictor/BoxEncodingPredictor (--/24.62k params)\n",
            "      FirstStageBoxPredictor/BoxEncodingPredictor/biases (48, 48/48 params)\n",
            "      FirstStageBoxPredictor/BoxEncodingPredictor/weights (1x1x512x48, 24.58k/24.58k params)\n",
            "    FirstStageBoxPredictor/ClassPredictor (--/12.31k params)\n",
            "      FirstStageBoxPredictor/ClassPredictor/biases (24, 24/24 params)\n",
            "      FirstStageBoxPredictor/ClassPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n",
            "  FirstStageFeatureExtractor (--/4.25m params)\n",
            "    FirstStageFeatureExtractor/InceptionV2 (--/4.25m params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7 (--/2.71k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/BatchNorm (--/0 params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/depthwise_weights (7x7x3x8, 1.18k/1.18k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/pointwise_weights (1x1x24x64, 1.54k/1.54k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Conv2d_2b_1x1 (--/4.10k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_2b_1x1/BatchNorm (--/0 params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_2b_1x1/weights (1x1x64x64, 4.10k/4.10k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Conv2d_2c_3x3 (--/110.59k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_2c_3x3/BatchNorm (--/0 params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_2c_3x3/weights (3x3x64x192, 110.59k/110.59k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_3b (--/218.11k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0 (--/12.29k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0/Conv2d_0a_1x1 (--/12.29k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0/Conv2d_0a_1x1/weights (1x1x192x64, 12.29k/12.29k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1 (--/49.15k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1 (--/12.29k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1/weights (1x1x192x64, 12.29k/12.29k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0b_3x3 (--/36.86k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0b_3x3/weights (3x3x64x64, 36.86k/36.86k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2 (--/150.53k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0a_1x1 (--/12.29k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0a_1x1/weights (1x1x192x64, 12.29k/12.29k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0b_3x3 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0c_3x3 (--/82.94k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0c_3x3/weights (3x3x96x96, 82.94k/82.94k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3 (--/6.14k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3/Conv2d_0b_1x1 (--/6.14k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3/Conv2d_0b_1x1/weights (1x1x192x32, 6.14k/6.14k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_3c (--/259.07k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0 (--/16.38k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0/Conv2d_0a_1x1 (--/16.38k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0/Conv2d_0a_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1 (--/71.68k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0a_1x1 (--/16.38k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0a_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0b_3x3 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2 (--/154.62k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0a_1x1 (--/16.38k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0a_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0b_3x3 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0c_3x3 (--/82.94k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0c_3x3/weights (3x3x96x96, 82.94k/82.94k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3 (--/16.38k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3/Conv2d_0b_1x1 (--/16.38k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3/Conv2d_0b_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_4a (--/384.00k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0 (--/225.28k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_0a_1x1 (--/40.96k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_0a_1x1/weights (1x1x320x128, 40.96k/40.96k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_1a_3x3 (--/184.32k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_1a_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_1a_3x3/weights (3x3x128x160, 184.32k/184.32k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1 (--/158.72k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0a_1x1 (--/20.48k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0a_1x1/weights (1x1x320x64, 20.48k/20.48k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0b_3x3 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_1a_3x3 (--/82.94k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_1a_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_1a_3x3/weights (3x3x96x96, 82.94k/82.94k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_4b (--/608.26k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0 (--/129.02k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0/Conv2d_0a_1x1 (--/129.02k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0/Conv2d_0a_1x1/weights (1x1x576x224, 129.02k/129.02k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1 (--/92.16k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0a_1x1 (--/36.86k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0a_1x1/weights (1x1x576x64, 36.86k/36.86k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0b_3x3 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2 (--/313.34k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0a_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0b_3x3 (--/110.59k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0b_3x3/weights (3x3x96x128, 110.59k/110.59k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0c_3x3 (--/147.46k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0c_3x3/weights (3x3x128x128, 147.46k/147.46k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3 (--/73.73k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3/Conv2d_0b_1x1 (--/73.73k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3/Conv2d_0b_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_4c (--/663.55k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0 (--/110.59k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0/Conv2d_0a_1x1 (--/110.59k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0/Conv2d_0a_1x1/weights (1x1x576x192, 110.59k/110.59k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1 (--/165.89k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0a_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0b_3x3 (--/110.59k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0b_3x3/weights (3x3x96x128, 110.59k/110.59k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2 (--/313.34k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0a_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0b_3x3 (--/110.59k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0b_3x3/weights (3x3x96x128, 110.59k/110.59k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0c_3x3 (--/147.46k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0c_3x3/weights (3x3x128x128, 147.46k/147.46k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3 (--/73.73k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3/Conv2d_0b_1x1 (--/73.73k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3/Conv2d_0b_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_4d (--/893.95k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0 (--/92.16k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0/Conv2d_0a_1x1 (--/92.16k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0/Conv2d_0a_1x1/weights (1x1x576x160, 92.16k/92.16k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1 (--/258.05k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0a_1x1 (--/73.73k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3 (--/184.32k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3/weights (3x3x128x160, 184.32k/184.32k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2 (--/488.45k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0a_1x1 (--/73.73k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0b_3x3 (--/184.32k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0b_3x3/weights (3x3x128x160, 184.32k/184.32k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0c_3x3 (--/230.40k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0c_3x3/weights (3x3x160x160, 230.40k/230.40k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3 (--/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3/Conv2d_0b_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3/Conv2d_0b_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_4e (--/1.11m params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0 (--/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0/Conv2d_0a_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1 (--/294.91k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0a_1x1 (--/73.73k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0b_3x3 (--/221.18k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0b_3x3/weights (3x3x128x192, 221.18k/221.18k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2 (--/700.42k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0a_1x1 (--/92.16k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0a_1x1/weights (1x1x576x160, 92.16k/92.16k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0b_3x3 (--/276.48k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0b_3x3/weights (3x3x160x192, 276.48k/276.48k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0c_3x3 (--/331.78k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0c_3x3/weights (3x3x192x192, 331.78k/331.78k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3 (--/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3/Conv2d_0b_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3/Conv2d_0b_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "  SecondStageBoxPredictor (--/6.15k params)\n",
            "    SecondStageBoxPredictor/BoxEncodingPredictor (--/4.10k params)\n",
            "      SecondStageBoxPredictor/BoxEncodingPredictor/biases (4, 4/4 params)\n",
            "      SecondStageBoxPredictor/BoxEncodingPredictor/weights (1024x4, 4.10k/4.10k params)\n",
            "    SecondStageBoxPredictor/ClassPredictor (--/2.05k params)\n",
            "      SecondStageBoxPredictor/ClassPredictor/biases (2, 2/2 params)\n",
            "      SecondStageBoxPredictor/ClassPredictor/weights (1024x2, 2.05k/2.05k params)\n",
            "  SecondStageFeatureExtractor (--/5.89m params)\n",
            "    SecondStageFeatureExtractor/InceptionV2 (--/5.89m params)\n",
            "      SecondStageFeatureExtractor/InceptionV2/Mixed_5a (--/1.44m params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0 (--/294.91k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_0a_1x1 (--/73.73k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_1a_3x3 (--/221.18k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_1a_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_1a_3x3/weights (3x3x128x192, 221.18k/221.18k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1 (--/1.14m params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0a_1x1 (--/110.59k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0a_1x1/weights (1x1x576x192, 110.59k/110.59k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0b_3x3 (--/442.37k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0b_3x3/weights (3x3x192x256, 442.37k/442.37k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_1a_3x3 (--/589.82k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_1a_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_1a_3x3/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "      SecondStageFeatureExtractor/InceptionV2/Mixed_5b (--/2.18m params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0 (--/360.45k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0/Conv2d_0a_1x1 (--/360.45k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0/Conv2d_0a_1x1/weights (1x1x1024x352, 360.45k/360.45k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1 (--/749.57k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0a_1x1 (--/196.61k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0a_1x1/weights (1x1x1024x192, 196.61k/196.61k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0b_3x3 (--/552.96k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0b_3x3/weights (3x3x192x320, 552.96k/552.96k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2 (--/937.98k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0a_1x1 (--/163.84k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0a_1x1/weights (1x1x1024x160, 163.84k/163.84k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0b_3x3 (--/322.56k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0b_3x3/weights (3x3x160x224, 322.56k/322.56k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0c_3x3 (--/451.58k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/weights (3x3x224x224, 451.58k/451.58k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3 (--/131.07k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3/Conv2d_0b_1x1 (--/131.07k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3/Conv2d_0b_1x1/weights (1x1x1024x128, 131.07k/131.07k params)\n",
            "      SecondStageFeatureExtractor/InceptionV2/Mixed_5c (--/2.28m params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0 (--/360.45k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0/Conv2d_0a_1x1 (--/360.45k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0/Conv2d_0a_1x1/weights (1x1x1024x352, 360.45k/360.45k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1 (--/749.57k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0a_1x1 (--/196.61k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0a_1x1/weights (1x1x1024x192, 196.61k/196.61k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0b_3x3 (--/552.96k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0b_3x3/weights (3x3x192x320, 552.96k/552.96k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2 (--/1.04m params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0a_1x1 (--/196.61k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0a_1x1/weights (1x1x1024x192, 196.61k/196.61k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0b_3x3 (--/387.07k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0b_3x3/weights (3x3x192x224, 387.07k/387.07k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0c_3x3 (--/451.58k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0c_3x3/weights (3x3x224x224, 451.58k/451.58k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3 (--/131.07k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3/Conv2d_0b_1x1 (--/131.07k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3/Conv2d_0b_1x1/weights (1x1x1024x128, 131.07k/131.07k params)\n",
            "\n",
            "======================End of Report==========================\n",
            "204 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              1\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   float_ops\n",
            "-account_type_regexes       .*\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     float_ops\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
            "\n",
            "Profile:\n",
            "node name | # float_ops\n",
            "_TFProfRoot (--/6.16k flops)\n",
            "  map/while/ToNormalizedCoordinates/Scale/mul_1 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Maximum_3 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Minimum (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Minimum_1 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Minimum_2 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Minimum_3 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Maximum_2 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Maximum_1 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul_1 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul_2 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul_3 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Maximum (300/300 flops)\n",
            "  map/while/ToNormalizedCoordinates/Scale/mul (300/300 flops)\n",
            "  map/while/ToNormalizedCoordinates/Scale/mul_2 (300/300 flops)\n",
            "  map_2/while/mul_3 (300/300 flops)\n",
            "  map_2/while/mul_2 (300/300 flops)\n",
            "  map_2/while/mul_1 (300/300 flops)\n",
            "  map_2/while/mul (300/300 flops)\n",
            "  map/while/ToNormalizedCoordinates/Scale/mul_3 (300/300 flops)\n",
            "  GridAnchorGenerator/mul (12/12 flops)\n",
            "  GridAnchorGenerator/mul_1 (12/12 flops)\n",
            "  GridAnchorGenerator/mul_2 (12/12 flops)\n",
            "  GridAnchorGenerator/truediv (12/12 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_18 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_19 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_9 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n",
            "  mul (1/1 flops)\n",
            "  map_2/while/Less_1 (1/1 flops)\n",
            "  map_2/while/Less (1/1 flops)\n",
            "  map_1/while/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n",
            "  map_1/while/ToNormalizedCoordinates/truediv (1/1 flops)\n",
            "  map_1/while/Less_1 (1/1 flops)\n",
            "  map_1/while/Less (1/1 flops)\n",
            "  map/while/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n",
            "  map/while/ToNormalizedCoordinates/truediv (1/1 flops)\n",
            "  map/while/Less_1 (1/1 flops)\n",
            "  map/while/Less (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/truediv (1/1 flops)\n",
            "  SecondStagePostprocessor/map/while/Less_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/map/while/Less (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize_1/Minimum (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize_1/mul (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize_1/mul_1 (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize_1/truediv (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize_1/truediv_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize/truediv_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize/truediv (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize/mul_1 (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize/mul (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize/Minimum (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/Less (1/1 flops)\n",
            "  Preprocessor/map/while/Less_1 (1/1 flops)\n",
            "  Preprocessor/map/while/Less (1/1 flops)\n",
            "  GridAnchorGenerator/zeros/Less (1/1 flops)\n",
            "  GridAnchorGenerator/mul_8 (1/1 flops)\n",
            "  GridAnchorGenerator/mul_7 (1/1 flops)\n",
            "  GridAnchorGenerator/assert_equal_1/Equal (1/1 flops)\n",
            "  FirstStageFeatureExtractor/GreaterEqual_1 (1/1 flops)\n",
            "  FirstStageFeatureExtractor/GreaterEqual (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n",
            "\n",
            "======================End of Report==========================\n",
            "2020-12-13 16:30:34.895967: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-12-13 16:30:34.911880: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2020-12-13 16:30:34.911943: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (0b6d36a6b087): /proc/driver/nvidia/version does not exist\n",
            "2020-12-13 16:30:34.925679: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2250000000 Hz\n",
            "2020-12-13 16:30:34.925985: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x22ed100 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-12-13 16:30:34.926018: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-800\n",
            "I1213 16:30:34.929039 140484751837056 saver.py:1284] Restoring parameters from training/model.ckpt-800\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "W1213 16:30:36.246788 140484751837056 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-800\n",
            "I1213 16:30:36.978172 140484751837056 saver.py:1284] Restoring parameters from training/model.ckpt-800\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W1213 16:30:37.681617 140484751837056 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "W1213 16:30:37.681927 140484751837056 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 356 variables.\n",
            "I1213 16:30:38.277537 140484751837056 graph_util_impl.py:334] Froze 356 variables.\n",
            "INFO:tensorflow:Converted 356 variables to const ops.\n",
            "I1213 16:30:38.401989 140484751837056 graph_util_impl.py:394] Converted 356 variables to const ops.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:384: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "W1213 16:30:39.033731 140484751837056 deprecation.py:323] From /content/models/research/object_detection/exporter.py:384: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:No assets to save.\n",
            "I1213 16:30:39.034637 140484751837056 builder_impl.py:640] No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "I1213 16:30:39.034779 140484751837056 builder_impl.py:460] No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: ./fine_tuned_model/saved_model/saved_model.pb\n",
            "I1213 16:30:39.416024 140484751837056 builder_impl.py:425] SavedModel written to: ./fine_tuned_model/saved_model/saved_model.pb\n",
            "INFO:tensorflow:Writing pipeline config file to ./fine_tuned_model/pipeline.config\n",
            "I1213 16:30:39.452768 140484751837056 config_util.py:254] Writing pipeline config file to ./fine_tuned_model/pipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usgBZvkz0nqD",
        "outputId": "6c64baf8-dd7f-4e22-c827-7bc2757ed1b4"
      },
      "source": [
        "!ls {output_directory}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\t\t\tmodel.ckpt.index  saved_model\n",
            "frozen_inference_graph.pb\tmodel.ckpt.meta\n",
            "model.ckpt.data-00000-of-00001\tpipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p09AOThWkaQv"
      },
      "source": [
        "## Download the model `.pb` file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnDo1lonKgFr"
      },
      "source": [
        "import os\n",
        "\n",
        "pb_fname = os.path.join(os.path.abspath(output_directory), \"frozen_inference_graph.pb\")\n",
        "assert os.path.isfile(pb_fname), '`{}` not exist'.format(pb_fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHqWkLBINYoI",
        "outputId": "e589ded0-1443-4ab5-803b-6aacc1372ef8"
      },
      "source": [
        "!ls -alh {pb_fname}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 50M Dec 13 16:30 /content/models/research/fine_tuned_model/frozen_inference_graph.pb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIqnjbWYsuQw"
      },
      "source": [
        "### Option1 : upload the `.pb` file to your Google Drive\n",
        "Then download it from your Google Drive to local file system.\n",
        "\n",
        "During this step, you will be prompted to enter the token."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAqyASIJqjae",
        "outputId": "cf405fc3-4ccb-406f-fc76-9564fa71c735"
      },
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once in a notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once in a notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "fname = os.path.basename(pb_fname)\n",
        "# Create & upload a text file.\n",
        "uploaded = drive.CreateFile({'title': fname})\n",
        "uploaded.SetContentFile(pb_fname)\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uploaded file with ID 17ULN2Puy_XImd7jXKkcpM8jldzdDhPqx\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FKFq8RXs6bs"
      },
      "source": [
        "### Option2 :  Download the `.pb` file directly to your local file system\n",
        "This method may not be stable when downloading large files like the model `.pb` file. Try **option 1** instead if not working."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "-bP0iMMnnr77",
        "outputId": "3433711d-f645-4758-8818-86a8fb0a2b24"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(pb_fname)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_fbbfd788-6d43-4be2-9ed6-0036bc0576e5\", \"frozen_inference_graph.pb\", 52209711)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFyCeiBb9BbS"
      },
      "source": [
        "### Download the `label_map.pbtxt` file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "K1TbL6Ox8q6Z",
        "outputId": "67c2dc0d-fff8-4dbd-9acb-63ecda703ca3"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(label_map_pbtxt_fname)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_b9f7b884-f0f6-43b1-a8c6-3c0e7a49d6a1\", \"label_map.pbtxt\", 46)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUmAo9foa1xq"
      },
      "source": [
        "### Download the modified pipline file\n",
        "If you plan to use OpenVINO toolkit to convert the `.pb` file to inference faster on Intel's hardware (CPU/GPU, Movidius, etc.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "pql2QpemazE1",
        "outputId": "076e3fa4-95a9-486f-f04d-ff877e65a808"
      },
      "source": [
        "files.download(pipeline_fname)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_ae0111bc-e2e8-4adc-8c9a-d4968d230f84\", \"faster_rcnn_inception_v2_pets.config\", 3722)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1AgBj1l0v_W"
      },
      "source": [
        "# !tar cfz fine_tuned_model.tar.gz fine_tuned_model\n",
        "# from google.colab import files\n",
        "# files.download('fine_tuned_model.tar.gz')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mz1gX19GlVW7"
      },
      "source": [
        "## Run inference test\n",
        "Test with images in repository `object_detection_demo/test` directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pzj9A4e5mj5l",
        "outputId": "d421f158-7ba7-4535-affc-ad202d6778c4"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
        "PATH_TO_CKPT = pb_fname\n",
        "\n",
        "# List of the strings that is used to add correct label for each box.\n",
        "PATH_TO_LABELS = label_map_pbtxt_fname\n",
        "\n",
        "# If you want to test the code with your images, just add images files to the PATH_TO_TEST_IMAGES_DIR.\n",
        "PATH_TO_TEST_IMAGES_DIR =  os.path.join(repo_dir_path, \"test\")\n",
        "\n",
        "assert os.path.isfile(pb_fname)\n",
        "assert os.path.isfile(PATH_TO_LABELS)\n",
        "TEST_IMAGE_PATHS = glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, \"*.*\"))\n",
        "assert len(TEST_IMAGE_PATHS) > 0, 'No image found in `{}`.'.format(PATH_TO_TEST_IMAGES_DIR)\n",
        "print(TEST_IMAGE_PATHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/detection_demo/test/23.jpg', '/content/detection_demo/test/14.jpg', '/content/detection_demo/test/28.jpg', '/content/detection_demo/test/31.jpg', '/content/detection_demo/test/12.jpg', '/content/detection_demo/test/73.jpg', '/content/detection_demo/test/21.jpg', '/content/detection_demo/test/43.jpg', '/content/detection_demo/test/26.jpg', '/content/detection_demo/test/1.JPG']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CG5YUMdg1Po7",
        "outputId": "16187a15-ff94-4dce-ca8b-1f64808a270c"
      },
      "source": [
        "%cd /content/models/research/object_detection\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# This is needed since the notebook is stored in the object_detection folder.\n",
        "sys.path.append(\"..\")\n",
        "from object_detection.utils import ops as utils_ops\n",
        "\n",
        "\n",
        "# This is needed to display the images.\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "\n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "\n",
        "\n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "    od_graph_def = tf.GraphDef()\n",
        "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "        serialized_graph = fid.read()\n",
        "        od_graph_def.ParseFromString(serialized_graph)\n",
        "        tf.import_graph_def(od_graph_def, name='')\n",
        "\n",
        "\n",
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(\n",
        "    label_map, max_num_classes=num_classes, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "\n",
        "def load_image_into_numpy_array(image):\n",
        "    (im_width, im_height) = image.size\n",
        "    return np.array(image.getdata()).reshape(\n",
        "        (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "# Size, in inches, of the output images.\n",
        "IMAGE_SIZE = (12, 8)\n",
        "\n",
        "\n",
        "def run_inference_for_single_image(image, graph):\n",
        "    with graph.as_default():\n",
        "        with tf.Session() as sess:\n",
        "            # Get handles to input and output tensors\n",
        "            ops = tf.get_default_graph().get_operations()\n",
        "            all_tensor_names = {\n",
        "                output.name for op in ops for output in op.outputs}\n",
        "            tensor_dict = {}\n",
        "            for key in [\n",
        "                'num_detections', 'detection_boxes', 'detection_scores',\n",
        "                'detection_classes', 'detection_masks'\n",
        "            ]:\n",
        "                tensor_name = key + ':0'\n",
        "                if tensor_name in all_tensor_names:\n",
        "                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
        "                        tensor_name)\n",
        "            if 'detection_masks' in tensor_dict:\n",
        "                # The following processing is only for single image\n",
        "                detection_boxes = tf.squeeze(\n",
        "                    tensor_dict['detection_boxes'], [0])\n",
        "                detection_masks = tf.squeeze(\n",
        "                    tensor_dict['detection_masks'], [0])\n",
        "                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
        "                real_num_detection = tf.cast(\n",
        "                    tensor_dict['num_detections'][0], tf.int32)\n",
        "                detection_boxes = tf.slice(detection_boxes, [0, 0], [\n",
        "                                           real_num_detection, -1])\n",
        "                detection_masks = tf.slice(detection_masks, [0, 0, 0], [\n",
        "                                           real_num_detection, -1, -1])\n",
        "                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
        "                detection_masks_reframed = tf.cast(\n",
        "                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
        "                # Follow the convention by adding back the batch dimension\n",
        "                tensor_dict['detection_masks'] = tf.expand_dims(\n",
        "                    detection_masks_reframed, 0)\n",
        "            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "            # Run inference\n",
        "            output_dict = sess.run(tensor_dict,\n",
        "                                   feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
        "\n",
        "            # all outputs are float32 numpy arrays, so convert types as appropriate\n",
        "            output_dict['num_detections'] = int(\n",
        "                output_dict['num_detections'][0])\n",
        "            output_dict['detection_classes'] = output_dict[\n",
        "                'detection_classes'][0].astype(np.uint8)\n",
        "            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
        "            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
        "            if 'detection_masks' in output_dict:\n",
        "                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
        "    return output_dict\n",
        "\n",
        "\n",
        "for image_path in TEST_IMAGE_PATHS:\n",
        "    image = Image.open(image_path)\n",
        "    # the array based representation of the image will be used later in order to prepare the\n",
        "    # result image with boxes and labels on it.\n",
        "    image_np = load_image_into_numpy_array(image)\n",
        "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "    # Actual detection.\n",
        "    output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
        "    # Visualization of the results of a detection.\n",
        "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "        image_np,\n",
        "        output_dict['detection_boxes'],\n",
        "        output_dict['detection_classes'],\n",
        "        output_dict['detection_scores'],\n",
        "        category_index,\n",
        "        instance_masks=output_dict.get('detection_masks'),\n",
        "        use_normalized_coordinates=True,\n",
        "        line_thickness=8)\n",
        "    plt.figure(figsize=IMAGE_SIZE)\n",
        "    plt.imshow(image_np)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GStNeHWPkTcN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}